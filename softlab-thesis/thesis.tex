\documentclass[diploma]{softlab-thesis}

\usepackage{syntax}
\usepackage{graphicx}
\usepackage{minted}
\usepackage{amsmath}

%%%
%%%  The document
%%%

\begin{document}

%%%  Title page

\frontmatter


\title{Βελτιστοποίηση κλήσεων αναδρομής ουράς σε συναρτησιακές γλώσσες με πολλαπλά είδη αποτίμησης }
\author{Παναγιώτης Μπουγουλιάς}
\authoren{Panagiotis Bougoulias}
\date{Αύγουστος 2019}
\datedefense{28}{8}{2019}

\supervisor{Νικόλαος Σ. Παπασπύρου}
\supervisorpos{Καθηγητής Ε.Μ.Π.}

\committeeone{Νικόλαος Σ. Παπασπύρου}
\committeeonepos{Καθηγητής Ε.Μ.Π.}
\committeetwo{Αριστείδης Παγουρτζής}
\committeetwopos{Αν. Καθηγητής Ε.Μ.Π.}
\committeethree{Γεώργιος Γκούμας}
\committeethreepos{Επίκ. Καθηγητής Ε.Μ.Π.}

\TRnumber{CSD-SW-TR-5-19}  % number-year, ask nickie for the number
\department{Τομέας Τεχνολογίας Πληροφορικής και Υπολογιστών}

\maketitle


%%%  Abstract, in Greek

\begin{abstractgr}%

Οι συναρτησιακές γλώσσες προγραμματισμού είναι διάσημες για τη χρήση αναδρομής αντί για «βρόχους», 
κάτι που υπάρχει και χαρακτηρίζει τις προστακτικές γλώσσες προγραμματισμού. Ενώ η αναδρομή είναι καλύτερη από 
τους βρόχους σε ό,τι αφορά την καθαρότητα του κώδικα, καθώς είναι άμεσα συνδεδεμένη με το μαθηματικό ορισμό
των συναρτήσεων, έχει ένα βασικό ελάττωμα το οποίο συνδέεται με τη χρήση της μνήμης για την εκτέλεση των 
προγραμμάτων. Το πρόβλημα αυτό είναι ότι ένας αλγόριθμος που χρησιμοποιεί σταθερό χώρο μνήμης για την εκτέλεση του
σε μια προστακτική γλώσσα προγραμματισμού, μπορεί να χρησιμοποιήσει γραμμικό χώρο σε συναρτησιακή, εξαιτίας 
της αναδρομής.
  

Η λύση αυτού του προβλήματος, που δόθηκε στη δεκαετία του '70 για τη γλώσσα Scheme, ήταν η χρήση της βελτιστοποίησης
κλήσεων ουράς, μια πολύ απλή αλλά, όπως αποδείχθηκε, πολύ αποτελεσματική τεχνική για την εξάλειψη του παραπάνω προβλήματος.
Εκτός από τη Scheme, η βελτιστοποίηση αυτή περιλαμβάνεται στις υλοποιήσεις των περισσότερων συναρτησιακών 
γλωσσών με αυστηρή σημασιολογία, όπως η SML/NJ και η OCaml, καθώς και σε υλοποιήσεις προστακτικών 
γλωσσών, όπως ο "Clang" μεταγλωττιστής για τη C/C++, κάτι το οποίο φανερώνει την αξία της συγκεκριμένης 
βελτιστοποίησης για τη εξάλειψη του κόστους δέσμευσης μνήμης εξαιτίας της αναδρομής. 

Ο σκοπός αυτής της διπλωματικής διατριβής είναι να ενσωματώσει αυτή την ευρέως γνωστή βελτιστοποίηση 
μεταγλωττιστή (βελτιστοποίηση κλήσεων ουράς) για συναρτησιακές γλώσσες προγραμματισμού με αυστηρή αποτίμηση σε 
συναρτησιακή γλώσσα προγραμματισμού με πολλαπλά είδη αποτίμησης (κλήση κατά αξία, κλήση κατ' όνομα και 
κλήση κατ' ανάγκη). Συγκεκριμένα στην  περίπτωση της κλήσης κατ' ανάγκης, οι τιμές που υπακούουν σε αυτή τη
σημασιολογία "δραπετεύουν" από τη εμβέλεια του ονόματος τους πιο εύκολα απ' ότι στην 
κλήση κατ' αξία, με αποτέλεσμα να είναι αρκετά πιο δύσκολο να βρεθούν οι κλήσεις ουράς.


\begin{keywordsgr}
Βελτιστοποίηση κλήσης ουράς, οκνηρή αποτίμηση, στατική ανάλυση, διερμηνέας.
\end{keywordsgr}
\end{abstractgr}



%%%  Abstract, in English


\begin{abstracten}%
  Functional programming languages favour recursion over loops
  while the latter are a key feature of imperative programming languages. Although recursion may 
  be better than loops in terms of code purity, as it is directly linked to the mathematical definition
  of functions, it has a major flaw associated with the memory overhead to execute
  programs. This problem is that an algorithm uses a fixed memory space to run it
  in a imperative programming language, it can use linear space in a functional language because
  of recursion.
  
  
  The solution to this problem, given in the 1970s for the programming language Scheme, was tail-call 
  optimisation, a very simple but, as it turned out, very effective in order to eliminate the above 
  problem.
  In addition to Scheme, this optimisation is included in most implementations of functional programming 
  languages with strict semantics, such as SML / NJ and OCaml, as well as in imperative programming 
  languages, such as the "Clang" compiler for C/C++, which demonstrates the value of this particular
  optimisation to eliminate memory overhead due to recursion.
  
  The purpose of this thesis is to integrate this well-known compiler optimisation
  (tail call optimisation) for strict functional programming languages in
  functional programming languages with multiple evaluation order choices (call-by-value, call-by-name and
  call-by-need). Specifically in the presence of call-by-need semantics, the program values under this 
  semantics "escape" their context more easily than in call-by-value, making tail-calls much more 
  difficult to reveal.
  

\begin{keywordsen}
Tail-call optimisation, lazy evaluation, static analysis, interpreter. 
\end{keywordsen}
\end{abstracten}


%%%  Acknowledgements

\begin{acknowledgementsgr}
Ευχαριστώ θερμά τον επιβλέποντα καθηγητή αυτής της διατριβής,
κ.~Νίκο Παπασπύρου, για τη συνεχή καθοδήγηση και εμπιστοσύνη
του. Θέλω να ευχαριστήσω ακόμα
το Γιώργο Φουρτούνη, ο οποίος με βοήθησε σε
διάφορα στάδια αυτής της εργασίας.  Θα ήθελα τέλος να ευχαριστήσω
την οικογένειά μου και κυρίως τους γονείς μου, οι οποίοι με
υποστήριξαν και έκαναν δυνατή την απερίσπαστη ενασχόλησή μου τόσο
με την εκπόνηση της διπλωματικής μου, όσο και συνολικά με τις
σπουδές μου.
\end{acknowledgementsgr}


%%%  Various tables

\tableofcontents
\listoftables
\listoffigures
%\listofalgorithms


%%%  Main part of the book

\mainmatter

\chapter{Εισαγωγή}


\section{Σκοπός}
Σκοπός της εργασίας είναι η ενσωμάτωση της βελτιστοποίησης κλήσης ουράς σε συναρτησιακές γλώσσες 
προγραμματισμού με την παρουσία πολλαπλών επιλογών σειράς αποτίμησης 
(κλήση κατ' αξία, κλήση κατ' όνομα, κλήση κατ' ανάγκη). Η βελτιστοποίησή μας μπορεί να συνδυαστεί με το
μετασχηματισμό defunctionalization, έτσι ώστε η 
βελτιστοποίηση απόδοσης που προκύπτει να υποστηρίζει επίσης συναρτησιακές γλώσσες υψηλότερης τάξης.

\section{Κίνητρο}

Η βελτιστοποίηση κλήσεων ουράς για συναρτησιακές γλώσσες με αυστηρή αποτίμηση είναι ένα καλά 
μελετημένο θέμα, αλλά αποτυγχάνει στην
παρουσία οκνηρής αποτίμησης (lazy): ο υπολογισμός ενός οκνηρού όρου μπορεί να συμβεί αυθαίρετα 
κατά τη διάρκεια της εκτέλεσης
του προγράμματος και έτσι οι οκνηροί όροι δραπετεύουν από το περιβάλλον τους 
πιο εύκολα από τους αυστηρούς.
Από τη μία πλευρά, η οκνηρότητα δίνει στους προγραμματιστές μεγάλες επιλογές: 
να χρησιμοποιούν άπειρες δομές δεδομένων,
να ορίσουν τη ροή ελέγχου (δομές) ως αφαιρέσεις (abstaractions), 
να αυξήσουν την απόδοση
αποφεύγοντας τους περιττούς υπολογισμούς και αποφεύγοντας τις περιπτώσεις σφάλματος 
κατά την αξιολόγηση σύνθετων εκφράσεων.
Αλλά αυτή η ευελιξία έρχεται με κόστος: τα πολύ οκνηρά προγράμματα μπορεί 
να οδηγήσουν σε κακή απόδοση, ακόμη και σε διαρροές μνήμης.
Από την άλλη πλευρά, η αυστηρότητα επιτρέπει στους προγραμματιστές να μετρούν
την επίδοση του προγράμματος πιο εύκολα, αλλά τα προγράμματα μπορούν
εμπίπτουν σε ανεπιθύμητη συμπεριφορά, όπως η απόκλιση.

Σε αυτή τη διατριβή, παίρνουμε το καλύτερο και των δύο κόσμων: τα προγράμματά μας δεν χρειάζεται 
να είναι πολύ οκνηρά ούτε πολύ αυστηρά. Χρησιμοποιώντας επισημειώσεις σειράς αποτίμησης, υποστηρίζουμε τη 
βελτιστοποίηση κλήσεων ουράς σε οκνηρές
συναρτησιακές γλώσσες προγραμματισμού, εξαλείφοντας έτσι την δέσμευση επιπλέον μνήμης που σχετίζεται 
με την αναδρομή, όπως και στις αυστηρές συναρτησιακές γλώσσες.

\section{Σύνοψη της διπλωματικής}

Σε αυτή τη διατριβή, ενσωματώνουμε την βελτιστοποίηση κλήσεων ουράς σε συναρτησιακή
γλώσσα με την παρουσία πολλαπλών σειρών αποτίμησης (κλήση κατ' αξία, κλήση κατ' όνομα, κλήση κατ' ανάγκη).
Η βελτιστοποίησή μας υποστηρίζει τύπους δεδομένων που έχουν οριστεί από τον χρήστη με αντιστοίχιση 
μοτίβων (pattern matching) και συνεπώς μπορούν να συνδυαστούν με το
μετασχηματισμό defunctionalization, έτσι ώστε να υποστηρίζονται επίσης λειτουργικές γλώσσες ανώτερης τάξης. 
Η γλώσσα πηγής, παρόμοια με τη Haskell,
μετασχηματίζεται (μέσω defunctionalization) σε μια χαμηλού επιπέδου, ελάχιστη, πρώτης τάξης συναρτησιακή 
γλώσσα
με μη αυστηρή σημασιολογία, οκνηρή αποτίμηση και οκνηρά δομημένα δεδομένα καθώς και επισημειώσεις 
αυστηρότητας. Για να βρούμε ευκαιρίες για βελτιστοποίηση, κάνουμε μια στατική ανάλυση για τη
συναρτησιακή γλώσσα χαμηλού επιπέδου, για τον εντοπισμό θέσεων κλήσης ουράς. Το δύσκολο κομμάτι,
σε σύγκριση με τις γλώσσες με αυστηρή σημασιολογία, είναι ότι η οκνηρή σημασιολογία κάνει τις τιμές 
του προγράμματος να ξεφύγουν από την εμβέλεια του ονόματός τους
και, συνεπώς, η εύρεση θέσεων κλήσης ουράς δεν είναι τόσο εύκολη. Αυτή η βελτιστοποίηση αξιολογήθηκε
σε έναν διερμηνέα της γλώσσας που δεσμεύει ρητά και μετράει πλαίσια, έτσι ώστε
στις θέσεις που βρέθηκαν από την ανάλυση, να μπορούμε να αντικαταστήσουμε σωστά τις περιττές παραμέτρους
πλαισίου με αυτές που απαιτούνται από το πλαίσιο που αντιπροσωπεύει την επόμενη αναδρομική κλήση.
Η βελτιστοποίηση είτε βελτιώνει την απόδοση του προγράμματος είτε δεν την αλλάζει. Επίσης, 
στην περίπτωση προγραμμάτων με αυστηρή σημασιολογία, η βελτιστοποίησή μας είναι ισοδύναμη με την κλασική 
βελτιστοποίηση κλήσεων ουράς. Συμπερασματικά,
σε μια μη αυστηρή, οκνηρή συναρτησιακή γλώσσα με οκνηρούς κατασκευαστές δεδομένων και 
επισημειώσεις αυστηρότητας, για όλους τα προγράμματα που χρησιμοποιούμε ως αναφορά, υπάρχει πάντα 
βελτιστοποίηση μνήμης, 
και για την πλειοψηφία
από αυτά υπάρχει σημαντική βελτιστοποίηση μνήμης με ενίσχυση της απόδοσης.

\section{Συνεισφορά}

Οι σημαντικότερες συνεισφορές μας, που παρουσιάζονται σε αυτή τη διατριβή, είναι:


Παρουσιάζουμε πώς η βελτιστοποίηση της κλήσης ουράς μπορεί να εφαρμοστεί σε μια συναρτησιακή 
γλώσσα με μεικτή σειρά αποτίμησης. Βασική συνεισφορά μας είναι πώς μπορεί να εφαρμοστεί
την παρουσία της οκνηρής αποτίμησης, μετατρέποντας έτσι αυτή τη βελτιστοποίηση σε επέκταση της 
βελτιστοποίησης κλήσεων ουράς για γλώσσες με κλήση κατ' αξία.

Μια πρωτότυπη υλοποίηση ενός διερμηνέα με ρητή δέσμευση πλαισίων, καθώς και μηχανισμό μέτρησης 
πλαισίων, για μια συναρτησιακή γλώσσα με κλήση κατ' αξία, κλήση κατ' όνομα και κλήση κατ' ανάγκη, οκνηρούς 
κατασκευαστές δεδομένων και pattern matching.

Ένας αλγόριθμος στατικής ανάλυσης για την εύρεση πραγματικών θέσεων κλήσης ουράς 
και την υλοποίηση του συστήματος χρόνου εκτέλεσης για αυτές τις βελτιστοποιήσεις που είναι 
ενσωματωμένες στον διερμηνέα.

Η αξιολόγηση αυτής της βελτιστοποίησης σε προγράμματα αναφοράς δείχνει ότι είτε βελτιώνει 
τη μνήμη ή δεν την αλλάζει. Η αξιολόγηση φαίνεται να προσεγγίζει σε πολλές περιπτώσεις τον αριθμό της
δέσμευσης πλαισίων σε γλώσσες ανά κλήση ανά αξία, που είναι το καλύτερο αποτέλεσμα που μπορούμε να έχουμε.

%

\chapter{Η γλώσσα}

Σε αυτό το κεφάλαιο, θα περιγράψουμε τη γλώσσα που μελετήσαμε σε αυτή τη διατριβή.
Η σημασιολογία της γλώσσας θα γίνει σαφής στον αναγνώστη, καθώς και
η ειδική αντιμετώπιση των πολλαπλών ειδών αποτίμησης στον τελικό πυρήνα της
γλώσσας, η οποία χρησιμοποιήθηκε για τη στατική ανάλυση και για τις βελτιστοποιήσεις. Εν συντομία, 
υπάρχει μια
περιεκτική περιγραφή της διαδρομής από μια συναρτησιακή γλώσσα ανώτερης τάξης
σε μια συναρτησιακή γλώσσα πρώτης τάξης με τις επισημειωμένες των σειρών αποτίμησης.

\section{Επισκόπηση της γλώσσας}

Η γλώσσα που μελετήσαμε είναι μια λειτουργική γλώσσα
με πολλαπλές σειρές αποτίμησης (κλήση κατ' ανάγκη ή
οκνηρή, κλήση κατ' όνομα και κλήση κατ' αξία ή αυστηρή).
Θεωρούμε την οκνηρότητα ως κάτι που συμβαίνει φυσικά στη γλώσσα, ενώ
οι άλλες δύο σειρές αποτίμησης χρησιμοποιούνται ως επεκτάσεις γλώσσας,
χρησιμοποιώντας κατάλληλες επισημειώσεις.

Οι επισημειώσεις αποτίμησης μπορούν να εμφανιστούν συντακτικά (δηλ. 
ο προγραμματιστής μπορεί να τις χρησιμοποιήσει στον κώδικα στις
στις τυπικές παράμετρους στον ορισμό της συνάρτησης) ή
μετά την εφαρμογή των μετασχηματισμών, που περιγράφονται στα τμήματα 3.2 έως 3.4,
στη γλώσσα πηγής. Το τελευταίο
είναι μόνο η περίπτωση αυστηρών όρων που αποκαλύπτονται από την ανάλυση αυστηρότητας.

\section{Μετασχηματισμός defunctionalization}

Πρόκειται για μια τεχνική μετασχηματισμού χρόνου μεταγλώτισσης που καταργεί τις εφαρμογές 
υψηλότερης τάξης
αντικαθιστώντας τις με μία μόνο συνάρτηση πρώτης τάξης, που παρουσιάστηκε από τον 
John Reynolds.
Η παρατήρηση του Reynolds ήταν ότι ένα δεδομένο πρόγραμμα περιέχει μόνο πεπερασμένα 
πολλές αφαιρέσεις λειτουργιών, έτσι ώστε το καθένα μπορεί
να ανατεθεί σε (και να αντικατασταθεί από) ένα μοναδικό αναγνωριστικό. Στη συνέχεια 
αντικαθίσταται κάθε εφαρμογή συνάρτησης μέσα στο πρόγραμμα
από μια κλήση προς τη λειτουργία εφαρμογής με το αναγνωριστικό λειτουργίας 
ως το πρώτο επιχείρημα. Η μόνη δουλειά της εφαρμογής είναι η συνάρτηση
να εφαρμόζεται σε αυτό το πρώτο επιχείρημα και, στη συνέχεια, να εκτελείται
τις εντολές που αντιστοιχούν με το αναγνωριστικό συνάρτησης στην εντολή με τα 
υπόλοιπες παραμέτρους.

% Μια επιπλοκή σε αυτή τη βασική ιδέα είναι ότι οι αθροιστικές λειτουργίες μπορούν να αναφέρουν ελεύθερες μεταβλητές. Σε τέτοιες καταστάσεις,
% η αποσταθεροποίηση πρέπει να προηγείται από μετατροπή κλεισίματος (ανύψωση λάμδα), έτσι ώστε οποιεσδήποτε ελεύθερες μεταβλητές μιας συνάρτησης
% αφαίρεση περνούν ως πρόσθετα επιχειρήματα για να εφαρμοστούν. Επιπλέον, εάν τα πώματα υποστηρίζονται ως τιμές πρώτης τάξης,
% καθίσταται αναγκαίο να αντιπροσωπεύονται αυτές οι δεσμεύσεις που έχουν ληφθεί δημιουργώντας δομές δεδομένων.

Ο μετασχηματισμός αποκοπής χρησιμοποιήθηκε στο MLton, ένας βελτιστοποιημένος μεταγλωττιστής για ML. 
Η γλώσσα πυρήνα πρώτης τάξης δημιούργησε ευκαιρίες για ανάλυση ολόκληρου του προγράμματος και 
οδήγησε σε εξαιρετική απόδοση.

Ως παράδειγμα του μετασχηματισμού, ακολουθεί η συνάρτηση map του Prelude.

\begin{minted}{haskell}
  map :: (a -> b) -> [a] -> [b]
  map f []     = []
  map f (x:xs) = f x : map f xs

  inc :: Int -> Int 
  inc a = a + 1
  
  result = map inc [1,2,3]
\end{minted}

Μετά την εκτέλεση του defunctionalization, το `map 'είναι (instantiated για ακεραίους):
\begin{minted}{haskell}
  data Func = Inc 

  apply :: Func -> b -> b
  apply f x =
    case f of
      Inc -> inc x

  map :: Func -> [a] -> [b]
  map f l =
  case l of
    []     -> acc
    x : xs -> apply f x : map f xs

  inc :: Int -> Int 
  inc a = a + 1

  result :: [Int]
  result = map Inc [1, 2, 3] []
\end{minted}

Οι διαφορές μεταξύ των δύο εκδόσεων είναι:
\begin{itemize}
\item Η υψηλής τάξης συνάρτηση, το πρώτο όρισμα της `map '(f :: a -> b)
μετασχηματίζεται σε \textit{μοναδικό} αναγνωριστικό, το οποίο είναι ο κατασκευαστής δεδομένων `Inc'.
\item Για την εφαρμογή μέσα στο σώμα της συνάρτησης `result', έχουμε την συνάρτηση πρώτης τάξης 
\textit{apply} η οποία αντιστοιχεί τα μοναδικά αναγνωριστικά που εφαρμόζονται στη `map'.
\end{itemize}

Δεν δίνονται περισσότερες λεπτομέρειες και φορμαλισμός του μετασχηματισμού defunctionalization εδώ.
Ο αναγνώστης μπορεί να αναφερθεί στη δημοσίευση του Reynolds για περισσότερες πληροφορίες 
σχετικά με αυτό το μετασχηματισμό.

\section{Ανάλυση αυστηρότητας}

Η κλήση κατ' ανάγκη μόνο όρους σε τιμές όταν χρειάζεται. Αυτό παρέχει την
ευκαιρία για άπειρες δομές δεδομένων και προγράμματα που δεν αποκλίνουν, όπως αυτά σε
αυστηρές γλώσσες προγραμματισμού. H αξιολόγηση μπορεί να συμβεί
αυθαίρετα και ως εκ τούτου οι οκνηροι όροι μπορούν να ξεφύγουν από το περιβάλλον τους.

Αλλά ο Mycroft παρατήρησε ότι ορισμένοι οκνηροί όροι είναι στην
πραγματικότητα αυστηροί υπό τις κατάλληλες συνθήκες. Για παράδειγμα,
το `case' αποτιμά κάποιον όρο (\emph{scrutinee}~\cite{PeytonJones94}),
κάνοντάς τον αυστηρό, παρόμοια με την αυστηρότητα των BangPatterns.

Και είναι κάτι παραπάνω από αυτό. Ας δούμε ξανά το πρόγραμμα sum:
\begin{minted}{haskell}
  sum :: [Int] -> Int -> Int
  sum [] acc = acc
  sum (x: xs) acc = sum xs (x + acc)
\end{minted}

Εδώ, ο οκνηρός όρος `acc', ο οποίος είναι σε μορφή που δεν έχει
υπολογιστεί ακόμα (\emph{thunk}~\cite{Bloss1988}), σε κάθε κλήση
λειτουργίας αποτιμάται μία φορά, όταν το πρόγραμμα κατά τη ροή
εκτέλεσης του φτάνει στη βασική περίπτωση. Αυτή η αυθαίρετη αποτίμηση
των οκνηρών όρων φαίνεται να μην είναι τόσο αυθαίρετη. Γνωρίζουμε πότε
πρόκειται να αξιολογηθεί το 'acc'.

Λοιπόν, το ερώτημα είναι, τι είναι αυτό που κάνει το `acc 'τόσο προβλέψιμο;
Από το παραπάνω παράδειγμα, έχουμε τις ακόλουθες πληροφορίες για το `acc':
\begin{itemize}
  \item `acc' είναι ένας ακέραιος αριθμός, που πάντα προστίθεται σε έναν άλλο ακέραιο αριθμό.
  \item `acc' είναι το αποτέλεσμα της συνάρτησης.
\end{itemize}

Από αυτές τις παρατηρήσεις μπορούμε να συμπεράνουμε ότι το acc πρόκειται να αξιολογηθεί 
(δεύτερη παρατήρηση) και όλες οι ενδιάμεσες τιμές είναι απαραίτητες για την αποτίμησή του, καθώς 
το `acc 'είναι ένας ακέραιος αριθμός (πρώτη παρατήρηση), οπότε και μπορούν να αποτιμώνται κάθε φορά.

Αν και σε αυτή τη διατριβή χρησιμοποιήσαμε ακέραιους αριθμούς και λίστες, η ανάλυση αυστηρότητας 
μπορεί να εφαρμοστεί εκτός από ακεραίους και σε οποιοδήποτε άλλες τιμές βασικού τύπου.
Η ανάλυση αυστηρότητας εκτελείται στη γλώσσα της ανώτερης τάξης μετά το defunctionalization για να 
εντοπίσει τούς αυστηρούς όρους.

\section{Άλλοι μετασχηματισμοί}

Μετά από το μετασχηματισμό defunctionalization και την ανάλυση αυστηρότητας, έχουμε επίσης
εκτελέσει μερικούς μετασχηματισμούς στη γλώσσα, προκειμένου η ενδιάμεση
γλώσσα να φτάσει στην τελική μορφή, η οποία είναι η είσοδος της ανάλυσης, που 
παρουσιάζεται στην επόμενη ενότητα.


\begin{itemize}
\item \textbf{Άλφα-μετονομασία:} Αυτός ο μετασχηματισμός (\emph{alpha-renaming} ή \emph{alpha-conversion}~\cite{Barendregt:1993:LCT:162552.162561}) μετονομάζει όλες τις μεταβλητές που δεσμεύονται από την αντιστοίχιση προτύπων.
Κάθε έκφραση `case' ανοίγει ένα νέο πεδίο εφαρμογής και τα ονόματα μεταβλητών σε αυτό το πεδίο δεσμεύονται στο πλησιέστερο
«περίπτωση». Αυτή η μεταμόρφωση επίσης χειρίζεται τη σκίαση ονόματος.
\item \textbf{Μετατροπή του if σε case:} Όταν η γλώσσα υποστηρίζει αντιστοίχιση προτύπων στα δεδομένα
(κατασκευαστές), η έκφραση `if' είναι άχρηστη. Μπορεί να μετατραπεί σε αντιστοίχιση προτύπου
το μηδενικό boolean κατασκευαστή. Ο Haskell δεν έχει έκφραση `if 'ως ενσωματωμένη (builtin). 
Eπιτρέπει μόνο συντακτική χρήση (ως συντακτική ζάχαρη για μοτίβα boolean).
\item \textbf{Προβολές κατασκευαστών (constructor projections):} Κάθε μεταβλητή που δεσμεύεται από ένα μοτίβο 
`case 'πρέπει να είναι μετασχηματισμένο σε έναν ειδικό συντακτικό κόμβο στη γλώσσα του πυρήνα, 
ο οποίος περιέχει το μοναδικό αναγνωριστικό της περίπτωσης και η θέση μέσα στη λίστα έκφρασης 
στο πρότυπο κατασκευαστή~\cite{Fourtounis:2013:GIT:2769663.2769674}. 
Το αναγνωριστικό "case" είναι μοναδικό μέσα σε έναν ορισμό συνάρτησης (τοπικά).
\end{itemize}

\section{Σύνταξη}

Σε αυτή την ενότητα δίνεται η σύνταξη της βασικής μας γλώσσας.
Αυτό είναι το αποτέλεσμα της ανάλυσης αυστηρότητας και
μετασχηματισμού καθυστέρησης, καθώς και των άλλων μετασχηματισμών της προηγούμενης
Ενότητα. Εκτελούμε τον αλγόριθμο ανάλυσης για να εντοπίσουμε θέσεις κλήσης ουράς με είσοδο
τη γλώσσα από αυτήν την ενότητα. Ο διερμηνέας είναι επίσης χτισμένος για τη γλώσσα αυτή. 
ο αξιολογητής για
οι βελτιστοποιήσεις εφαρμόζονται επίσης στο εσωτερικό του διερμηνέα για αυτή τη γλώσσα.

Στο σχήμα~\ref{fig:elgrammar}, υπάρχει η αφηρημένη σύνταξη του
η ενδιάμεση γλώσσα πρώτης τάξης.
Πρέπει να επισημάνουμε τα ακόλουθα σημεία, πριν εμβαθύνουμε βαθύτερα στη γλώσσα:
\begin{itemize}
  \item Στη γλώσσα προέλευσης υπάρχει μια έκφραση `if 'συντακτικά. Στο συντακτικό σχήμα δεν υπάρχει.
Αυτό οφείλεται στο ότι η `case' είναι πολύ πιο ισχυρή από το `if 'και το` if' μπορεί να μετατραπεί 
σε `case'. Στην πραγματικότητα έχουμε (boolean είναι κατασκευασμένα δεδομένα επίσης) pattern matching 
σε booleans:
\begin{minted}{haskell}
    if cond then e1 else e2 => case cond of {True -> e1; False -> e2}
\end{minted}
\item Δεν υπάρχουν μερικές εφαρμογές, ούτε σε συναρτήσεις ούτε σε εφαρμογές κατασκευαστών.
Αυτό σημαίνει ότι τα επιχειρήματα σε μια κλήση λειτουργίας είναι ίδια στον αριθμό με τον ορισμό 
της λειτουργίας.
\item Δεν υπάρχει έκφραση `let' στην γλώσσα. Αντ 'αυτού υποθέτουμε ότι η γλώσσα μας εξαρτάται 
πλήρως από τον ανυψωτή λάμδα (lambda lifter). O lambda lifter του Johnson 
\textit{πλήρους οκνηρότητας} θα έχει το επιθυμητό αποτέλεσμα~\cite{Johnsson:1985:LLT:5280.5292}.
\item Τα μοτίβα των περιπτώσεων είναι απλά και δεν επιτρέπουν τα μοτίβα μπαλαντέρ (wildcard). 
Μετατρέποντας ένα πολύπλοκο μοτίβο σε ένα απλό είναι ένα καλά μελετημένο θέμα.
\end{itemize}


\begin{figure}[t]
  \hrule
  \begin{grammar}
      <p> ::= <fdef>\textsuperscript{+} \hfill\ Program
  
      <fdef> ::= \textit{f v\textsubscript{1} ... v\textsubscript{n}} = <expression> \hfill\ Function Definition
  
      <expr> ::= \textit{v} \hfill\ Variable
      \alt <integer> \hfill\ Integer
      \alt \textit{f e\textsubscript{1} ... e\textsubscript{n}} \hfill\ Function application
      \alt \textit{c e\textsubscript{1} ... e\textsubscript{n}} \hfill\ Constructor application
      \alt \texttt{case} \textit{e\textsubscript{0}} \texttt{of} \textit{patt\textsubscript{1} $\rightarrow$ e\textsubscript{1} | ... | patt\textsubscript{n} $\rightarrow$ e\textsubscript{n}} \hfill\ Case expression
       
      <patt> ::= \textit{c v\textsubscript{1} ... v\textsubscript{n}} \hfill\ Constructor pattern
      \alt <integer> \hfill\ Integer pattern
  
      <integer> ::= 1, 2, ... \hfill\ Integer domain
  
  \end{grammar}
  \hrule
\caption{Η γραμματική της γλώσσας\label{fig:elgrammar}}
\end{figure}

Η σύνταξη στο σχήμα είναι μια σύνταξη μιας συναρτησιακής γλώσσας πρώτης τάξης. Η σύνταξή μας έχει 
δύο κύριες διαφορές από αυτές που φαίνονται στο σχήμα:
\begin{itemize}
\item Η συγκεκριμένη σύνταξη της βασικής γλώσσας έχει σημειώσεις τάξης αξιολόγησης προκειμένου να
να διακρίνει μεταξύ της σημασιολογίας κατά τη διέλευση των παραμέτρων. Έχουμε ήδη αναφέρει το
τα σχόλια αυστηρότητας που προστίθενται από την ανάλυση αυστηρότητας.
Πιο συγκεκριμένα, ο προγραμματιστής μπορεί συγκεκριμένα να σχολιάσει τις μορφές στον ορισμό 
της λειτουργίας με:
\begin{itemize}
\item {`!' για μια αυστηρή τυπική παράμετρο,}
\item {`\# 'για τυπική παράμετρο κλήσης με όνομα, ενώ}
\item {Οι οκνηρές τυπικές παράμετροι δεν σχολιάζονται, επειδή θεωρούμε την 
οκνηρότητα ως κάτι που φυσικά συμβαίνει στη γλώσσα.}
\end{itemize}%

Όσον αφορά την αφηρημένη σύνταξη, οι τυπικές παράμετροι ενός ορισμού συνάρτησης είναι:
\begin{minted}{haskell}
  type Formal = (VN, (EvalOrder, Type))
  type VN = String 
  type EvalOrder = CBV | CBN | Lazy 
  data Type = TInt | TCons Type -- an value of type integer (TInt) or 
                                -- a list of values with type Type
\end{minted}
όπου ο κατασκευαστής τύπου μιας τυπικής παραμέτρου έχει τις πληροφορίες σχετικά με το όνομα της παραμέτρου και
τη στατική πληροφορία της εντολής αξιολόγησης και τον τύπο της. Υποθέτουμε τους τύπους βάσης ως ακέραιους αριθμούς και αργότερα
το τμήμα ανάλυσης, θα εξηγήσουμε γιατί αυτό αρκεί.

\item Υπάρχει ένας ακόμα κόμβος στο συντακτικό δέντρο: οι προβολές κατασκευαστών (\textit{constructor projections}). 
Ο μετασχηματισμός γι 'αυτό, ο συγκεκριμένος κόμβος σύνταξης έχει εξηγηθεί νωρίτερα σε προηγούμενη ενότητα και η σύνταξη σε
όρους Haskell είναι:
\begin{minted}{haskell}
data Expr = ... | CProj CaseID CPos
\end{minted}

Σε μια προβολή κατασκευαστή, το  `CaseID' δείχνει τη θέση του `case' όπου ανήκει o όρος, μέσα στο σώμα της συνάρτησης,
και το δεύτερο όρισμα (`CPos') είναι η θέση της μεταβλητής στη λίστα εκφράσεων του μοτίβου κατασκευαστή σε διακλάδωση του `case'.


Ο σκοπός των προβολών του κατασκευαστή είναι να `δέσει' τις μεταβλητές στη δεξιά πλευρά της διακλάδωσης με τις μεταβλητές
στην αριστερή πλευρά. Με τον τρόπο αυτό, οι μεταβλητές αυτές διακρίνονται από τις μεταβλητές ανώτερου επιπέδου, δηλ.
από τις τυπικές παραμέτρους στον ορισμό της συνάρτησης και προσφέρουν τη δυνατότητα να γνωρίζουμε τη θέση τους στο πλαίσιο,
ένας λόγος που θα γίνει σαφέστερος στο επόμενο κεφάλαιο, όπου θα δώσουμε τις λεπτομέρειες του μοντέλου εκτέλεσης.
\end{itemize}


\chapter{Μοντέλο εκτέλεσης}

Σε αυτό το κεφάλαιο, θα παρουσιάσουμε τις τεχνικές λεπτομέρειες του μοντέλου εκτέλεσης για
τη γλώσσα που μελετήσαμε σε αυτή τη διατριβή καθώς και τις τεχνικές λεπτομέρειες σχετικά με την υλοποιήση και τη λειτουργία 
τον διερμηνέα, στον οποίο αξιολογούμε την τεχνική μας για την βελτιστοποίηση της κλήσης ουράς.

Στην επόμενη ενότητα υπάρχει μια περιγραφή υψηλού επιπέδου του μοντέλου.
Στη συνέχεια παρουσιάζονται οι δομές δεδομένων που χρησιμοποιούνται κατά το χρόνο εκτέλεσης 
και στη συνέχεια η λειτουργία του διερμηνέα παρουσιάζεται με τη μορφή λειτουργικής σημασιολογίας (operational semantics) για τη γλώσσα.


\section{Περιγραφή υψηλού επιπέδου του μοντέλου εκτέλεσης}

In this section, we present a high-level description for the execution model; this will be helpful for the reader
to follow the technical details from the next sections. Also, it will be easier to compare to other existing 
abstract machines and interpreters that exist for a lazy functional language.

Το μοντέλο μας, βασισμένο στον  GIC~\cite{Fourtounis14}, 
includes the following high-level properties:
\begin{itemize}
\item Υλοποιούμε μια  αφηρημένη μηχανή πρώτης τάξης. Πρώτης τάξης, διότι δεν υποστηρίζουμε πέρασμα συναρτήσεων υψηλής τάξης ως παραμέτρους σε συνάρτηση
, καθώς και μερική αποτίμηση. Η οκνηρότητα είναι η προεπιλεγμένη σημασιολογία για το μοντέλο μας.
\item Έχουμε ένα μοντέλο βασισμέμο στη δέσμευση πλαισίων για τη γλώσσα μας, αλλά τα πλαίσια δεσμεύονται στο σωρό αντί για στοίβα (heap allocated frames).
Ο λόγος γι' αυτό είναι ότι η οκνηρή αποτίμηση δε συμβαδίζει με την ακολουθιακή ροή της εκτέλεσης του προγράμματος, κάτι το οποίοπ καθιστά αδύνατη 
τη δέσμευση/αποδέσμευση πλαισίων με τις λειτουργίες push/pop.
\item Ο διερμηνέας μας υποστηρίζει τη ρητή δέσμευση πλαισίων, η οποία χρειάζεται για το μετασχηματισμό των πλαισίων στη βελτιστοποίηση 
καθώς και την αξιολόγηση της τεχνικής μας, όπως επίσης και ένα μηχανισμό καταμέτρησης των πλαισίων.
\item Η γλώσσα μας  υποστηρίζει πολλαπλά είδη αποτίμησης και έτσι ο διερμηνέας μας τα χειρίζεται και αυτά (call-by-value, call-by-name, call-by-need)
με κατάλληλο τρόπο.
\item Τα δεδομένα μας κατασκευάζονται από οκνηρούς κατασκευαστές δεδομένων, αλλά μπορούμε επίσης να υποστηρίξουμε ML-λίστες (δεδομένα με βαθιά αποτίμηση, όπως στη γλώσσα ML).
\item Στις κλήσεις συναρτήσεων ακολουθούμε την πολιτική push/enter. Πριν εισέλθουμε στο σώμα της συνάρτησης,
δεσμεύουμε το πλαίσιο και αποτιμούμε όλες τις πραγματικές παραμέτρους, σεβόμενοι τη σημασιολογία τους.
\item Το μοντέλο μας υποστηρίζει pattern matching (σε δεδομένα και τιμές βασικόυ τύπου) με παρόμοιο τρόπο, όπως στη Haskell. 
Αυτό αποτελεί το πιο σύνθετο γνώρισμα μιας οκνηρής συναρτησιακής γλώσσας, ειδικά αν αναλογιστούμε ότι οι πρώτες αφηρημένες μηχανές γι' αυτές τις γλώσσες δεν παρείχαν 
υποστήριξη για το συγκεκριμένο γνώρισμα.
\end{itemize}

\section{Σύστημα χρόνου εκτέλεσης}

Αυτή η ενότητα περιέχει μια λεπτομερή εξήγηση για την πρωτότυπη εφαρμογή του διερμηνέα μας
που χρησιμοποιείται στη γλώσσα. Πρώτον, θα παρουσιάσουμε τις δομές δεδομένων που χρησιμοποιούνται κατά τη διάρκεια εκτέλεσης. Έπειτα,
παρουσιάζουμε τα λειτουργικά χαρακτηριστικά του διερμηνέα μας.

\section{Δομές δεδομένων κατά το χρόνο εκτέλεσης}

Εδώ υπάρχουν ορισμοί των δομών χρόνου εκτέλεσης, όπως χρησιμοποιούνται στην υλοποίηση. Αν και η εφαρμογή είναι σε Haskell, ο κώδικας θα είναι απλός, έτσι ώστε κάθε αναγνώστης με ένα βασικό υπόβαθρο 
συναρτησιακού προγραμματισμού να μπορεί να το καταλάβει.

Στις επόμενες ενότητες που θα περιγράψουμε τις δομές χρόνου εκτέλεσης, θα χρησιμοποιήσουμε την ακόλουθη σύμβαση. Στην αρχή, ένας ορισμός
θα εμφανιστεί, ενώ στξ συνέχια πιθανώς θα συνοδεύεται από έναν ή περισσότερους ορισμούς. Αν περιέχει πιο πολύπλοκα δεδομένα στο σώμα του, θα 
περιγράφεται αργότερα στην ενότητα ή θα υπάρχει ένας δείκτης σε μια άλλη ενότητα που θα περιέχει λεπτομέρειες γι' αυτόν τον ορισμό.

\subsection{Μνήμη}

Σε αυτή την ενότητα παρέχουμε τον ορισμό της δομής της μνήμης(\textit{memory}), ένα \textit{mutable} χώρο αποθήκευσης, 
όπου αποθηκεύονται τα πλαίσια.


Για τη δομή \textit{memory}, έχουμε τα παρακάτω:
\begin{minted}{haskell}
  type FrameId = Int
  data Mem = Mem {
    memFrames :: Map FrameId Frame, lastFrameId :: FrameId
  }
\end{minted}

Ο αναγνώστης μπορεί να σκεφτεί τη δομή αυτή ως μνήμη σε έναν υπολογιστή: κάθε κύτταρο μνήμης έχει μια διεύθυνση (\textit{FrameId}) και
η διεύθυνση έχει ένα περιεχόμενο (\textit{frame}). Μια παρόμοια αναπαράσταση με το mutable σωρό του Launchbury για οκνηρή αποτίμηση.
Εδώ να σημειώσουμε ότι όλα τα πλαίσια δεν έχουν την ίδια χωρητικότητα. Λεπτομέρειες θα δοθούν σε επόμενη ενότητα για ένα πλαίσιο.


Αυτή η προαναφερθείσα δομή δεδομένων συνοδεύεται από τις τρεις ακόλουθες λειτουργίες, που δίνονται αμέσως μετά. 
\begin{itemize}
  \item Προσθήκη ενός πλαισίου στη μνήμη με τη λειτουργία \textit{push}, στο σχήμα~\ref{fig:pushEL}.
  \item Ανάγνωση του περιεχόμενου ενός πλαισίου από τη μνήμη, αν δοθεί το αναγνωριστικό του (\textit{getFrame})
  , η οποία δίνεται στο σχήμα~\ref{fig:getFrameEL}.
  \item Ενημέρωση του περιεχομένου ενός πλαισίου στη μνήμη,
  δοθέντος του αναγνωριστικού του (\textit{updFrame}), η οποία δίνεται στο σχήμα~\ref{fig:updFrameEL}.
\end{itemize}

Αργότερα θα χρησιμοποιήσουμε τα ονόματα των λειτουργιών 
\textit{push}, \textit{getFrame} και \textit{updFrame} για να αναφερθούμε σε αυτές χωρίς περαιτέρω επεξήγηση. 


\begin{figure}[htp]
  $ \mathit{push} :: \mathit{Mem \times Frame \rightarrow Mem} $ \\
  $ \mathit{push~(mem, frame) = mem'} $ \\
  $ \mathit{mem' = Mem~\{~memFrames = frames', lastFrameId = lastId~\} } $ \\
  $ \mathit{frames' = frame : (memFrames~mem)} $ \\
  $ \mathit{lastId = lastFrameId~mem + 1} $
\caption{Push λειτουργία για τη μνήμη\label{fig:pushEL}}
\end{figure}~
\begin{figure}[htp]
  $ \mathit{getFrame} :: \mathit{Mem \times FrameId \rightarrow Frame} $ \\
  $ \mathit{getFrame~(mem, id) = frame} $ \\
  $ \mathit{frame = lookup~id~(memFrames~mem)} $
\caption{GetFrame λειτoυργία\label{fig:getFrameEL}}
\end{figure}~
\begin{figure}[htp]
  $ \mathit{updFrame} :: \mathit{Mem \times FrameId \times Frame \rightarrow Mem} $ \\
  $ \mathit{upFrame~(mem, frameId, frame) = 
      mem~\{memFrames = insert~frameId~frame~(memFrames~mem)~\} } $ 
\caption{UpdateFrame λειτουργία\label{fig:updFrameEL}}
\end{figure}


\subsection{Προσωρινά σταματημένη εκτέλεση από δεδομένα (suspensions)}

Ο ορισμός για τα  suspensions είναι:
\begin{minted}{haskell}
  data Susp = Susp (CN, [Expr]) FrameId
\end{minted}

Ένα \textit{Susp} περιέχει:
\begin{itemize}
  \item Το όνομα του κατασκευαστή \textit{CN} μαζί με τα ορίσματα του σε μια λίστα εκφράσεων. 
  \item Ένα δείκτη με τη μορφή αναγνωριστικού (\textit{FrameId}) για το πλαίσιο που είναι το περιβάλλον του suspension.
Αυτό είναι το περιβάλλον μέχρι τη στιγμή που αυτό το suspension δημιουργήθηκε. Όταν η εκτέλεση του προγράμματος επιβάλλει την αποτίμησή του,
αυτό θα είναι το περιβάλλον που θα χρησιμοποιήσει.
\end{itemize}

\subsection{Τιμές}

Μια τιμή μπορεί να είναι ένας ακέραιος (ή γενικά μια τιμή βασικού τύπου) ή ένα suspension.
\begin{minted}{haskell}
  data Value = 
    VI Integer 
  | VC Susp 
\end{minted}

Από τον παραπάνω ορισμό, έχουμε ότι μια τιμή μπορεί να είναι είτε ένας ακέραιος (ή γενικά ένας τύπος βάσης) ή αναστολή κατασκευασμένων δεδομένων. 
Ενώ η πρώτη είναι προφανής, ειδικά για τους περισσότερους προγραμματιστές που χρησιμοποιούν αυστηρές γλώσσες, το τελευταίο είναι κάτι που συμβαίνει σε οκνηρές
γλώσσες προγραμματισμού. Οι υπολογισμοί μπορεί να μην αποτιμώνται βαθιά και έτσι μπορούν να δημιουργήσουν thunks ή
αφήνουν thunks που μπορεί να αποτιμηθούν αργότερα.

\subsection{Πλαίσια}

Η βασική μονάδα από τη μηχανή εκτέλεσης είναι το πλαίσιο. Ένα πλαίσιο περιέχει όλες τις απαραίτητες πληροφορίες
για μια κλήση συνάρτησης. Δεσμεύεται κάθε φορά που πραγματοποιείται μια νέα κλήση συνάρτησης. Τότε, μπορεί να ενημερωθεί σε περίπτωση που περιέχει
μια οκνηρή παράμετρο.

Ακολουθεί ο ορισμός του πλαισίου:
\begin{minted}{haskell}
  type FN      = String 
  type CaseID  = Int 
  type FrameId = Int 

  data Frame   = Frame {
    fName  :: FN,                  -- Function Name
    fArgs  :: [FrameArg],          -- Bindings of formals with actuals
    fSusps :: [(CaseID, Susp)],    -- Data deconstruction forced by `case'
    fPrev  :: FrameId              -- pointer to previous stack frame 
  }
\end{minted}

Ένα πλαίσιο έχει τις ακόλουθες πληροφορίες κατά τη διάρκεια της ζωής του:
\begin{itemize}
  \item Το όνομα της συνάρτησης (\textit{FN}). Αυτή η πληροφορία είναι σημαντική για την αναζήτηση του ορισμού της συνάρτησης στη δομή
  \textit{functions map}, μια δομή που θα εξηγηθεί αργότερα, για να προχωρήσει η εκτέλεση του προγράμματος.
  \item Οι πραγματικές παράμετροι που συνδέονται με τις τυπικές παραμέτρους του ορισμού της συνάρτησης \textit{`FN'}.
  \item Πληροφορίες για τα suspensions, δημιουργία thunk και αποτίμηση που επιβάλλεται από την `case'. Κάθε \textit{`CaseID'}, 
  είναι μοναδικό στο σώμα της συνάρτησης και περιέχει δείκτες στα δικά του thunks.
  \item Ένα δείκτη με τη μορφή αναγνωριστικόυ στο προηγούμενο πλαίσιο (\textit{fPrev}). Αυτό είναι το \textit{περιβάλλον} στην υλοποίηση του 
  διερμηνέα, το οποίο υπονοείται και δεν υπάρχει ρητά στο \textit{state} του.
\end{itemize} 

Ένα όρισμα που ζει στα `fArg :: [FrameArg]', έχει τον ακόλουθο ορισμό:
\begin{minted}{haskell}
  data FrameArg = 
    StrictArg { val :: Value }
  | ByNameArg { expr :: Expr }
  | LazyArg   { expr :: Expr, isEvaluated :: Bool, cachedVal :: Maybe Value }  
\end{minted}

Ένα όρισμα μπορεί να είναι:
\begin{itemize}
  \item Αυστηρό και να περιέχει μόνο μια \textit{τιμή}.
  \item Σε σημασιολογία της κλήσης κατ΄ όνομα και έτσι να περιέχει μόνο μια έκφραση, ένα thunk χωρίς επιλογή για
  απομνημόνευση.
  \item Lazy και έτσι να περιέχει μια έκφραση, με τον ίδιο τρόπο όπως τα ορίσματα call-by-name, 
  αλλά επίσης και μια \textit{σημαία}(flag) για το αν είναι αποτιμημένο ή όχι (εξασφαλίζοντας έτσι την ιδιότητα της αποτίμησης άπαξ, ή στα αγγλικά \textit{single evaluation property}) 
  και επίσης χώρο για την αποθηκευμλενη του τιμή (\textit{cached value}).
\end{itemize}

\section{Διερμηνέας}

Ο διερμηνέας είναι μια συνάρτηση που λαμβάνει ένα \textit{expression}, έναν \textit{στατικό} χώρο μνήμης ενός προγράμματος που περιέχει
πληροφορίες σχετικά με τους ορισμούς συναρτήσεων και ένα \textit{state}, και 
φτάνει σε ένα \textit{τελικό state} και \textit{επιστρέφει μια τιμή}, όπου είναι μια έκφραση από τις εκφράσεις της σύνταξης
που παρουσιάζεται σε προηγούμενη ενότητα. Ο ορισμός του \textit{state} ακολουθεί αργότερα στην ενότητα.

Από εδώ και πέρα, η συνάρτηση $\mathit{eval}$ αντιστοιχεί στη λειτουργία του διερμηνέα. Η δήλωση του \textit{eval}
η λειτουργία εμφανίζεται στο σχήμα~\ref{fig:evalEL}:
\begin{figure}[h]
  $
    \mathit{eval} :: \mathit{Expr} \times \mathit{FunctionsMap} \times \mathit{State} \rightarrow 
    \mathit{State} \times \mathit{Value}
  $
\caption{Δήλωση της συνάρτησης \textit{eval}\label{fig:evalEL}}
\end{figure}

\begin{figure}[t]
$
  \mathit{State :: (Mem, FrameId, NRFrames)}
$
\caption{Κατάσταση (state) του διερμηνέα\label{fig:stateEL}}
\end{figure} 

To \textit{State} της \textit{eval} φαίνεται στο σχήμα~\ref{fig:stateEL},
όπου οι ορισμοί για \textit{Mem}, \textit{FrameId} δίνονται νωρίτερα στο κεφάλαιο. Το πεδίο \textit{NRFrames}
δίνει τον αριθμό από τα πλαίσια που δεσμεύτηκαν έως τώρα. 

H δομή \textit{FunctionsMap} είναι μια δομή που δημιουργείται κατά το χρόνο μεταγλώττισης και παραμένει ζωντανή στο χρόνο εκτέλεσης. 
Δεν αλλάζει κατά την εκτέλεση του προγράμματος και αποτελείται από ζευγάρια κλειδιού-τιμής, όπου:
\begin{itemize} 
  \item Τα κλειδιά είναι τα ονόματα από τις top-level συναρτήσεις.
  \item Οι τιμές είναι ένα ζεύγος τυπικών παραμέτρων με τις στατικές τους πληροφορίες (είδος αποτίμησης, τύπος)
  της συνάρτησης καθώς και το σώματ της συνάρτησης.
\end{itemize}

Ο ορισμός δίνεται στο σχήμα~\ref{fig:functionsmapel}:
\begin{figure}[h]
\begin{minted}{haskell}
  type FN = String 
  data FunctionsMap = Map FN ([Formal], Expr)
\end{minted}
\caption{FunctionsMap\label{fig:functionsmapel}}
\end{figure}

Το αποτέλεσμα του διερμηνέα είναι το αποτέλεσμα της εκτέλεσης του σώματος της συνάρτησης κορυφαίου επιπέδου \textit{main}.
Αυτή η συνάρτηση είναι μια ειδική περίπτωση συνάρτησης και θεωρείται ότι δεν έχει κανένα όρισμα. Έτσι, η αρχική έκφραση
\textit{expr0} είναι: 
\begin{minted}{haskell}
  (_, expr0) = Map.lookup "main" functionsMap
\end{minted}

Το \textit{αρχικό state} του διερμηνέα είναι:
\begin{figure}[h]
$ 
  \mathit{State0 = (mem0, frameId0, nr\_frames0) }
$
\caption{Αρχικό state του διερμηνέα\label{fig:state0el}}
\end{figure}

Στο αρχικό state, που φαίνεται στο σχήμα~\ref{fig:state0el}, έχουμε:
\begin{itemize}
  \item Το αρχικό state της μνήμης \textit{mem0}, είναι:
    \begin{minted}{haskell}
      -- cTOPFRAMED: last frame id available when execution starts
      mem0   = push (Mem Map.empty 0) frame0 
      frame0 = Frame "main" [] [] cTOPFRAMEID 
    \end{minted}
  \item Το αρχικό id από το πρώτο frame στη μνήμη που είναι ελεύθερο:
    \begin{minted}{haskell}
      frameId0 = lastFrameId mem0
    \end{minted}
  \item Ο αρχικός αριθμός πλαισίων που έχουν δεσμευτεί, πριν ξεκινήσει η εκτέλεση της eval, είναι:
    \begin{minted}{haskell}
      nr_frames = 1
    \end{minted}
  καθώς έχουμε \textit{μια} δέσμευση πλαισίου για τη συνάρτηση "main".
\end{itemize}

Σε αυτό το σημείο, έχουμε τα πάντα έτοιμα. Δηλώσαμε τη συνάρτηση του διερμηνέα \textit{eval} και έχουμε μια αρχική
να ξεκινήσει η εκτίμησή μας με. Τώρα, ας δούμε την εκτέλεση κάθε έκφρασης του δένδρου σύνταξης της γλώσσας μας
που παρουσιάζεται στην ενότητα της σύνταξης. Οι μικρές λεπτομέρειες εφαρμογής παραλείπονται για λόγους σαφήνειας. Αρχικά υποθέτουμε παντού την οκνηρότητα,
ενώ αργότερα θα υπάρχει μια επισκόπηση του τρόπου με τον οποίο ο διερμηνέας εκτελείται παρουσία λιστών ML.

Η δομή \textit{FunctionsMap} επίσης παραλείπεται ως όρισμα της eval. Υποθέτουμε ότι ψάχνουμε αυτό για τα τυπικές παραμέτρους και όταν θέλουμε να μεταβούμε στο σώμα μιας συνάρτησης, π.χ. στην 
κλήση συναρήσεων.

Σε κάθε βήμα εκτέλεσης η \textit{eval} αναζητά την τρέχουσα κατάσταση. Όπως έχουμε ήδη αναφέρει το state είναι
ένα πεδίο με~\cite{Abel13}:

\begin{minted}{haskell}
  State = (Mem, FrameId, NRFrames) 
  -- FrameId: id of the current frame
\end{minted}
, και έτσι κοιτάζοντας το frame του τρέχοντος state, παίρνουμε το τρέχον περιβάλλον, έχουμε:
\begin{minted}{haskell}
  thisFrame = getFrame mem frameId 
  Frame caller funArgs susps prevFrameId = thisFrame 
\end{minted}

Με αυτόν τον τρόπο, έχουμε πληροφορίες για:
\begin{itemize}
  \item \textit{caller}: το όνομα της συνάρτησης που καλεί και είμαστε τώρα μέσα στο σώμα της,
  \item \textit{funArgs}: τα τρέχοντα ορίσματα της τρέχουσας συνάρτησης που είναι κατασκευασμένα στο πλαίσιο (δείτε αργότερα πώς τα χτίζουμε
  όταν γίνεται κλήση συνάρτησης),
  \item \textit{susps}: προσωρινά σταματημένες εκτέλεσεις για δεδομένα που η εκτέλεσή τους επιβάλλεται από το pattern matching του case, 
  \item \textit{prevFrameId}: Το αναγνωριστικό από το προηγούμενο πλαίσιο, σαν να είχαμε ένα δείκτη στο προηγούμενο πλαίσιο.
\end{itemize}

Αφού αποκτηθούν οι απαραίτητες πληροφορίες από την τρέχουσα κατάσταση, ο διερμηνέας χειρίζεται κάθε μια από τις εκφράσεις
με τον ακόλουθο τρόπο, που παρουσιάζεται στις επόμενες ενότητες.

\subsection{Αποτίμηση μεταβλητής}

Υπενθυμίζουμε σε αυτό το σημείο ότι μια μεταβλητή δεσμευμένη στην αντιστοίχιση μοτίβων δεν αξιολογείται εδώ 
λόγω του μετασχηματισμού της σε constructor projection που περιγράψαμε προηγουμένως, και επομένως σε αυτό το τμήμα μελετάμε 
την αποτίμηση μεταβλητών που είναι δεμένες με τις τυπικές παραμέτρους μιας συνάρτησης.

Μια μεταβλητή ανώτατου επιπέδου υπάρχει στις τυπικές παραμέτρους ενός ορισμού συνάρτησης. Στους όρους \textit{πλαισίου},
ψάχνουμε για το σωστό \textit{FrameArg} στο πεδίο \textit{funArgs}, που αναφέρθηκε προηγουμένως όταν εξηγήσαμε
την \textit{τρέχουσα κατάσταση} του διερμηνέα.

Η διαδικασία είναι η ακόλουθη:
\begin{itemize}
  \item Πρώτον, βρίσκουμε τη θέση της μεταβλητής στο τρέχον frame.
  \begin{itemize}
    \item Ψάχνουμε τη συνάρτηση \textit{που καλεί} στη δομή \textit{FunctionsMap} για να βρόυμε την υπογραφή
    (\textit{signature}) της συνάρτησης.
    \item Άπαξ και βρούμε την υπογραφή, στη συνέχεια βρίσκουμε τη θέση της μεταβλητής στις τυπικές παραμέτρους της συνάρτησης, με χρήση του ονόματός της, 
    δηλ. τον \textit{δείκτη (i)} του ορίσματος.
  \end{itemize} 
  \item Δεδομένου του δείκτη που υπολογίσαμε νωρίτερα, βρίσκουμε το κατάλληλο όρισμα στο τρέχον πλαίσιο.
\end{itemize}

Στη συνέχια έχουμε τρεις περιπτώσεις όσα και τα είδη αποτίμησης.

Σε αυτό το σημείο, δίνουμε τα v' and s' για:
  $ \mathit{eval (v, s) = (v', s')} $

  \begin{itemize}
    \item cbv: Αποτίμηση μεταβλητής για call-by-value 
          μεταβλητές φαίνονται στο σχήμα~\ref{fig:cbv-varLookup-el}.
      \begin{figure}[t]
      \hrule
        \begin{align*}
           & \mathit{(v', s') = (val, s),} \\
           \mathit{where} \\ 
           & \mathit{v = StrictArg \hfill\ val}
        \end{align*}
      \caption{Αποτίμηση μεταβλητής για call-by-value\label{fig:cbv-varLookup-el}}
      \end{figure}
    \item cbn e.o.: Αποτίμηση μεταβλητής για call-by-name
    φαίνεται στο σχήμα~\ref{fig:cbn-varLookup-el}.

    \begin{figure}[t]
      \begin{align*}
        & \mathit{ (v', s') = (val, s), \hfill\ where } \\
        & \mathit{ v = ByNameArg \hfill\ expr, } \\
        & \mathit{(val, s'') = eval \hfill\ expr \hfill\ (mem, prevFrameId, nr\_frames)} \\
      \end{align*}
    \caption{Αποτίμηση μεταβλητής για call-by-name\label{fig:cbn-varLookup-el}}
    \end{figure}      

    \item lazy e.o.: Στο σχήμα~\ref{fig:lazy-varlookup-el}) έχουμε \textit{δυο} υποπεριπτώσεις.
    Αυτές είναι αν το \textit{b} είναι \textit{true} ή \textit{false}, δηλ. ο οκνηρός όρος είναι αποτιμημένος και αποθηκευμένος
    ή μη αποτιμημένος. Στην τελευταία περίπτωση, ο διερμηνέας χρειάζεται να αποτιμήσει τη μεταβλητή και να ενημερώσει το πλαίσιο, όπως φαίνεται και στο σχήμα.

    \begin{figure}[t]
      \[\mathit{v = LazyArg \hfill\ e \hfill\ b \hfill\ val}\]
      
      \begin{itemize}
          \item \textit{b} is \textit{true}: \[ \mathit{(v', s') = (val, s)} \]
          \item \textit{b} is \textit{false}:
            \begin{align*}
                & \mathit{(v', s') = (val', (updFrame \hfill\ mem' \hfill\ frameId \hfill\ frame', frameId, nr\_frames')), where} \\
                & \mathit{(val', (mem', frameId', nr\_frames')) = eval \hfill\ e \hfill\ (mem, prevFrameId, nr\_frames)} \\
                & \mathit{frame'[funArgs] = ( funArgs[i] = LazyArg \hfill\ e \hfill\ true \hfill\ val' )} \\
            \end{align*}
      \end{itemize}
    \caption{Αποτίμηση μεταβλητής για call-by-need\label{fig:lazy-varlookup-el}}
    \hrule
  \end{figure}


 Σημειώνουμε εδώ ότι όταν έχουμε αλλαγή στην κατάσταση της μνήμης, και πιθανή αποτίμηση της έκφρασης π[ροκαλεί τη δημιουργία νέου πλαισίου
 ενημερώνουμε την κατάσταση της μνήμης και το μετρητή των πλαισίων.

  \end{itemize}


  \subsection{Κλήση συνάρτησης}

  Σε αυτή την ενότητα, περιγράφεται η λειτουργία του διερμηνέα για κλήση συνάρτησης, όπου η έκφραση είναι:
  $ \mathit{Expr = Call \hfill\ callee \hfill\ actuals,} $
  όπου έχουμε τις πληροφορίες για το όνομα της συνάρτησης \textit{που καλείται} και τις πραγματικές παραμέτρους της κλήσης.
  
  \begin{figure}[htp]
    \[ \mathit{makeArgs :: [Actual] \times [Formal] \times State \rightarrow [FrameArg] \times State}, \]
  \caption{Δήλωση της συνάρτησης κατασκευής ορισμάτων\label{fig:makeArgs-el}}
  \end{figure} ~
  \begin{figure}[htp]
    \begin{align*}
      \mathit{(v, state') = eval \hfill\ actual \hfill\ state} \\
      \mathit{frameArg = StrictArg \hfill\ v}
    \end{align*}
  \caption{Κατασκευή call-by-value ορίσματος στο πλαίσιο\label{fig:makeCBVArg-el}}
  \end{figure} ~
  \begin{figure}[htp]
    \[ 
      \mathit{frameArg = ByNameArg \hfill\ actual} 
    \] 
  \caption{Κατασκευή call-by-name ορίσματος στο πλαίσιο\label{fig:makeCBNArg-el}}
  \end{figure} ~
  \begin{figure}[htp]
    \[
      \mathit{frameArg = LazyArg \hfill\ actual \hfill\ false \hfill\ empty} 
    \]
  \caption{Κατασκευή οκνηρού ορίσματος στο πλαίσιο\label{fig:lazyArgConstruction-el}}
  \end{figure} ~
  \begin{figure}[htp]
    \begin{align*}
      & \mathit{eval \hfill\ (Call \hfill\ callee \hfill\ actuals, s) = (val, s'''),} \\ \mathit{where} \\
      & \mathit{(formals, funBody) = lookup \hfill\ callee \hfill\ FunctionsMap} \\
      & \mathit{(frameArgs, (mem', \_, nr\_frames')) = makeArgs \hfill\ actuals \hfill\ formals  \hfill\ state} \\
      & \mathit{newFrame = Frame \hfill\ callee \hfill\ frameArgs \hfill\ [] \hfill\ frameId} \\
      & \mathit{mem'' = push \hfill\ mem' \hfill\ newFrame \hfill\ (nr\_frames + 1) \hfill\ frameId} \\
      & \mathit{s' = (mem'', lastFrameId \hfill\ mem'', nr\_frames + 1)} \\
      & \mathit{(val, s'') = eval \hfill\ funBody \hfill\ s'} \\
      & \mathit{(s'' = (mem''', _, nr\_frames''))} \\
      & \mathit{s''' = (mem''', frameId, nr\_frames'')}
    \end{align*}
  \caption{Λειτουργική σημασιολογία για την κλήση συνάρτησης\label{fig:functionCall-el}}
  \end{figure}
  
  % \pagebreak
  
Πρώτον, θα παρουσιάσουμε μια συνάρτηση για την κατασκευή των επιχειρημάτων, λαμβάνοντας υπόψη τις πραγματικές παραμέτρους της κλήσης
και τις τυπικές παραμέτρους του ορισμού της συνάρτησης που βρίσκεται στη δομή \textit{FunctionsMap}.

  
Η συνάρτηση, που ονομάζεται \textit{makeArgs} έχει τη μορφή, που φαίνεται στο σχήμα~\ref{fig:makeArgs-el},
όπου οι πραγματικοί και οι τυπικοί παράμετροι εξηγούνται παραπάνω και το \textit{State} αναπαριστά την τρέχουσα κατάσταση του διερμηνέα.

Για κάθε πραγματική που αντιστοιχεί σε κάθε επίσημη παράμετρο, έχουμε τα ακόλουθα, ανάλογα
αν η παράμετρος είναι σε cbv, cbn ή lazy:
\begin{itemize}
\item cbv: Όπως φαίνεται στο σχήμα~\ref{fig:makeCBVArg-el} η συνάρτηση επιστρέφει \textit{(frameArg, state')}, όπου το
\textit{frameArg} προστίθεται στο \textit{[FrameArg]} και το \textit{state'} είναι η είσοδος στο όρισμα state της συνάρτησης
\textit{makeArgs}.
\item cbn: Όπως φαίνεται στο σχήμα~\ref{fig:makeCBNArg-el}, το state παραμένει αμετάβλητη και έτσι το  
\textit{(frameArg, state)} επιστρέφεται.
\item lazy: Όπως φαίνεται στο σχήμα~\ref{fig:lazyArgConstruction-el} το state δεν αλλάζει, με αποτέλεσμα  
να επιστρέφεται το \textit{(frameArg, state)}.
\end{itemize}
  
Όπως φαίνεται παραπάνω, μόνο τα επιχειρήματα cbv εκτελούνται σε αυτό το σημείο και η αλλαγή μνήμης που προκαλούν,
επιστρέφεται στην κατάσταση της συνάρτησης \textit{eval}.

Τώρα, είναι καιρός να ξαναρχίσουμε την παρουσίαση σχετικά με την κλήση λειτουργίας στον διερμηνέα.
Η λειτουργική σημασία μιας κλήσης λειτουργίας εμφανίζεται στο σχήμα~\ref{fig:functionCall-el}.
Κάθε φορά που έχουμε μια κλήση συνάρτησης, ένα νέο πλαίσιο δεσμεύεται στη μνήμη. Τότε, ο διερμηνέας
αποτιμά το σώμα της συνάρτησης και τελικά επαναρυθμίζουμε το περιβάλλον για την επόμενη λειτουργία που
χειρίζεται ο διερμηνέας. 

%
\subsection{Ταίριασμα προτύπων}

Όπως έχει ήδη αναφερθεί, διαχωρίζουμε μεταξύ pattern matching σε ακεραίους και pattern matching σε δεδομένα.
Μια διακλάδωση (branch) στο pattern matching είναι:
\begin{minted}{haskell}
  type Branch  = (Pattern, Expr)
  data Pattern = CPat { tag :: CN, vars :: [VN] } -- pattern matching on constructors 
               | IPat { pattVal :: Int }          -- pattern matching on integers 
\end{minted}

\begin{figure}[htp]
  \begin{align*}
    \mathit{caseExpr = Case \hfill\ caseId \hfill\ e \hfill\ branches}
  \end{align*}
\caption{Η έκφραση case\label{fig:case-el}}
\end{figure} ~
\begin{figure}[htp]
  % \hrule
  \begin{align*}
    &  \mathit{eval \hfill\ (e, s) = (e', s'),}  \\
    \mathit{where} \\
    &  \mathit{s' = (mem', savedFrameId, n), \hfill\ and} \\
    &  \mathit{e' = VI \hfill\ i, \hfill\ integer \hfill\ pattern \hfill\ matching, or} \\
    &  \mathit{e' = VC \hfill\ c, \hfill\ constructor \hfill\ pattern \hfill\ matching} \\
    &  \mathit{c = Susp \hfill\ (cn, \_) \hfill\ \_}  
  \end{align*}
\caption{Αποτίμηση του όρου που εξετάζεται\label{fig:scrueval-el}}
\end{figure} ~
\begin{figure}[htp]
  \begin{align*}
    & \mathit{eval \hfill\ (caseExpr, s) = (eval \hfill\ e'' \hfill\ s', s'),} \\
    \mathit{where} \\
    & \mathit{e'' = lookup \hfill\ (IPat \hfill\ i) \hfill\ cases} \\
    % \mathit{, and} \\
    & \mathit{\textit{s'} \hfill\ is \hfill\ the \hfill\ state \hfill\ after \hfill\ scrutinee's 
    \hfill\ evaluation.}
  \end{align*}
\caption{Λειτουργική σημασιολογία για pattern matching σε ακεραίους\label{fig:intPattMatch-el}}
\end{figure} ~
\begin{figure}[htp]
  \begin{align*}
    & \mathit{eval \hfill\ (caseExpr, s) = (eval \hfill\ e'' \hfill\ s'', s''), } \\ 
    \mathit{where} \\
    & \mathit{pattIndex = indexOfPattern \hfill\ cn \hfill\ patterns} \\
    & \mathit{(\_, e'') = branches \hfill\ [pattIndex]} \\
    & \mathit{susps' = (caseId, c) \hfill\ : \hfill\ susps} \\
    & \mathit{frame' = Frame \hfill\ caller \hfill\ funArgs \hfill\ susps' \hfill\ prevFrameId} \\
    & \mathit{s'' = (updFrame \hfill\ mem' \hfill\ frameId \hfill\ frame', \hfill\ frameId, \hfill\ n)}
  \end{align*}
\caption{Λειτουργική σημασιολογία για pattern matching σε κατασκευαστές δεδομένων\label{fig:consPattMatch-el}}
% \hrule
\end{figure}



Η σύνταξη της έκφρασης `case' φαίνεται στο σχήμα~\ref{fig:case-el}. Για την αποτίμηση της έκφρασης αυτής,
ο διερμηνέας κάνει τα επόμενα βήματα:~
\begin{itemize}
  \item Πρώτα, αποτιμά τον όρο που εξετάζεται (scrutinee), η αποτίμηση του οποίου φαίνεται στο σχήμα~\ref{fig:scrueval-el}.
  \item Στη συνέχεια, στο σχήμα~\ref{fig:intPattMatch-el}, φαίνεται πώς συμπεριφέρεται ο διερμηνέας για pattern matching πάνω σε ακεραίους.
  \item Τέλος, το pattern matching πάνω σε κατασκευαστές δεδομένων φαίνεται στο σχήμα~\ref{fig:consPattMatch-el}.
\end{itemize}


Στους παραπάνω ορισμούς, η \textit{indexOfPatterns} δίνει σαν έξοδο το δείκτη 
στη λίστα των διακλαδώσεων, για να γνωρίζει ο διερμηνέας ποια θα είναι η επόμενη έκφραση που θα αποτιμήσει.

Σημειώνουμε, σε αυτό το σημείο ότι, παρόλο που η υλοποίηση μας δουλεύει με λίστες, αντίστοιχα η λειτουργία μπορεί να γενικευτεί 
για οπποιοδήποτε κατασκευαστή δεδομένων, καθώς αυτοί είναι επί της ουσίας συναρτήσεις. Το τελευταίο είναι προφανές αν αναλογιστούμε ότι δουλεύουμε σε μια 
συναρτησιακή γλώσσα, όπου οι συναρτήσεις είναι πολίτες πρώτης κατηγορίας.


\subsection{Εφαρμογή κατασκευαστή δεδομένων}

Στην περίπτωση που έχει εφαρμογή ενός \textit{lazy κατασκευαστή δεδομένων} (lazy data constructor),
αυτό είναι ισοδύναμο με την δέσμευση μνήμης ενός thunk. Στην περίπτωσή μας, αυτό είναι μια δέσμευση ενός 
suspension, όπως εξηγήθηκε προηγουμένως.
Πιο συγκεκριμένα, η \textit{eval} για μια εφαρμογή όρου σε lazy data constructor φαίνεται στο 
σχήμα~\ref{fig:consAppl-el}.

\begin{figure}[h]
  \begin{align*}
    & \mathit{eval \hfill\ (ConstrF \hfill\ tag \hfill\ exprs, s) = (VC \hfill\ (Susp \hfill\ (tag, exprs) \hfill\ frameId), s)} \\
    \mathit{, where} \\
    &  \mathit{\textit{frameId}: \hfill\ the \hfill\ id \hfill\ of \hfill\ the 
    \hfill\ current \hfill\ frame \hfill\ existing \hfill\ in \hfill\ the \hfill\ interpeter's 
    \hfill\ state,} \\
    &  \mathit{\textit{tag}: \hfill\ the \hfill\ name \hfill\ of \hfill\ the \hfill\ 
    constructor.}
  \end{align*}
\caption{Λειτουργική σημασιολογία για εφαρμογή οκνηρών κατασκευαστών\label{fig:consAppl-el}}
\end{figure} ~
% \begin{figure}[h]
%   \begin{align*}
%     & \mathit{eval~(SHConstrF~tag~(e~:~es), s) = (VC~(Susp~(tag, (e'~:~es))~frameId), s')} \\
%     & \mathit{(e',s') = eval~(e, s)}
%   \end{align*}
% \caption{Strict head list constructor application\label{fig:shconsAppl}}
% \end{figure} ~
% \begin{figure}[h]
%   \begin{align*}
%     & \mathit{eval~(STConstrF~tag~(e~:~es), s) = (VC~(Susp~(tag, (e~:~es'))~frameId), s')} \\
%     & \mathit{(es',s') = eval~(es, s)}
%   \end{align*}
% \caption{Strict tail list constructor application\label{fig:stconsAppl}}
% \end{figure} ~
% \begin{figure}[h]
%   \begin{align*}
%     & \mathit{eval~(MLConstrF~tag~(e~:~es), s) = (VC~(Susp~(tag, (e'~:~es'))~frameId), s'')} \\
%     & \mathit{(e',s') = eval~(e, s)} \\
%     & \mathit{(es', s'') = eval~(es, s')}
%   \end{align*}
% \caption{ML-list constructor application\label{fig:mlconsAppl}}
% \end{figure}

% \newpage

\subsection{Προβολές κατασκευαστών}

Σε αυτήν την περίπτωση, ο διερμηνέας έχει συναντήσει μια μεταβλητή που δεσμεύεται από
pattern matching. Όπως αναφέρθηκε προηγουμένως, η αποτίμηση 
ενός όρου αναγκάζεται, όταν πρέπει να αποτιμηθούν τέτοιες μεταβλητές.
Η λειτουργία της \textit{eval} για την \textit{προβολή κατασκευαστή} εμφανίζεται στο
σχήμα~\ref{fig:consproj-el}.

\begin{figure}[htp]
  \begin{align*}
    & \mathit{eval \hfill\ (CProj \hfill\ caseId \hfill\ cpos, s) = (val, s'),} \\
    \mathit{where } \\
    & \mathit{s' = mem' \hfill\ frameId \hfill\ nr\_frames'} \\
    & \mathit{susp = lookup \hfill\ cid \hfill\ susps} \\
    & \mathit{Susp \hfill\ (\_, el) \hfill\ savedFrameId = susp} \\
    & \mathit{e' = el[cpos]} \\
    & \mathit{(val, (mem', \_, nr\_frames')) = eval \hfill\ (e', s)}
  \end{align*}
\caption{Λειτουργική σημασιολογία για την προβολή κατασκευαστή\label{fig:consproj-el}}
\end{figure}

Πρώτον, βρίσκουμε το κατάλληλο $\mathit{susp}$ μέσα στο πεδίο $\mathit{susps}$ του τρέχοντος πλαισίου. Στη συνέχεια, 
από τη λίστα εκφράσεων $\mathit{el}$ βρίσκουμε τον κατάλληλοο κατασκευαστή στη θέση $\mathit{cpos}$ . 
Μετά την αποτίμηση της έκφρασης έχουμε την τιμή-αποτέλεσμα και το επόμενο state του διερμηνέα μας.

%

\chapter{Ανάλυση: Σε αναζήτηση ευκαιριών βελτιστοποίησης}
\label{ch:analysis-gr}

Σε αυτό το κεφάλαιο, παρουσιάζουμε την ανάλυση που εκτελείται προκειμένου να αποκαλυφθούν οι πραγματικές θέσεις κλήσης ουράς.
Πρώτον, κάνουμε ορισμένους σημαντικούς ορισμούς υψηλού επιπέδου για να μπορέσει ο αναγνώστης να παρακολουθήσει τις επόμενες ενότητες.

Η είσοδος της στατικής ανάλυσης μας είναι η γλώσσα πυρήνα πρώτης τάξης, που έχει δοθεί στο αντίστοιχο 
κεφάλαιο, μαζί με τη λειτουργική σημασιολογία που παρουσιάστηκε στο προηγούμενο κεφάλαιο.
Η έξοδος είναι κατάλληλα επισημειωμένες κλήσεις συναρτήσεων, όπου ο εμπλουτισμένος διερμηνέας του επόμενου κεφαλαίου θα διαχειριστεί κατάλληλα.
Η ανάλυση που παρουσιάζεται σε αυτό το κεφάλαιο αποκαλύπτει που θα εφαρμοστεί η βελτιστοποίηση, ενώ στο επόμενο κεφάλαιο θα παρουσιαστεί η λειτουργία 
κατά το χρόνο εκτέλεσης.



% Analysis chapter 

\section{Κλασική βελτιστοποίηση κλήσεων ουράς}

Στο σημείο αυτό, αρχικά δίνουμε δυο ορισμούς: οφείλουμε να διευκρινήσουμε ότι ο όρος κλήσεις ουράς δεν είναι ο ίδιος με 
τον όρο βελτιστοποιήσιμες κλήσεις ουράς. Ενώ οι δυο αυτοί όροι ταυτίζονται σε μια γλώσσα προγραμματισμού με αυστηρή σημασιολογία,
αυτό δεν συμβαίνει σε μια γλώσσα υπό την παρουσία της οκνηρής αποτίμησης.

\subsection{Ορισμοί}

\paragraph{Ορισμός 4.1}
Μια κλήση συνάρτησης είναι σε \textit{θέση κλήσης ουράς}, ή είναι \textit{κλήση ουράς}, \textit{αν και μόνο αν} η εκτέλεσή της πραγματοποιείται ακριβώς πριν επιστρέψει 
η καλούσα συνάρτηση.

\paragraph{Ορισμός 4.2}
Μια κλήση ουράς είναι \textit{βελτιστοποιήσιμη}, ή είναι \textit{πραγματική κλήση ουράς}, \textit{αν και μόνο αν} αυτή είναι σε θέση κλήσης ουράς (ορισμός 4.1) και ικανοποιεί τους κανόνες που παρουσιάζονται 
στην ενότητα~\ref{sec:data-driven-analysis-el}.

Στις επόμενες ενότητες, παρουσιάζουμε τη διαδρομή από τις \textit{κλήσεις συναρτήσεων}, που υπάρχουν στη γλώσσα πυρήνα μας, στις \textit{θέσεις κλήσεων ουράς}, 
και από εκεί στις \textit{βελτιστοποιήσιμες κλήσεις ουράς}. Οι τελευταίες επισημειώνονται από την ανάλυσή μας στη γλώσσα πυρήνα, 
και συγκεκριμένα με την επισημείωση \textit{TailCall}. Όταν ο διερμηνέας μας συναντά αυτές τις εκφράσεις, πραγματοποιεί τη βελτιστοποίηση κατά το χρόνο εκτέλεσης.

\subsection{Αναλυση ροής ελέγχου προγράμματος: Εντοπίζοντας τις κλήσεις ουράς}
\label{sec:control-flow-el}

Για μια γλώσσα προγραμματισμού με αυστηρή σημασιολογία, αυτό το βήμα είναι ακριβώς ό,τι χρειάζεται: φανερώνει τις κλήσεις ουράς, οι οποίες είναι όλες βελτιστοποιήσιμες. 
Αντίθετα, σε μια γλώσσα με πολλαπλά είδη αποτιμήσεων, και ειδικά με την παρουσία οκνηρής αποτίμησης, αυτό δεν είναι αρκετό, καθώς η αποτίμηση των οκνηρών όρων δε γνωρίζουμε πότε θα 
αποτιμηθεί, με αποτέλεσμα να δραπετεύουν από τη στατική τους εμβέλεια.  

Πρόκειται για μια τοπική ανάλυση, η οπία πραγματοποιείται στο σώμα μιας συνάρτησης. Η ανάλυση συνοψίζεται στους παρακάτω κανόνες:
\begin{itemize}
  \item Το σώμα μιας συνάρτησης είναι κλήση ουράς.
  \item Όταν μια if/case έκφραση είναι κλήση ουράς, τότε οι διακλαδώσεις τους είναι επίσης κλήσεις ουράς.
  Στην περίπτωση ενός `if' για παράδειγμα, τα then/else είναι σε θέσεις κλήσεων ουράς.
  \item Τίποτα άλλο δεν είναι σε θέση κλήσεων ουράς.
\end{itemize}

Για να γίνει πιο σαφές το παραπάνω, χρησιμοποιούμε το εξής παράδειγμα:
\begin{minted}{haskell}
  foo n = 
    if n > 0  
      then n * foo (n-1) 
      else 1
\end{minted}

Το σώμα της συνάρτησης `foo' είναι tail call. Αυτό σημαίνει ότι το `if', που είναι η πιο πάνω έκφραση στο σώμα της συνάρτησης, είναι σε θέση κλήσης ουράς.
Έτσι, τα then/else είναι κλήσεις ουράς. Στη `then' πρόταση όμως, όπου πραγματοποιείται ένας πολλαπλασιασμός, η κλήση στη `foo' δεν είναι σε θέση κλ'ησης ουράς, 
σύμφωνα με τον τρίτο κανόνα.

Αλλά αν είχαμε το επόμενο πρόγραμμα:
\begin{minted}{haskell}
  foo n res = 
    if n > 0 
      then foo (n - 1) (n * res)
      else res
\end{minted}
τότε η κλήση της συνάρτησης στη then πρόταση είναι σε θέση κλήσης ουράς, καθώς το then ειναι σε θέση κλήσης ουράς.

\subsection{Ανάλυση οδηγούμενη από τα δεδομένα: Βελτιστοποιήσιμες κλήσεις ουράς}
\label{sec:data-driven-analysis-el}


Μετά την αποκάλυψη των θέσεων κλήσης ουράς, που προκύπτει από τη ροή ελέγχου του προγράμματος, η οποία παρουσιάζεται στην προηγούμενη ενότητα, 
τώρα εφαρμόζουμε ορισμένους κανόνες για να αποκαλυφθούν οι πραγματικά βελτιστοποιήσιμες κλήσεις ουράς, ανάλογα με το είδος αποτίμησης 
που έχουν οι όροι στην καλούσα και καλόυμενη συνάρτηση αντίστοιχα. 
Μετά από όλα, βελτιστοποίηση κλήσης ουράς πρόκειται για το πέρασμα του ελέγχου από τον καλούντα στον καλούμενο. 
Αυτό το βήμα παραλείπεται στις γλώσσες που χρησιμοποιούν την κλήση κατ' αξία, όπου υπάρχει
μόνο ένα είδος αποτίμησης, το οπίο επιτρέπει τη βελτιστοποίηση εντελώς απροβλημάτιστα.

Παρόλο που φαίνεται ότι οι κανόνες εφαρμόζονται σε ένα δεύτερο πέρασμα ανάλυσης, αυτό γίνεται για λόγους σαφήνειας
στο κείμενο. Στην πραγματικότητα μπορούμε να το κάνουμε αυτό σε ένα πέρασμα, σε μια ενιαία ανάλυση, ακριβώς μόλις η 
ανάλυση ροής ελέγχου αποφασίσει, αν η κλήση που μελετάται είναι κλήση ουράς.


Οι κανόνες για ένα πιθανό tail-call, που αποκαλύφθηκε από την ανάλυση της προηγούμενης υποενότητας, 
για να είναι βελτιστοποιήσιμο tail-call είναι:
\begin{itemize}
  \item Οι πραγματικές παράμετροι στην κλήση δεν εξαρτώνται από τις τυπικές παραμέτρους του της καλούσας συνάρτησης. 
  Για παράδειγμα, αυτές οι πραγματικές παράμετροι μπορεί να είναι σταθερές. 
  \item Οι πραγματικές παράμετροι στην κλήση είναι μεταβλητές. Εάν είναι μεταβλητές μπορούμε
  προβλέψουμε στατικά αν και πότε θα είναι δυνατή η μετάλλαξη του πλαισίου κατά τη διάρκεια εκτέλεσης. 
  Ο αναγνώστης μπορεί επίσης να αναφερθεί στο σχήμα~\ref{fig:mutate-el} για τις πιθανές περιπτώσεις. 
  Πραγματοποιούμε τη βελτιστοποίηση σχεδόν σε όλες τις περιπτώσεις, εκτός από δυο υποπεριπτώσεις.
  \item Η πραγματική παράμετρος είναι μια έκφραση, αλλά είναι σε θέση κλήσης κατ' αξία. Σε αυτή την περίπτωση, υπάρχουν
  δύο υποπεριπτώσεις:
    \begin{itemize}
      \item Η έκφραση έχει βασικό τύπο (π.χ. ακέραιο). Αυτή είναι η ευκολότερη υποπερίπτωση, καθώς αυτές οι εκφράσεις,
      όταν αποτιμώνται, αποτιμώνται απευθείας σε τιμή βασικού τύπου, χωρίς να αφήνουν thunks που δεν έχουν αποτιμηθεί.
      Σε αυτήν την περίπτωση, θα μπορούσαμε επίσης να έχουμε δεδομένα όπως οι λίστες της ML, τα οποία 
      επίσης αποτιμώνται σε βάθος.
      \item Η έκφραση είναι κατασκευασμένα δεδομένα. Σε αυτή την περίπτωση, βρίσκουμε όλες τις μεταβλητές μέσα στην
      έκφραση. Εάν αυτές οι μεταβλητές αποτιμώνται απευθείας σε τιμή, χωρίς να αφήνουν thunks, (τιμές με τύπο βάσης ή βαθιά αποτιμημένα
      δεδομένα), τότε αυτή η κλήση συνάρτησης είναι βελτιστοποιήσιμη κλήση ουράς.
      \item Οι κλήσεις ουράς που δεν υπόκεινται στους παραπάνω κανόνες δεν είναι βελτιστοποιήσιμες.
    \end{itemize}
\end{itemize}



%
\chapter {Υλοποίηση βελτιστοποίησης κλήσεων ουράς στο χρόνο εκτέλεσης}

In this chapter, we will present how the optimisations are implemented in the interpreter.
More specifically, we will present how \textit{eval} operates, when a tail call has come up (figure~\ref{fig:annos-el}).
\begin{figure}[h]
$\mathit{eval \hfill\ (e, s) = (e', s'), }$ \\
$\mathit{\hfill\ \hfill\ where \hfill\ e = TailCall \hfill\ callee \hfill\ actuals}$
\caption{Επισημειωμένες εκφράσεις\label{fig:annos-el}}
\end{figure}


\section {Λειτουργία για την κλασική βελτιστοποίηση κλήσεων ουράς}

Classic tail call evaluation contains one major \textit{operation}, which makes the optimisation 
feasible: this is \textit{frame mutation}. This operation includes the replacement of the current frame's arguments 
with the arguments necessary for the construction of the frame for the next function call. For this operation,
it is mandatory that the caller's arguments do not escape and for those that escape we correctly passed them 
to the new frame. 

Η κλασική βελτιστοποίηση κλήσης ουράς περιέχει μια κύρια \textit{λειτουργία}, η οποία κάνει τη βελτιστοποίηση
εφικτή: αυτή είναι η \textit{μετάλλαξη πλαισίου}(frame mutation). Αυτή η ενέργεια περιλαμβάνει την αντικατάσταση 
των ορισμάτων τρέχοντος πλαισίου με τα απαραίτητα ορίσματα για την κατασκευή του πλαισίου που αντιπροσωπεύει 
την επόμενη κλήση λειτουργίας. Για αυτή τη λειτουργία, είναι υποχρεωτικό τα ορίσματα του καλούντος να μην 
`δραπετεύσουν' και γι 'αυτά που `δραπετεύουν' να τα μεταβιβάσουμε σωστά στο νέο πλαίσιο.

Η \textit{eval} για το \textit{TailCall} ακολουθεί στο σχήμα~\ref{fig:tco-el}; 
Η λειτουργικότητα του \textit{checkMutate} θα εξηγηθεί αργότερα στην ενότητα. Οι υπόλοιπες μεταβλητές 
που φαίνονται στο σχήμα είναι:
\begin{itemize}
  \item \textit{formals} είναι οι τυπικές παράμετροι του ορισμού της κληθείσας συνάρτησης,
  \item \textit{actuals} είναι οι πραγματικές παράμετροι της κληθείσας συνάρτησης,
  \item \textit{funArgs} είναι τα ορίσματα μέσα στον τρέχον πλαίσιο του καλούντα,
  \item and \textit{s} είναι το τρέχον state του διερμηνέα.
\end{itemize}


\begin{figure}[h]
  \begin{align*}
    & \mathit{eval \hfill\ (TailCall \hfill\ callee \hfill\ actuals, s) = (e', s'),} \\
    \mathit{where} \\
    & \mathit{(formals, funBody) = lookup \hfill\ FunctionsMap \hfill\ callee} \\
    & \mathit{e' = eval \hfill\ (funBody, s')} \\
    & \mathit{s' = checkMutate \hfill\ formals \hfill\ actuals \hfill\ funArgs \hfill\ s} 
  \end{align*}
\caption{Λειτουργική σημασιολογία για βελτιστοποίηση κλήσεων ουράς\label{fig:tco-el}}
\end{figure}


Σε αυτό το σημείο, παρουσιάζουμε τον ορισμό της συνάρτησης \textit{checkMutate}, η οποία 
είναι μια συνάρτηση της οποίας αν της δοθεί το τρέχον state του διερμηνέα εκτελεί τo frame mutation 
και παράγει το επόμενο state του διερμηνέα. Η δήλωση της συνάρτησης δίνεται στο σχήμα~\ref{fig:checkdecl-el} 
και η λειτουργική σημασιολογία της συνάρτησης δίνεται στο σχήμα~\ref{fig:checkMutate-el}.

\begin{figure}[h]
  \begin{align*}
    \mathit{checkMutate :: [Actual] \times [Formal] \times [FrameArg] \times State \rightarrow State} 
  \end{align*}
\caption{Δήλωση της λειτουργίας $\mathit{checkMutate}$\label{fig:checkdecl-el}}
\end{figure}

 

\begin{figure}[h]
  \begin{align*}
    & \mathit{checkMutate \hfill\ (actuals, formals, funArgs, s) = s', } \\
    \mathit{where } \\
    & \mathit{(mem, frameId, nr\_frames) = s} \\
    & \mathit{(callerFormals, \_) = lookup \hfill\ callee \hfill\ FunctionsMap} \\
    & \mathit{(funArgs', s'') = mutate \hfill\ callerFormals \hfill\ formals \hfill\ funArgs \hfill\ actuals \hfill\ s } \\
    & \mathit{(mem', frameId', nr\_frames') = s''} \\
    & \mathit{frame'' = Frame \hfill\ callee \hfill\ funArgs' \hfill\ [] \hfill\ prevFrameId} \\
    & \mathit{s' = (updFrame \hfill\ mem' \hfill\ frameId \hfill\ frame'', frameId, nr\_frames')}
  \end{align*}
\caption{Λειτουργική σημασιολογία για τη λειτουργία \textit{checkMutate}\label{fig:checkMutate-el}}
\end{figure}

Ακολουθεί η περιγραφή της βοηθητικής συνάρτησης \textit{mutate}, η λειτουργική σημασιολογία 
της οποίας φαίνεται στο σχήμα~\ref{fig:mutate-el}.
Από το σχήμα φαίνεται τα παρακάτω για την είσοδο της συνάρτησης. Η συνάρτηση λοιπόν πάιρνει:
\begin{itemize}
  \item Τις επίσημες παραμέτρους της καλούσας,
  \item Τις επίσημες παραμέτρους της κληθείσας,
  \item τα ορίσματα του τρέχοντος πλαισίου,
  \item τις πραγματικές παραμέτρους της κλήσης,
  \item την τρέχουσα κατάσταση του διερμηνέα,
\end{itemize}
και παράγει:
\begin{itemize}
\item Τα επιχειρήματα πλαισίου για το νέο πλαίσιο. Σημειώνουμε εδώ ότι θέλουμε να μετατρέψουμε τις πραγματικές 
παραμέτρους της κλήσης της λειτουργίας στις κατάλληλες παραμέτρους πλαισίου, χρησιμοποιώντας τις υπογραφές λειτουργίας 
του καλούντος και του καλούντος. Συγκεκριμένα, μας ενδιαφέρει η μορφή των επιχειρημάτων και επομένως πρέπει να 
γνωρίζουμε την αξιολόγηση σειρά των λειτουργιών.
\item Η επόμενη κατάσταση για τον διερμηνέα. Επειδή η αξιολόγηση \textit{μπορεί} να πραγματοποιηθεί, 
ενώ αυτή η λειτουργία εκτελείται
(για παράδειγμα, πρέπει να μετατρέψουμε ένα τεμπέριστο επιχείρημα σε αυστηρό και έτσι να κάνουμε την αξιολόγηση πριν
πηδούμε στο σώμα της κλήσης), πρέπει να αλλάξουμε την κατάσταση μνήμης και να μετρήσουμε σωστά τα πλαίσια
για την αξιολόγηση που ακολουθεί στο επόμενο κεφάλαιο.
\end{itemize}

Καθώς η γλώσσα είναι πρώτης τάξης, δεν υποστηρίζει μερικές εφαρμογές όρων, και επομένως ο αριθμός των παραμέτρων
στην λίστα πραγματικών παραμέτρων είναι ίση με τον αριθμό των τυπικών της συνάρτησης του καλούντος. Η συνάρτηση 
\textit{mutate} τερματίζεται όταν οι δύο αυτές λίστες είναι κενές στην ίδια επανάληψη, διαφορετικά `ρίχνει' μια 
εξαίρεση. Η εκτέλεσή της αρχίζει και συνεχίζει μέχρι να τερματίσει επεξεργάζοντας κάθε πραγματική παράμετρο της κλήσης. 
Το αποτέλεσμα είναι μια λίστα που συγκεντρώνει το αποτέλεσμα κάθε επανάληψης. 


\begin{figure}[h]
  $\mathit{getIndex :: VN \times EvaluationOrder \times Type \times [Formal] \rightarrow Index}$ \\
  $\mathit{getIndex~(vn,~eo,~type)~fs=elemIndex~(vn,(eo,type))~fs}$ \\
  \\
  $\mathit{getEvaluationOrder :: Formal \rightarrow EvaluationOrder} $ \\
  $\mathit{getEvaluationOrder :: (\_, (eo, \_)) = eo}$ \\
  \\%
  $\mathit{signOfVar :: [Formal] \times VN \rightarrow EvalutionOrder \times Type } $ \\
  $\mathit{signOfVar~formals~vn = lookup~vn~formals}$ \\
  \\%
  $\mathit{transform :: CallerEO \times CalleeEO \times FrameArg \times 
            State \rightarrow FrameArg \times State}$ \\
  $\mathit{transform~(CBV, CBV, arg, s) = (arg, s)}$ \\
  $\mathit{transform~(CBN, CBN, arg, s) = (arg, s)}$ \\
  $\mathit{transform~(Lazy, Lazy, arg, s) = (arg, s)}$ \\
  $\mathit{transform~(CBV, CBN, ByNameArg~e, s) = (StrictArg~v, s'),}$ \\
  $\mathit{\hfill\ \hfill\ where~(v, s') = eval~(e, s)}$ \\
  $\mathit{transform~(CBV, Lazy, LazyArg~e~b~v, s) = 
              if~b~then~(StrictArg~v, s)~else~(val, s'),}$ \\
  $\mathit{\hfill\ \hfill\ where~(val, s') = eval~(e, s)} $ \\
  $\mathit{transform~(CBN, CBV, StrictArg~(VI~v),s)=(ByNameArg~(EInt~v),s)}$ \\
  $\mathit{transform~(CBN, CBV, StrictArg~(VC~c),s)=error}$ \\
  $\mathit{transform~(CBN, Lazy, LazyArg~e~true~(VI~v), s) = (ByNameArg~(EInt~v), s)}$ \\
  $\mathit{transform~(CBN, Lazy, LazyArg~e~true~(VC~c), s) = error}$ \\
  $\mathit{transform~(CBN, Lazy, LazyArg~e~false~v, s) = (ByNameArg~e, s)}$ \\
  $\mathit{transform~(Lazy, CBV, StrictArg~v, s) = (LazyArg~e~true~v, s)}$ \\
  $\mathit{transform~(Lazy, CBN, ByNameArg~e, s) = (LazyArg~e~false~null, s)}$ \\
  \\%
  $\mathit{mutate :: [Formal] \times [Formal] \times [FrameArg]
            \times [Actual] \times Index \times State \rightarrow [FrameArg] \times State} $ \\
  $\mathit{mutate~(\_,~[],\_,[],\_,~acc,~s)=(acc,~s)}$ \\
  $\mathit{mutate~(callerfs,~calleefs,~args,~(EVar~v~:~as),~ix,~acc,~s)}$ \\
  $\mathit{\hfill\ =~mutate~(callerfs,~calleefs,~args,~as,~(ix+1),(arg'~:~acc), ~s')}$ \\
  $\mathit{\hfill\ \hfill\ where~calleeEO=getEvaluationOrder~calleefs[ix]}$ \\
  $\mathit{\hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ 
            sign@(callerEO, callerType) = signOfVar~(vn, callerfs)}$ \\
  $\mathit{\hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ 
            callerIx = getIndex~(vn, sign)~callerfs}$ \\
  $\mathit{\hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ 
            arg = args[callerIx]}$ \\
  $\mathit{\hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ 
            (arg', s') = mutate~(calleeEO, callerEO, arg, s)}$ \\
  $\mathit{mutate~(callerfs,~calleefs,~args,~(a@(EInt~n)~:~as),~ix,~acc,~s)}$ \\
  $\mathit{\hfill\ =~mutate~(callerfs,~calleefs,~args,~as,~(ix+1),(arg~:~acc), ~s)}$ \\
  $\mathit{\hfill\ \hfill\ where~calleeEO=getEvaluationOrder~calleefs[ix]}$ \\
  $\mathit{\hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ 
      if~calleeEO=CBV~then~StrictArg~(VI~n)~else~if~calleeEO=CBN~then~ByNameArg~a~}$ \\
  $\mathit{\hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ 
           \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ 
           \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ 
           \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\
    else~LazyArg~a~false~null}$ \\
  $\mathit{mutate~(callerfs,~calleefs,~args,~(a~:~as),~ix,~acc,~s)}$ \\ 
  $\mathit{\hfill\ =if~calleeEO=CBV~then~mutate~(callerfs,~calleefs,~args,~as,~(ix+1),(arg'~:~acc), ~s')}$ \\
  $\mathit{\hfill\ \hfill\ where~calleeEO=getEvaluationOrder~calleefs[ix]}$ \\  
  $\mathit{\hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ 
            (v, s') = eval~(a, s)}$ \\
  $\mathit{\hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ 
            arg'=StrictArg~v}$ \\
\caption{Λειτουργική σημασιολογία για τη λειτουργία $\mathit{mutate}$\label{fig:mutate-el}}
\end{figure}

%
\chapter{Επίλογος}

Αυτή η εργασία δείχνει πώς να επεκτείνουμε την κλασική βελτιστοποίηση κλήσης ουράς σε 
γλώσσες με οκνηρή αποτίμηση που υποστηρίζουν πολλαπλά είδη αποτίμησης (όπως π.χ.
κλήση κατ' αξία και κλήση κατ' όνομα). Η εφαρμογή μας είναι ένας
διερμηνέα που χρησιμοποιεί πληροφορίες από μια τοπική στατική ανάλυση, 
προκειμένου να ανιχνευθούν ευκαιρίες βελτιστοποίησης στις θέσεις κλήσεων ουράς.

Η τεχνική μας μπορεί επίσης να υλοποιηθεί σε ενα μεταγλωττιστή για οκνηρές 
γλώσσες που χρησιμοποιεί defunctionalization, όπως ο GIC~\cite{Fourtounis14} ή ο
GRIN~\cite{Boquist96,Podlovics19}.  Αυτή η ενσωμάτωση χρειάζεται ένα μικρό
γεννήτορα κώδικα για μετάλλαξη των πλαισίων για τις τις κλήσεις ουράς,
οδηγούμενη από τις αποφάσεις του διερμηνέα μας. Ένα τέτοιο βήμα είναι 
το προφανές για την υλοποίηση μας. 

Ενσωμάτωση με ένα πιο σύνθετο μεταγλωττιστή θα μπορούσε επίσης να βοηθήσει για να 
αξιολογήσουμε την τεχνική μας με πιο ρεαλιστικά προγράμματα ως αναφορά (benchmarks),
όπως η \emph{nofib} benchmark σουίτα~\cite{nofib}.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\englishtext

\chapter{Introduction}
\label{ch:introduction}

\section {Purpose of the thesis}

The purpose of the thesis is to integrate tail-call optimisation to functional programming languages 
in the presence of multiple evaluation order choices (call-by-value, call-by-name, call-by-need). Our optimisation can be combined with the 
defunctionalization transformation~\cite{Reynolds72definitionalinterpreters}, so that the resulting performance optimisation also supports
higher-order functional languages. 

\section {Motivation}

Tail-call optimisation for strict functional languages is a well-studied topic, but it fails in the 
presence of laziness: the computation of a lazy argument can happen arbitrarily during the execution 
of the program and thus lazy arguments escape their context more easily than strict ones.
On the one hand, laziness gives programmers great options: to use infinite data structures~\cite{Abel13}, 
to define control flow (structures) as abstaractions instead of primitives, to increase performance
by avoiding needless calculations, and to avoid error conditions when evaluating compound expressions.
But this flexibility comes at a cost: too lazy programs can lead to poor performance and even memory leaks.
On the other hand, strictness enables programmers to count performance more easily, but programs can 
fall into undesired behavior, such as divergence.

In this thesis, we get the best of both worlds: our programs need not be too lazy nor too strict,
with evaluation order annotations supporting tail-call optimisation in lazy evaluated 
functional programming languages, thus eliminating memory overhead associated with recursion in the 
same way as in strict functional languages.

\section {Overview of the thesis}

In this thesis, we integrate tail-call optimisation in a functional 
language in the presence of multiple evaluation order choices (strict, lazy, call-by-name semantics). 
Our optimisation supports user-defined data types with pattern matching and thus can be combined with the
defunctionalization transformation, so that higher-order functional languages are also supported. The source language, similar to Haskell, 
is transformed (via defunctionalization) to a low-level, minimal, first-order functional language 
with non-strict semantics, lazy evaluation and lazy structured data as well as strictness 
annotations. To find opportunities for optimisation, we perform a static analysis on the 
low-level functional language, to spot tail-call positions. The difficult part, 
compared with languages with strict semantics, is that lazy semantics makes program values escape 
their context and thus finding tail-call positions is not trivial. This optimisation was evaluated
on an interpreter of the language that explicitly allocates and measures frames, so that on 
tail-call positions found by the analysis, we can properly replace the unnecessary current 
frame's arguments with the arguments needed by the frame that represents the next function call. 
Our optimisation either improves program run-time, or does not change it. Also, in the case of 
strict programs, our optimisation is equivalent to classic tail-call optimisation. In conclusion,
in a non-strict, lazy-evaluated functional language with lazy data constructors and strictness 
annotations, for all benchmarks we use, there is always memory optimisation, and for the majority 
of them there is a significant memory optimisation with performance boost.

\section{Contributions}

Our major contributions, presented in this thesis, are:
\begin{itemize}
  \item We show how tail-call optimisation and tail recursion modulo cons can be applied to a functional programming 
  language with mixed evaluation order. Our key contribution is how it can be applied in 
  the presence of \textit{lazy} evaluation, and thus turning the optimisation to an extension of tail-call optimisation 
  for call-by-value languages.
  \item A prototype implementation of an interpreter with explicit frame allocation, as well as frame counting mechanism,
  for a functional language with call-by-value, call-by-name and call-by-need semantics, lazy data constructors 
  and pattern matching.
  \item A static analysis algorithm to find \textit{true} tail call positions and the implementation of the runtime system 
  for these optimisations embedded in the interpreter.
  \item The evaluation of this optimisation on micro benchmarks shows that it either improves the runtime 
  or does not change it. The evaluation seems to approach in many cases the number of frame allocations in call-by-value languages, 
  which is the best result we can have.
\end{itemize}

An overview of the contents of each chapter follows:
\begin{itemize}
  \item In \textit{Chapter~\ref{ch:background}}, we provide the necessary background for the reader in 
        order to follow the next chapters. We give a comprehensive explanation of classic 
        tail-call optimisation (section~\ref{sec:tco}), an overview of the evaluation order choices we study 
        in this thesis (section~\ref{sec:evaluation-order}), an overview of static analysis (section~\ref{sec:static-analysis}). Finally, 
        in section~\ref{sec:abstract-machines} we give an overview of abstact machines and interpreters, focusing on 
        lazy functional languages.

  \item In \textit{Chapter~\ref{ch:overview}}, we give an overview of the thesis; we provide the intuition 
        for our key ideas presented in the rest of the thesis.

  \item In \textit{Chapter~\ref{ch:language}}, we present the language we studied. Briefly, we describe 
        how from a higher-order functional language and applying the appropriate 
        transformations (sections~\ref{sec:defunctionalization}-\ref{sec:other-transformations}) we can reach the first-order functional 
        language we used for our analysis and evaluation of the optimisation.

  \item In \textit{Chapter~\ref{ch:execution-model}}, we describe the execution model of our language. We present operational 
        properties as well as implementation details.

  \item In \textit{Chapter~\ref{ch:analysis}}, we give the static analysis algorithm that we use in order to spot 
        and thus properly annotate true tail-call positions. These annotated function calls 
        are later handled by the interpreter.

  \item In \textit{Chapter~\ref{ch:evaluator}}, how we operationally treat inside the interpreter the 
        tail call optimisable function calls and tail recursion modulo cons.

  \item In \textit{Chapter~\ref{ch:evaluation}}, we give an evaluation of our optimisations on microbenchmarks.

  \item \textit{Chapter~\ref{ch:related}} and \textit{Chapter`\ref{ch:conclusion}} are related work and conclude the thesis respectively.

\end{itemize}




\chapter{Background}
\label{ch:background}

In this chapter, we provide the reader the necessary background for this thesis. The optimisations presented in this thesis 
are explained. Anyone familiar with these ideas, can skip this section and continue to the next chapter, where we give the intuition behind the
main idea of this thesis.

\section{Tail-call optimisation}
\label{sec:tco}

The main optimisation this thesis discusses is the tail-call optimisation. This optimisation, first found in Scheme~\cite{Sussman:1975:IEL:889230,Steele:1976:LUI:889232} and
generally usually found in strict functional languages, 
allows functional programming languages to have constant space 
similar to `for' loops from imperative programming languages~\cite{Clinger:1998:PTR:277650.277719}. 
Without this, recursion would require \textit{linear} memory space; 
i.e. one frame allocation for each function call. More recent works perform tail-call optimisation 
for non-functional languages, such as C/C++~\cite{Probst01} 
and Java~\cite{Madsen:2018:TCE:3178372.3179499}.

What exactly is \textit{tail call optimisation}? Tail calls are function calls in specific locations;
specifically they are function calls performed as the final action of a function. Tail-call optimisation is actually passing 
the control from the caller to the callee; the runtime does not allocate a new frame for the 
callee function. Instead, it reuses the current frame from the caller function. This leads to 
a constant memory usage for the whole procedure. 

In the example below, we have a `factorial' in OCaml:
\begin{minted}{OCaml}
  let rec fact n = 
    if n > 0 
      then n * fact (n-1)
      else 1
\end{minted}

Inside the function's body, there is a function call to `fact'. This is not a tail-call, because this call is not 
the last call performed in the function's body. In this example, `*' is the last operation performed, just before the function returns.
Let's assume that we have a call to the function:
\begin{minted}{OCaml}
 let main = fact 3
\end{minted}

The calling stack in this execution is:
\begin{minted}{OCaml}
fact 3 = 3 * fact 2
fact 2 = 2 * fact 1
fact 1 = 1 * fact 0 
fact 0 = 1
\end{minted}

From the calling stack above, it seems that `fact 3' requires the result of `fact 2', which requires the result of `fact 1', which 
requires the result of `fact 0', in order to produce the final result. A stack frame is allocated for each function call and it is finally 
free, when the result is returned to the caller. The last operation that happens in every call is the multiplication.

Let's take a look at a second example, again for the `factorial'.
\begin{minted}{OCaml}
  let rec fact' n acc = 
    if n > 0 
      then fact' (n-1) (n * acc)
      else acc 
\end{minted}

These two examples have absolutely the same result. The \textit{path} they follow in order to produce it though, is totally different.
At this point, let's imagine a call to the function of the second example:
\begin{minted}{OCaml}
  let main = fact' 3 1
\end{minted}

Here is calling stack for ` fact' ':
\begin{minted}{OCaml}
  fact' 3 1 = fact' 2 3
  fact' 2 3 = fact' 1 6
  fact' 1 6 = fact' 0 6
  fact' 0 6 = 6
\end{minted}

As we observe, the call to fact' is the last call the function does before it returns. Also, the return result `acc' of the function is 
evaluated at every function call. This is the reason why fact' can run using only one stack frame, and thus we have \textit{constant} stack 
space for the execution. Constant space is also what happens if we wrote `factorial' with a `for' loop, imperative 
programming style. 

Tail-call optimisation is great for both having functional programming, and thus recursion and more clear code, and also not the 
memory overhead recursion \textit{usually} requires.

\section{Evaluation order choices}
\label{sec:evaluation-order}

In this section, we will describe the evaluation order choices we used in this thesis. In the setting of our first-order language, evaluation order is closely tied to how parameters passed and evaluated at a function call. Evaluation order controls \textit{how} the caller and the callee function will interact, 
when the former calls the latter. 

The evaluation order choices we studied are: 
\begin{itemize}
  \item call-by-value or \textit{strict} arguments (e.g. OCaml, Scheme), 
  \item call-by-name arguments, and
  \item call-by-need or \textit{lazy} arguments (e.g. Haskell).
\end{itemize}

Call-by-name and call-by-need semantics is similar to each other; they always produce the same result.
Their key difference is that call-by-need computes a value when it needs it, memoizes the result after the computation 
and does not evaluate it again, while call-by-name re-evaluates the value, in case it's needed again for a computation.
This makes call-by-name less practical. Call-by-need can also be considered as a \textit{practical} implementation 
of call-by-name, first appeared as a real-world implementation in the \textit{Miranda} programming 
language, later in \textit{Clean} and have become more popular
with Haskell's programming language implementation: the Glasgow Haskell Compiler (GHC).

\subsection {Call-by-value (CBV) or \textit{strict} evaluation}
\label{sec:cbv}

Call by value is the most commonly used technique for parameter passing. It' s used in the most functional 
programming languages (e.g. Scheme, OCaml etc) and also in imperative and object oriented programming 
languages (C/C++, Java etc).

\par Call by value principles briefly are:
\begin{itemize}
  \item Evaluate \textit{fully} the actual parameters at the call inside the caller function's body.
  \item \textit{Bind} the \textit{fully evaluated} values with callee's formal parameters \textit{locally} inside the callee.
\end{itemize}

Let's become more clear using a simple first example:
\begin{minted}{haskell}
  length :: [Int] -> Int -> Int
  length l@[]     acc = acc 
  length l@(x:xs) acc = length xs (acc + 1)

  -- Make the call to length
  main = length [1,2,3] 0
\end{minted}

Let's suppose strictness in the example above, i.e.:
\begin{itemize}
  \item `l' is a strict list, exactly the same as a regular list in SML.
  \item  `acc' is also a strict parameter. 
\end{itemize}

During the execution we have the following memory snapshots:
\begin{minted}{haskell}
  length [1,2,3] 0 = length [2,3] 1 -- At this point, `acc' is 
                                    -- evaluated to 0+1 = 1.
  length [2,3]   1 = length [3]   2
  length [3]     2 = length []    3
  length []      3 = 3
\end{minted}

This is the tail-recursive form of the function, known from the previous section, that counts the number 
of elements inside a list. As it seems above, the accumulator parameter `acc' is evaluated in every 
function call, before the control of the call passes to the callee.

Now, let's take a look at a second example, where the accumulator is a list. The purpose for this 
example is to highlight the difference between strict data constructors a la ML and lazy data constructors.
It will become obvious in later section, when we will talk about laziness (section~\ref{sec:lazy}).

\begin{minted}{haskell}
  makelist n acc = 
    if n > 0 
      then makelist (n-1) (n : acc)
      else acc
  main = makelist 3 []
\end{minted}

The calling stack of this program is:
\begin{minted}{haskell}
  makelist 3 []      = makelist 2 [3] 
  -- Again, `acc' is evaluated before 
  -- the call on the right-hand side is triggered.
  makelist 2 [3]     = makelist 1 [2,3]
  makelist 1 [2,3]   = makelist 0 [1,2,3]
  makelist 0 [1,2,3] = [1,2,3]
\end{minted}

Until this point, we examined CBV semantics, the most common 
semantics that a programmer uses. From this point on, we will dive into 
the two remaining kinds of semantics we used and we will show to the reader 
the relation between them and their key differences, especially for datatypes.
It is important the reader to understand the key differences from now, even though 
we will have a comprehensive explanation throughout the thesis.

\subsection {Call-by-name (CBN) evaluation}
\label{sec:cbn}

Call by name is an evaluation strategy where the arguments to a function are not evaluated before the function is called. 
They are substituted directly into the function body (using capture-avoiding substitution) and then left to be evaluated 
whenever they appear in the function. If an argument is not used in the function body, the argument is never evaluated; 
if it is used several times, it is re-evaluated each time it appears.

Call-by-name evaluation is occasionally preferable to call-by-value evaluation. If a function's 
argument is not used in the function, call by name will save time by not evaluating the argument, 
whereas call by value will evaluate it regardless. If the argument is a non-terminating computation, 
the advantage is enormous. However, when the function argument is used, call by name is often slower, 
requiring a mechanism called a \emph{thunk}, first appeared in ALGOL60~\cite{Naur78}. More recent works 
works prove a relation between call-by-name and call-by-value~\cite{Wadler03}, supporting our interest 
to investigate call-by-name as an evaluation order present in our core language.

A first example in order to showcase how a programmer can put CBN semantics to good use, is:

\begin{minted}{haskell}
  loop x = loop x

  head []     = error "Empty list"
  head (x:xs) = x

  main = head [42, loop 42]
\end{minted}

While in CBV, this program would cause a memory overflow, because it would try to evaluate [42, loop 42],
while `loop' is an ifinite loop and it would diverge, and thus the above would be an incorrect program, 
in CBN it will return 42, which is actually the first element of the list.

In a second example though, the drawback of CBN becomes obvious; it re-evaluates already evaluated values and thus 
turns the algorithm complexity from linear to more than quadratic. The example follows:

\begin{minted}{haskell}
  fact n acc = 
    if n > 0 
      then fact (n-1) (n*acc)
      else acc

  main = fact 3
\end{minted}

In this example, the successive order of calls would be:
\begin{minted}{haskell}
  -- 1 
  fact 3 1 = 
    if n > 0                  -- Here becomes n = 3
      then fact (n-1) (n*acc) -- where n = 3  and acc = 1*3
  -- 2
  if n > 0                    -- Evaluates n-1=3-1=2 and n = 2 
    then fact (n-1) (n*acc)   -- again n-1=2-1=1 and n*acc=1*1
  -- This will follow until the end of execution, 
  -- and this leads to call-by-name with memoization (call-by-need).
\end{minted}


\subsection {Call-by-need or \textit{lazy} evaluation }
\label{sec:lazy}

Call by need is a memoized variant of call by name where, if the function argument is evaluated, 
that value is stored for subsequent uses. If the argument is side-effect free, this produces the same results as call by name, 
saving the cost of recomputing the argument. 

Haskell is a well known language that uses lazy evaluation. Because evaluation of expressions may happen arbitrarily 
far into a computation, Haskell only supports side-effects (such as mutation) via the use of monads. This eliminates any 
unexpected behavior from variables whose values change prior to their delayed evaluation.

Lazy evaluation is roughly guarded by two major priciples:
\begin{itemize}
  \item \textit{Call-by-name} semantics, and
  \item \textit{single-evaluation} property, which makes the memoization compulsory.
\end{itemize}

At this point, let's take a closer look at this program, also presented in the previous section about CBN,
but now in the presence of laziness:

\subsection{Lazy data constructors}
\label{sec:lazy-data-cons}

\begin{minted}{haskell}
  loop x = loop x -- function that diverges

  head l = 
    case l of 
      []     -> error "Empty list"
      (x:xs) -> x

  main = head [42, loop 42]
\end{minted}

When we call `head' with [42, loop 42] the following happens:
\begin {itemize}
  \item Allocates a frame with an unevaluated \textit{thunk}~\cite{Bloss1988}, which is [42, loop 42], for the function call to head.
  This means that `l' formal parameter contains a pointer to the memory cell, which contains the aforementioned actual parameter. 
  \item Then, `head' is evaluated. Imagine `case' as an operation that "opens" the data, i.e. it forces evaluation \textit{one} 
  more step. The first expression to be evaluated is the list `l', which is \textit{needed} in order to pick a branch. More 
  specifically `eval l' produces `x1:x2', where `x1' contains a pointer to `42' and `x2' contains a pointer to `loop 42'.
  It also binds `x', `xs' to `x1', `x2' successively.
  \item At this point, `case' knows which branch to pick from the previous step. As `l' is not an empty list, it picks the 
  second branch. 
  \item On the right-hand side of the second branch, there is variable `x'. Now, the value of `x' is needed, and thus 
  it evaluates `x1', that is evaluates the content of the pointer and finally it returns 42.
  \item An important notice is that because pattern matching variable `xs' does not exist on the right hand side 
  of the branch, it does not evaluate `xs' and thus the program does not diverge.
\end{itemize}

\subsection{BangPatterns: Haskell with strictness}
\label{sec:bangpatterns}

Haskell's de facto compiler, the Glasgow Haskell Compiler (GHC),
contains a language extension, ``bang patterns'', available both in
the interactive environment (\texttt{ghci}) with:
\begin{minted}{haskell}
  ghci -XBangPatterns
\end{minted}
and also in the compiler as a flag, or as a language extension annotation inside a Haskell's source file as:
\begin{minted}{haskell}
  {-# LANGUAGE BangPatterns #-}
\end{minted}
which allow the explicit use of strictness in Haskell. We should also mention the existence of `seq', a function found
in Haskell's Prelude:
\begin{minted}{haskell}
  seq :: a -> b -> b
\end{minted}
which forces the evaluation of the first argument and returns the second argument as a result.

The example below showcases the use:
\begin{minted}{haskell}
  {-# LANGUAGE BangPatterns #-}

  loop x = loop x -- function that diverges

  -- !l: l is a strict parameter
  head !l = 
    case l of 
      []     -> error "Empty list"
      (x:xs) -> x

  main = head [42, loop 42]
\end{minted}

The same annotation in our language's source files is used; it will be explained in detail in later section of 
Chapter~\ref{ch:language}. For now, we provide some explanation about how the above program will run, in order to highlight 
the difference with `head' with the lazy parameter, Haskell's builtin, which was given earlier. 

The program above has the following behaviour when executed:
\begin{itemize}
  \item Again, `head' is called. But now the frame for `head' has an evaluated \textit{thunk}, because `!' moves the 
  evaluation one more step. So, in contrast to the earlier example, `l' has a pointer to (x1:x2), where x1 contains a pointer to 
  `42' and x2 contains a pointer to `loop 42'. The \textit{thunk} is also marked as \textit{evaluated}.
  \item Then, `head' is evaluated. At this point, when `case' needs to evaluate `l', which is marked as evaluated, `case' knows 
  which branch to follow, which is the same as earlier, and does not do anything else.
  \item After the branch is picked, again the right hand side of the branch is evaluated and `42' is returned as a result.
  \item An important notice here is that `!' does not force \textit{deep} evaluation of the data structure. It just moves the 
  value from weak-head normal form to head normal form. For data, this means that the outermost value is evaluated.
\end{itemize}

The idea about extending Haskell with strictness was used in StrictCore, an intermediate language 
which aims to improve GHC's Core language by having
thunk/value distinction at the type level and multi-arity functions and multiple value returns, 
inspired by~\cite{Bol09}.


\subsection{Deepseq: ML-lists in Haskell}
\label{sec:deepseq}

The above functionality of `BangPatterns' shows that even with these strictness annotations, data constructors (lists in our
example) are not the same as ML lists. But Haskell also has the `deepseq' module, which cause deep evaluation of the data, 
and in this way we can \textit{head normal data}. 

It follows an explanation of `deepseq' functionality. 
BangPatterns are used in data constructors definitions.

\begin{minted}{haskell}
  data List a = Empty | Cons !a !(List a)
\end{minted}

In the above data definition, `Cons' contains:
\begin{itemize}
  \item A strict head, annotated with a `!'.
  \item A strict tail, annotated also with a `!'.
\end{itemize}

In case that this list was used for `head', we finally have ML lists and the program 
will diverge as it happens in a strict functional language like OCaml. `Deepseq' automatically can turn a data structure
defined in Haskell into a ML-like data structure, by automatic instance derivation.

In case the programmer needs more customization, they can use BangPatterns in every possible combination. 
The definitions below are also used in this thesis' language.
\begin{minted}{haskell}
  -- 1. Haskell builtin lists.
  data List a = Empty | Cons a (List a) 
  -- 2. Lists with strict head.
  data List a = Empty | Cons !a (List a)
  -- 3. Lists with strict tail.
  data List a = Empty | Cons a !(List a)
  -- 4. Deeply evaluated lists. 
  data List a = Empty | Cons !a !(List a)
\end{minted}

\section {Static analysis}
\label{sec:static-analysis}

%% \subsection{General background}


Static program analysis attempts to predict all possible runtime
behaviour of a program~\cite{Nielson:2010:PPA:1965094}. This analysis
happens without running the program, using just the program text (or
equivalent intermediate representation). This permits the analysis to
run before the program runs and can thus be used to guide decisions
such as compile-time optimizations.

In practice, all realistic programming language implementations
incorporate a set of static analysis that help apply optimizations,
check type annotations, detect errors, or otherwise catch program
behavior before it happens.

Of particular interest to this thesis is strictness
analysis~\cite{PeytonJones:1991:UVF:645420.652528,Holdermans:2010:MSM:2088270.2088274},
an analysis especially useful for lazy languages, where laziness can
be overriden by a ``strictness'' annotation (such as the functionality
described in section~\ref{sec:bangpatterns}). This analysis runs on a
lazy program and determines which expressions can be evaluated
efficiently using call-by-value, instead of lazy evaluation, without
changing the meaning of the program. More details about this analysis will be given in section~\ref{sec:strictness-analysis}.

%% In the rest of this thesis, we
%% will assume that the strictness information can either come from the
%% user or from such an analysis.

In Chapter~\ref{ch:analysis}, we will also give our own static
analysis that will be able to detect the program points where
tail-call optimization can be applied.

\section{Abstract machines and Interpreters}
\label{sec:abstract-machines}

\subsection {Stack Environment Control Dump machine (SECD)}
\label{sec:secd}

The SECD machine is a highly influential virtual machine and abstract 
machine intended as a target for functional programming 
language compilers, introduced in 1964~\cite{La64}, and later explained
in detail~\cite{Danvy:2004:RDL:2154439.2154443}. The letters stand for Stack, Environment, 
Control, Dump, the internal registers of the machine. 
The registers Stack, Control, and Dump point to (some 
realisations of) stacks, and Environment points to (some 
realisation of) an associative array.

\subsection{Three-instruction machine (TIM)}
\label{sec:tim}

TIM~\cite{Argo89}.

provide background for abstract machines and Interpreters
secd, tim, stg etc etc

\subsection{G-Machine}
\label{sec:g-machine}
Write about G-Machine, STG's predecessor. Compare it with G-Machine.

\subsection{Spineless Tagless G-Machine (STG)}
\label{sec:stg}
Overview of STG~\cite{Jo92} and its latest version~\cite{Ma06}.

\subsection{Push/enter vs. eval/apply}
\label{sec:push-enter}
Push-enter vs. eval-apply~\cite{Ma06}, marlow and jones. Our model is push-enter, since it is first-order.

% \section {Boxed vs. Unboxed values}
% μπλα μπαλα.





\chapter {Overview}
\label{ch:overview}

In this chapter, we present to the reader some examples providing the intuition of the main idea described 
in the following chapters. The description is informal and the reader has to know only the details of laziness 
described in the background in order to follow. We do not refer to details of the analysis and the execution model 
that may confuse the reader, while leaving that part for later explanation, in the appropriate sections.

More specifically, in section~\ref{sec:classic-tco-examples} we provide examples for integers (values always in WHNF) and 
for almost all the cases of handling lists (`lazy' data constructors): 
consuming (`sum'), constructing (`makelist'), consuming and constructing (`map'). 
In section~\ref{sec:modulo-cons-example}, an example for tail recursion modulo cons is presented. It is an extension of classic 
tail-call optimisation, first appeared in Prolog implementations.


\section {Classic tail-call optimisation}
\label{sec:classic-tco-examples}

% \subsection {Example 1: Integers}
% In this example, the only values are integers. As mentioned 
% in the previous chapter, integer values are always in weak-head normal 
% form (WHNF). This means that their \textit{full} evaluation requires \textit{one} more evaluation
% step, provided that the program does \textit{not} diverge. 


% In the first example presented below the argument is in CBV evaluation order, 
% while in the second it is in lazy evaluation order. \textbf{[1 or 2 examples (if 1 is not enough) which makes clear the copy of values from 
% one frame to the next and also the importance of strictness.]}


\subsection {Example 1: Consuming lists}
\label{sec:example1}

The first example with constructed data is a 
function that \textit{consumes} the input data in 
order to produce a result.  The function traverses 
the input once and then computes the result. As we 
already mentioned, all arguments here are \textit{lazy}.

\begin{minted}{haskell}
sum :: [Int] -> Int -> Int
sum []     acc = acc
sum (x:xs) acc = sum xs (x + acc)
\end{minted}

In \textit{strict} languages like SML/NJ or Scheme,
this is subject to tail-call optimisation. As we know from section~\ref{sec:cbv},
`acc' is \textit{fully} evaluated in every execution step, while in the
presence of laziness `acc' is evaluated \textit{once}, when the input 
list is empty and the function \textit{needs} it as a result.

The intuition here is that lazy argument `acc' has to be strict, as in the example below,
because it is a variable that has always a value (in the case the value of the variable `x') added to it,
and finally it is returned as a result. This is known in the world from strictness analysis [1], as we 
will describe later in section~\ref{sec:strictness-analysis}.

\begin{minted}{haskell}
  sum :: [Int] -> Int -> Int
  sum l !acc = 
    case l of 
      []     -> acc 
      x : xs -> sum xs (x + acc) 
\end{minted}

At the latter example, `acc' (an integer or WHNF) is strict. This means that `acc' is 
fully evaluated in each execution step, and thus it can be tail-call optimised. This, of course,
is not possible if `acc' was, for example, a list, as we will illustrate with the following examples.


\subsection {Example 2: Constructing lists}
\label{sec:example2}

In this example, we have a function that constructs a list with successive 
integers up to the input number `n' (`0' excluded, `n' included). The function contains 
a tail-recursive call in its body to itself (`makelist (n-1) (n : acc)'). 

\begin{minted}{haskell}
makelist :: Int -> [Int] -> [Int]
makelist !n !acc = 
  if n > 0 
    then makelist (n-1) (n : acc)
    else acc
\end{minted}

Although the example above seems a perfect candidate for tail-call optimisation, it is not, 
at least in the traditional point of view of tail-call optimisation. Here, lists are 
lazy data constructors and are not fully evaluated in every execution step. The bang (`!') does not 
force deep evaluation of the data, but it forces the evaluation one more step. That means that the strict 
`acc' constructs its \textit{backbone} (a memory thunk) in memory, along with a \textit{recipe} 
(`n-1' and `n:acc' cells) for further evaluation. 

With a more case-aware analysis and additional work in the evaluator, 
we were actually able to tail-call optimise the example
above. The details will follow in sections~\ref{sec:classic-tco-analysis} and \ref{sec:classic-tco-eval} for the analysis 
and the evaluator respectively.

\subsection {Example 3: Constructing and consuming lists}
\label{sec:example3}

An example of constructing and consuming, or better \textit{processing}, lists is `map' or `foldl'/`foldr'.
In the example below, we present a defunctionalized version of `map', similar to Prelude's `map', instantiated for
the integer domain.

\begin{minted}{haskell}
data Func = Add Int
apply f x =
 case f of
   Add a0 -> add a0 x

map :: Func -> [a] -> [b] -> [b]
map f l acc =
 case l of
   []     -> acc
   x : xs -> map f xs (apply f x : acc)

inc a = a + 1

result = map (Add 1) [1, 2, 3] []
\end{minted}
In the example presented above, 
the tail-recursive call to `map' can be subject to tail-call optimisation, 
following the same principles as in the examples like `sum' and `makelist'. The classic non tail-recursive 
version of `map' (`apply f x : map f xs') is actually subject to tail recursion modulo cons, which is presented 
in the following section.

\section{Tail recursion modulo cons}
\label{sec:modulo-cons-example}

Tail recursion modulo cons is a generalization of classic tail-call optimisation. First found in an 
implementation of Prolog, it can also be applied in
functional programming languages, especially those with lazy evaluation~\cite{Wadler84}.

Tail recursion modulo cons can also be found in bibliography, as \textit{guarded} recursion, 
a recursive call guarded by a constructor. This can become more clear, if we consider lazy data constructors, 
described in section~\ref{sec:lazy}, which use a mechanism called \textit{thunk} for their evaluation.

Let's illustrate this idea with a simple example presented in the next section.

\subsection {Motivating example}
In Example 3 (section~\ref{sec:example3}), `makelist' was in the tail-recursive 
form. In this section, we have a different version of the function. 
Programmers who constantly use strict functional programming languages like OCaml 
will argue that the program below is bad. 

In Haskell, this is not the case. Actually, in Haskell's Prelude all functions are written 
in the form below, where these programs are subject to many optimisations triggered 
by Haskell's \textit{rewriting machine}, and performed in the runtime 
(especially this program is subject to \textit{fusion}~\cite{Coutts07}). 

At this point, we showcase the use of tail recursion \textit{modulo cons}, instead of other optimisations
used in GHC.

\begin{minted}{haskell}
makelist x = 
  if x > 0 
    then x : makelist (x-1)
    else []
\end{minted}

In the example above, the \textbf{\textit{then}} clause contains a constructor 
application: 
\begin{center}
  @ (@ (:) x) (@ makelist (x-1))
\end{center}

This recursive call is guarded by the constructor (:).
From section~\ref{sec:lazy-data-cons}, where we described lazy data constructors,
we know that this constructor application will be suspended when 
the program is running. This means that it will create a memory 
thunk with two cells, which will contain `x' and `makelist (x-1)'.
The function call to makelist is actually a call that can be transformed 
to a tail-recursive call to `makelist', if the `cons' thunk is \textit{updated} 
with the value of the variable `x'. 

\chapter {The language}
\label{ch:language}

In this chapter, we will describe the language that we studied in this thesis.
The semantics of the language will become clear to the reader, as well as 
the special treatment of the evaluation order in the final core 
language, which was used for the static analysis and for the optimisations. Briefly, a 
comprehensive description of the path from a higher-order functional language 
to a first-order functional language with the evaluation-order annotations will follow.

\section {Overview of the language }
\label{sec:language-overview}

The language we studied is a functional language 
with multiple evaluation orders (call-by-need or 
\textit{lazy}, call-by-name and call-by-value or \textit{strict}).
We consider laziness as something that happens naturally in the language, while 
the other two evaluation orders are used as language extensions,
using proper annotations.

The annotations can appear syntactically (i.e. the programmer can annotate 
the formal parameters in the function definition) or 
after applying the transformations, described in sections 3.2 to 3.4, 
to the source language. The latter
is only the case for strict arguments revealed by strictness analysis.

\section {Defunctionalization transformation}
\label{sec:defunctionalization}

Defunctionalization is a compile time tranformation technique which eliminates higher order 
functions, replacing them by a single first-order \textit{apply} function, introduced by John Reynolds~\cite{Reynolds72definitionalinterpreters}.
Reynolds' observation was that a given program contains only finitely many function abstractions, so that each can 
be assigned (and replaced by) a unique identifier. Every function application within the program is then replaced 
by a call to the apply function with the function identifier as the first argument. The apply function's only job is 
to dispatch on this first argument, and then perform the instructions denoted by the function identifier on the 
remaining arguments.

One complication to this basic idea is that function abstractions may reference free variables. In such situations, 
defunctionalization must be preceded by lambda lifting~\cite{Johnsson:1985:LLT:5280.5292}, so that any free variables of a function 
abstraction are passed as extra arguments to apply. In addition, if closures are supported as first-class values, 
it becomes necessary to represent these captured bindings by creating data structures.

The defunctionalization transformation was used in MLton, an optimising compiler for ML. The first-order
core language created oportunities for whole-program analysis and led to great performance~\cite{mlton}.

As an example of defunctionalization, Prelude's `map' follows. The transformation leads to 
the non tail-recursive version of `map'.

Prelude's `map':

\begin{minted}{haskell}
  map :: (a -> b) -> [a] -> [b]
  map f []     = []
  map f (x:xs) = f x : map f xs

  inc :: Int -> Int 
  inc a = a + 1
  
  result = map inc [1,2,3]
\end{minted}

After performing defunctionalization `map' is (instantiated for integers):
\begin{minted}{haskell}
  data Func = Inc 

  apply :: Func -> b -> b
  apply f x =
    case f of
      Inc -> inc x

  map :: Func -> [a] -> [b]
  map f l =
  case l of
    []     -> acc
    x : xs -> apply f x : map f xs

  inc :: Int -> Int 
  inc a = a + 1

  result :: [Int]
  result = map Inc [1, 2, 3] []
\end{minted}

The differences between the two versions are:
\begin{itemize}
  \item Higher-order function, the first argument of `map' (f :: a -> b) is 
  transformed to a \textit{unique} identifier, which is the data constructor `Inc'.
  \item For the application inside the body of `result' function, we have the first order \textit{apply}
  function, which patterns matches on the unique identifiers that are applied to `map'.
\end{itemize}

Further details and formalization of defunctionalization transformation are not given here. 
The reader can refer to Reynolds' paper for more information about this transformation.

\section {Strictness analysis}
\label{sec:strictness-analysis}

Lazy evaluation only evaluates terms to values when needed; this provides the 
opportunity for infinite data structures and programs that do not diverge, as those in 
strict programming languages. But everything comes at a cost: evaluation can happen 
arbitrarily and thus lazy arguments can escape their context.

But Mycroft
noticed that some lazy terms are actually strict under the right circumstances~\cite{Mycroft:1980:TPT:647324.721526}. For instance, the `case' 
construct forces the evaluation of an expression, called the \emph{scrutinee}~\cite{PeytonJones94}, causing the scrutinee to actually become strict, 
similar to strictness presented in section~\ref{sec:bangpatterns} about BangPatterns. 

And it's more than that. Let's look again the sum program of section~\ref{sec:example1}:
\begin{minted}{haskell}
  sum :: [Int] -> Int -> Int
  sum []     acc = acc
  sum (x:xs) acc = sum xs (x + acc)
\end{minted}

Here, lazy argument `acc', which is a thunk in each function call is evaluated once, when the program's 
execution flow reaches the base case. This \textit{arbitrary} evaluation of lazy arguments seems not to 
be so arbitrary after all. We do know when `acc' is going to be evaluated.

The question is: what makes `acc' so predictable? From the example above, we have the following information for `acc':
\begin{itemize}
  \item `acc' is an integer, always added to another integer.
  \item `acc' is the result of the function.
\end{itemize}

From these observations we can deduct that `acc' is going to be evaluated (second observation) and 
all intermediate values are needed for its evaluation, as `acc' is an integer (first observation).

Although in this thesis we used integers and lists, strictness
analysis can be applied except for integer domain to any other domain. In practice, strictness analysis is a
core analysis of Haskell
implementations~\cite{PeytonJones:1991:UVF:645420.652528,burn:lemetayer:1996,Holdermans:2010:MSM:2088270.2088274}.

In our model, strictness analysis may be performed in the
defunctionalized higher-order language in order to properly annotate
strict arguments. Strictness annotations are also available in the
language syntax, and thus the programmer can manually give such
annotations. The origin of the strictness annotations (analysic
vs. manual input) is thus not imporant for the aims of this thesis; we
only assume that such annotations are available.

\section {Other transformations}
\label{sec:other-transformations}

After defunctionalization transformation and strictness analysis are performed, we also 
perform some more transformations to the source language in order the intermediate 
language to reach the final form, which is the input of the analysis, presented in later section.


\begin{itemize}
  \item \textbf{Alpha-renaming:}  This transformation (also known as \emph{alpha-conversion}~\cite{Barendregt:1993:LCT:162552.162561}) renames all variables bound by pattern matching.
  Every `case' expression opens a new scope and variable names in this scope are bound to the closest 
  `case' pattern. This transformation also handles name shadowing. 
  \item \textbf{If-to-case transform:}  When the language supports pattern matching on data 
  (constructors), `if' expression is useless. It can be transformed to pattern matching on 
  the nullary boolean constructor. Haskell does not have `if' expression as builtin; it only allows
  syntactic use (as syntactic sugar for boolean patterns).
  \item \textbf{Constructor projections:}  Every variable bound by a `case' pattern has to be 
  transformed to a special syntactic node in the core language, which contains the case unique identifier
  and the position inside the expression list in the constructor pattern~\cite{Fourtounis:2013:GIT:2769663.2769674}. The `case' id is 
  unique inside a function definition (locally).
\end{itemize}

\section{Syntax}
\label{sec:syntax}

In this section, the syntax of our core language is given.
This is the output of the strictness analysis and 
defunctionalization transformation as well as the other transformations of the previous 
section. We run the analysis algorithm to spot tail-call positions with input 
the language from this section. The interpreter is also built for that language; the evaluator for 
the optimisations are also implemented inside the interpreter for this language.

Figure~\ref{fig:grammar} shows the abstract syntax of 
the first order intermediate language.
We need to highlight the following points, before we dive deeper into the language:
\begin{itemize}
  \item The source language contains an `if' expression syntactically. In the syntax figure there is no such construct.
  This is because `case' is much more powerful than `if' and an `if' can be transformed to a `case'. 
  Actually, we have (boolean are constructed data as well):
  \begin{minted}{haskell}
    if cond then e1 else e2 => case cond of { True -> e1; False -> e2 }
  \end{minted}
  \item There are not any partial applications, neither in function nor in constructor applications.
  This means that the arguments in a function call are the same in number as in the function definition.
  \item There is no `let' expression in the core language. Instead we assume that our language 
  fully depends upon a lambda lifter; a Johnson-style \textit{full laziness} lambda lifter~\cite{Johnsson:1985:LLT:5280.5292}
  will get the work done.
  \item Case patterns are simple and do not allow wildcard patterns. Turning a complex case pattern into
  a simple case pattern is a well studied topic~\cite{Au85,Wadler87}.
  \item The scrutinee of a case construct is not a case expression. We assume that case-of-case 
  transform~\cite{Jone98} is performed.
\end{itemize}

% Better have it as figure. 
\begin{figure}[t]
\hrule
\begin{grammar}
    <p> ::= <fdef>\textsuperscript{+} \hfill\ Program

    <fdef> ::= \textit{f v\textsubscript{1} ... v\textsubscript{n}} = <expression> \hfill\ Function Definition

    <expr> ::= \textit{v} \hfill\ Variable
    \alt <integer> \hfill\ Integer
    \alt \textit{f e\textsubscript{1} ... e\textsubscript{n}} \hfill\ Function application
    \alt \textit{c e\textsubscript{1} ... e\textsubscript{n}} \hfill\ Constructor application
    \alt \texttt{case} \textit{e\textsubscript{0}} \texttt{of} \textit{patt\textsubscript{1} $\rightarrow$ e\textsubscript{1} | ... | patt\textsubscript{n} $\rightarrow$ e\textsubscript{n}} \hfill\ Case expression
     
    <patt> ::= \textit{c v\textsubscript{1} ... v\textsubscript{n}} \hfill\ Constructor pattern
    \alt <integer> \hfill\ Integer pattern

    <integer> ::= 1, 2, ... \hfill\ Integer domain

\end{grammar}
\hrule
\caption{My grammar\label{fig:grammar}}
\end{figure}

The syntax in the figure is a syntax of a first order functional language. Our syntax has two main 
differences from the one shown in the figure:
\begin{itemize}
  \item The concrete syntax of the core language has evaluation order annotations in order to 
  distinguish between the semantics during the parameter passing. We have already mentioned the 
  strictness annotations added by the strictness analysis. 
  More specifically, the programmer can concretely annotate the formals in the function definition with:
    \begin{itemize}
      \item {`!' for a strict formal parameter,}
      \item { `\#' for a call-by-name formal parameter, while}
      \item {lazy arguments are not annotated, because we consider laziness as something that naturally happens 
      in the language.}
    \end{itemize}
  
  As far as the abstract syntax is concerned, the formal parameters of a function definition are:
  \begin{minted}{haskell}
    type Formal = (VN, (EvalOrder, Type))
    type VN = String 
    type EvalOrder = CBV | CBN | Lazy 
    data Type = TInt | TCons Type -- an value of type integer (TInt) or 
                                  -- a list of values with type Type
  \end{minted}
  where the type constructor of a formal parameter has the information about the parameter's name and 
  the static info of its evaluation order and its type. We assume the base types as integers and later in 
  the analysis part, we will explain why this is enough.

  \item There is one more node in the syntax tree: \textit{constructor projections}. The transformation for this 
  particular syntax node has been explained earlier (section~\ref{sec:other-transformations}). 
  \begin{minted}{haskell}
    data Expr = ... | CProj CaseID CPos 
  \end{minted}
  In a constructor projection, the first argument `CaseID' shows the position of case where the argument belongs
  and the second argument the position of the variable in the left hand side of a constructor pattern in a `case' branch.
  
  The purpose of constructor projections is to bind the variables on the right hand side of the branch with the variables 
  on the left hand side of the branch. In this way, these variables are distinguished from the top level variables, i.e.
  the formal parameters in the function definition and they offer the possibility to know the position in the frame, 
  a reason that will become more clear in the next chapter, where we are going to give the details of the 
  execution model.
\end{itemize}



\chapter {Execution model}
\label{ch:execution-model}

In this chapter, we will present technical details the operational semantics for the 
language we studied in this thesis as well as the technical details about the implementation of
the interpreter, on which we evaluate our technique for the tail-call optimisation and
tail recursion modulo cons.

In section~\ref{sec:execution-model-overview} there is a high-level description of the machine; 
then in section~\ref{sec:runtime-structs} the runtime 
data structures and the design decisions will become clear to the reader.


\section {Overview of the execution model}
\label{sec:execution-model-overview}

In this section, we present a high-level description for the execution model; this will be helpful for the reader
to follow the technical details from the next sections. Also, it will be easier to compare to other existing 
abstract machines and interpreters that exist for a lazy functional language.

Our model, based on GIC~\cite{Fourtounis14}, 
includes the following high-level properties:
\begin{itemize}
  \item We implement a first-order lazy abstract machine. First-order as we do not support
  function arguments cannot be functions and partial evaluation. Laziness is the default semantics
  for our model.
  \item We have a frame-based execution model for our language, but the frames are 
  \textit{heap-allocated frames}, instead of stack. The reason for this is that lazy evaluation 
  breaks the sequential order of execution, because of frame updates, and thus we are not able 
  to allocate and deallocate frames with push/pop operations.
  \item Our interpreter supports explicit frame allocation, needed for frame mutation and evaluation 
  of our technique, as well as a frame counting mechanism of frames.
  \item Our language supports multiple evaluation orders and thus our interpreter 
  also handles them (call-by-value, call-by-name, call-by-need).
  \item Our data are lazy data constructors, but we can also support ML-lists (data with deep evaluation
  presented in section~\ref{sec:deepseq}).
  \item At function calls we follow the push/enter function call policy. Before jumping into 
  the function's body, we allocate the frame and evaluate all the actual parameters, with the respect
  to the semantics. 
  \item Our model supports pattern matching (constructors and base type values) similar to Haskell. 
  This is the most complicated feature in a lazy functional language, if we consider that initial 
  abstract machine did not provide support for that (section~\ref{sec:g-machine}).
\end{itemize}

\section {Runtime system}
\label{sec:runtime-system}

This section contains a detailed explanation of the prototype implementation of the interpreter we 
used for the language. First, we are going to present the data structures used in the runtime; then, 
we present the operational features of our interpreter. 

\section{Runtime data structures}
\label{sec:runtime-structs}
Here, there are the definitions of the runtime structures, as they are used in the implementation. The 
implementation is in Haskell, but the code will be simple, so that every reader with a basic background of a functional 
language can understand.

In the next sections that will describe the runtime structures, we will use the following convention. At first, a definition 
will appear; probably accompanied with one or more definitions. If it contains more complex data in its body, it will be 
described later in the section or there will be a pointer to another section.

\subsection{Memory: The global frame container}

In this section, we provide the definition of \textit{memory}: 
a \textit{mutable} memory space, where frames (explained in section~\ref{sec:frames}) are stored.

We have the following definition for \textit{memory}:
\begin{minted}{haskell}
  type FrameId = Int
  data Mem = Mem {
    memFrames :: Map FrameId Frame, lastFrameId :: FrameId
  }
\end{minted}

The data definition has the following fields:
\begin{itemize}
  \item A \textit{map} data structure in which a unique \textit{frame} identifier actually corresponds to 
  a frame in the memory (\textit{memFrames}). 
  \item The frame identifier for the last frame that was allocated (\textit{lastFrameId}).
\end{itemize}

The reader can think of memory as the memory in a computer: every memory cell has an address (\textit{FrameId}) and 
the address has a content (\textit{frame}). A similar representation to Launchbury's mutable heap for 
lazy evaluation~\cite{La93}.
Here, not all frames have the same capacity; the details will be given in later section for a frame.

This aforementioned data structure is accompanied with three operations in order to handle it:
\begin{itemize}
  \item Add a frame to the memory with \textit{push} operation (figure~\ref{fig:push}).
  \item Get a frame from the memory given its unique identifier (\textit{getFrame})
  (figure~\ref{fig:getFrame}).
  \item Update the content of a memory's frame, given its unique identifier (\textit{updFrame})
  (figure~\ref{fig:updFrame}).
\end{itemize}

\begin{figure}[h]
  $ \mathit{push} :: \mathit{Mem \times Frame \rightarrow Mem} $ \\
  $ \mathit{push~(mem, frame) = mem'} $ \\
  $ \mathit{mem' = Mem~\{~memFrames = frames', lastFrameId = lastId~\} } $ \\
  $ \mathit{frames' = frame : (memFrames~mem)} $ \\
  $ \mathit{lastId = lastFrameId~mem + 1} $
\caption{Push frame operation\label{fig:push}}
\end{figure}

\begin{figure}[h]
  $ \mathit{getFrame} :: \mathit{Mem \times FrameId \rightarrow Frame} $ \\
  $ \mathit{getFrame~(mem, id) = frame} $ \\
  $ \mathit{frame = lookup~id~(memFrames~mem)} $
\caption{Get frame operation\label{fig:getFrame}}
\end{figure}

\begin{figure}[h]
  $ \mathit{updFrame} :: \mathit{Mem \times FrameId \times Frame \rightarrow Mem} $ \\
  $ \mathit{upFrame~(mem, frameId, frame) = 
      mem~\{memFrames = insert~frameId~frame~(memFrames~mem)~\} } $ 
\caption{Update frame operation\label{fig:updFrame}}
\end{figure}


Later on, we will use the terms \textit{push}, \textit{getFrame} and \textit{updFrame} in order to refer to 
operations performed in memory.

\subsection{Suspended execution of constructed data}
\label{sec:suspended}

The data definition of suspensions (for short or suspended execution of constructed data) is:
\begin{minted}{haskell}
  data Susp = Susp (CN, [Expr]) FrameId
\end{minted}

A \textit{Susp} data construction contains:
\begin{itemize}
  \item The constructor's name \textit{CN} along with the arguments applied to it in an expression list, 
  as the constructors in our language are \textit{lazy}.
  \item A pointer to the frame' s identifier (\textit{FrameId}) , which is the environment for this suspension.
  This is the environment, until this suspension has been created. When the execution of the program forces the 
  constructor' s execution again, it will use this environment for its evaluation.
\end{itemize}

\subsection{Values}
\label{sec:values}

A value can either an integer value or a suspension.

\begin{minted}{haskell}
  data Value = 
    VI Integer 
  | VC Susp 
\end{minted}

From the above definition, we have that a value can be either an integer (or generally a base type 
value) or a suspension of constructed data (see section~\ref{sec:suspended}). While the former is obvious, especially 
for most programmers who use strict languages, the latter is something that happens in lazy evaluated 
programming languages. Computations may not be deeply evaluated and thus they can create thunks or 
leave unevaluated thunks that can be evaluated later.

\subsection{Frames}
\label{sec:frames}

The basic \textit{unit} of the execution machine is a \textit{frame}. A frame contains all necessary information 
for a function call. It is allocated every time a new function call takes place; then, it can be mutated in case it contains
a lazy parameter.

Here is the definition of a \textit{frame}:
\begin{minted}{haskell}
  type FN      = String 
  type CaseID  = Int 
  type FrameId = Int 

  data Frame   = Frame {
    fName  :: FN,                  -- Function Name
    fArgs  :: [FrameArg],          -- Bindings of formals with actuals
    fSusps :: [(CaseID, Susp)],    -- Data deconstruction forced by `case'
    fPrev  :: FrameId              -- pointer to previous stack frame 
  }
\end{minted}

A frame has the following information during its lifetime:
\begin{itemize}
  \item The function's name (\textit{FN}). This information is important to lookup the function 
  definition in \textit{functions map}, a structure that will be explained later, and the execution to 
  proceed.
  \item The actual parameters that are binded with the formal parameters of the function 
  definition of \textit{`FN'}.
  \item Information about suspended execution, thunk creation and evaluation forced by `case'. Each \textit{`CaseID'}, 
  unique in the body of the function contains pointers to its own thunks.
  \item A pointer to the previous frame's unique identifier (\textit{fPrev}). This is the \textit{environment} in the 
  interpreter's implementation, implied and not explicitely existing in the \textit{state} of the interpreter.
\end{itemize} 
An argument that lives in `fArg :: [FrameArg]' has the following definition:

\begin{minted}{haskell}
  data FrameArg = 
    StrictArg { val :: Value }
  | ByNameArg { expr :: Expr }
  | LazyArg   { expr :: Expr, isEvaluated :: Bool, cachedVal :: Maybe Value }  
\end{minted}

An argument can be either:
\begin{itemize}
  \item Strict and thus containing a \textit{value} (more about values in section~\ref{sec:values}).
  \item Call-by-name and thus containing only an expression, an unevaluated thunk with no option for 
  memoization.
  \item Lazy and thus containing an expression, in the same way as call-by-name arguments, 
  but also a \textit{flag} whether it is evaluated or not (preserving in this way the \textit{single evaluation property} if 
  it is already evaluated) and also space for the \textit{cached value}.
\end{itemize}

\section{Interpreter}

The interpreter is a function that takes a program's \textit{expression}, a \textit{static} memory space which contains 
information about top-level function definitions and a \textit{state}, 
reaches a \textit{final state} and \textit{returns a value}, where an expression is one of the expressions of the syntax 
tree presented in section~\ref{sec:syntax}. The definition of the \textit{state} follows later in the section.

From now on, the function $\mathit{eval}$ corresponds to the interpreter function.The declaration of the \textit{eval} 
function is shown in figure~\ref{fig:eval}:

\begin{figure}[h]
  \[
    \mathit{eval} :: \mathit{Expr} \times \mathit{FunctionsMap} \times \mathit{State} \rightarrow 
    \mathit{State} \times \mathit{Value}
  \]
\caption{Declaration of \textit{eval}\label{fig:eval}}
\end{figure}

\begin{figure}[t]

\[
  \mathit{State :: (Mem, FrameId, NRFrames)}
\]

\caption{State of the interpreter\label{fig:state}}
\end{figure} 

The \textit{State} of the \textit{eval} is shown in figure~\ref{fig:state}:
where the definitions for \textit{Mem}, \textit{FrameId} are given earlier in this chapter. The field \textit{NRFrames}
gives the number of frames allocated so far. Remember at this point that the interpreter includes \textit{explicit frame 
allocation} and this number is the \textit{goal number} for the tail-call optimisation, that will be presented in a 
later section.

The structure \textit{FunctionsMap} is a stucture that is created at compile time and it remains alive in the runtime 
as well. It does not change during the execution of the program and is a \textit{map} of key-value pair, where:
\begin{itemize} 
  \item Keys are the names of top-level functions.
  \item Values are a pair of formal parameters with their static information (evaluation order, type) 
  of the function and the body of the function.
\end{itemize}

The data definition of the aforementioned structure is shown in figure~\ref{fig:functionsmap}:
\begin{figure}[h]
\begin{minted}{haskell}
  type FN = String 
  data FunctionsMap = Map FN ([Formal], Expr)
\end{minted}
\caption{FunctionsMap\label{fig:functionsmap}}
\end{figure}
The result of the interpreter is the result of the execution of the body of the top-level function \textit{main}. 
This function is a special case of a function and is assumed not to have any arguments. So, the initial expression 
\textit{expr0} is: 
\begin{minted}{haskell}
  (_, expr0) = Map.lookup "main" functionsMap
\end{minted}
% \newline

The \textit{initial state} for the interpreter's execution to start with, is:
\begin{figure}[h]
\[ 
  \mathit{State0 = (mem0, frameId0, nr\_frames0) }
\]
\caption{Initial state of the interpreter\label{fig:state0}}
\end{figure}
, where:
\begin{itemize}
  \item The initial state of memory, called \textit{mem0}, is:
    \begin{minted}{haskell}
      -- cTOPFRAMED: last frame id available when execution starts
      mem0   = push (Mem Map.empty 0) frame0 
      frame0 = Frame "main" [] [] cTOPFRAMEID 
    \end{minted}
  \item The initial id of the last frame id that lives in the memory is given by:
    \begin{minted}{haskell}
      frameId0 = lastFrameId mem0
    \end{minted}
  \item The initial number of frames allocated, before eval starts execution are:
    \begin{minted}{haskell}
      nr_frames = 1
    \end{minted}
  as we have \textit{one} frame allocation for "main" function.
\end{itemize}

At this point, we have everything set up. We declared the interpreter's function \textit{eval} and we have an initial 
state to start our eval with. Now, let's dive into the execution of each expression of the syntax tree of our language 
presented in section~\ref{sec:syntax}. Minor implementation details are omitted for clarity; at first we assume laziness everywhere, 
while later there will be an overview of how the interpreter runs in the presence of ML-lists.

We finally begin our pattern matching on the expressions. The \textit{FunctionsMap} structure is also omitted as 
eval's argument; we assume that we lookup this for formals and we want to jump to a function's body, e.g. in the function  
call expression.

In every execution step our \textit{eval} is looking up the current state. As we have already mentioned the state is 
a record of:
\begin{minted}{haskell}
  State = (Mem, FrameId, NRFrames) 
  -- FrameId: id of the current frame
\end{minted}
and thus by looking up the current's state frame, we can obtain the environment, as following:
\begin{minted}{haskell}
  thisFrame = getFrame mem frameId 
  Frame caller funArgs susps prevFrameId = thisFrame 
\end{minted}

In this way, we have information about:
\begin{itemize}
  \item \textit{caller}: the name of the caller function we are currently in,
  \item \textit{funArgs}: the current function' s actual arguments that are built for the frame (see later how we build these 
  arguments when a function call is invoked), 
  \item \textit{susps}: suspended executions for constructors forced by pattern matching, 
  \item \textit{prevFrameId}: The id of the previous frame, just like having a pointer to the previous frame.
\end{itemize}

After the necessary information from the current state is obtained, the intepreter handles each one of the expressions
in the following way, presented in the following sections.

\subsection{Variable lookup}

We remind at this point that a variable bound at case pattern matching is not evaluated here because of the constructor 
projection transformation we described earlier in section~\ref{sec:other-transformations}, and thus in this section we are concerned about evaluation 
of top-level variables. 

A top-level variable exists in the formal parameters of a function definition. In \textit{frame's terms}, 
we are looking for the proper \textit{FrameArg} in the \textit{funArgs} field, mentioned earlier when we explained 
the interpreter's \textit{current state}.

The procedure is the following (this is equivalent to lookup the variable inside the environment):
\begin{itemize}
  \item First, we find the position of the variable in the current frame.
  \begin{itemize}
    \item Lookup the \textit{caller} function in the \textit{FunctionsMap} structure to find the function's 
    \textit{signature}.
    \item Once the signature is found, then we find the position in formal parameters of the function definition, 
    i.e. the \textit{index (i)} of the argument.
  \end{itemize} 
  \item Given the index that we found earlier, we find the proper frame argument in the current frame. 
\end{itemize}

Once we have found the proper frame argument, we have \textit{three} cases, depending whether the variable is in cbv, cbn or lazy 
evaluation order (we use the abbrevation e.o. which stands for evaluation order). 

Later, we give the v' and s' for:
  $ \mathit{eval (v, s) = (v', s')} $

  \begin{itemize}
    \item cbv e.o.: Variable lookup operation for call-by-value 
          variables is shown in figure~\ref{fig:cbv-varLookup}.
      \begin{figure}[t]
      \hrule
        \begin{align*}
           & \mathit{(v', s') = (val, s),} \\
           \mathit{where} \\ 
           & \mathit{v = StrictArg \hfill\ val}
        \end{align*}
      \caption{Variable lookup for call-by-value\label{fig:cbv-varLookup}}
      \end{figure}
    \item cbn e.o.: Variable lookup operation for call-by-value 
    variables is shown in figure~\ref{fig:cbn-varLookup}.

    We note that whatever is the new interpreter's state \textit{s''}, we do not memoize it, as call-by-name semantics 
    does not include any change of the memory's state.

    \begin{figure}[t]
      \begin{align*}
        & \mathit{ (v', s') = (val, s), \hfill\ where } \\
        & \mathit{ v = ByNameArg \hfill\ expr, } \\
        & \mathit{(val, s'') = eval \hfill\ expr \hfill\ (mem, prevFrameId, nr\_frames)} \\
      \end{align*}
    \caption{Variable lookup for call-by-name\label{fig:cbn-varLookup}}
    \end{figure}      

    \item lazy e.o.: In this case (figure~\ref{fig:lazy-varlookup}) we have \textit{two} subcases.
    The subcases are whether \textit{b} is \textit{true} or \textit{false}, i.e. the lazy argument is evaluated and cached or
    not evaluated. In the latter case, the interpreter needs to evaluate the variable and update the frame, as shown below,
    in the appropriate case:

    \begin{figure}[t]
      \[\mathit{v = LazyArg \hfill\ e \hfill\ b \hfill\ val}\]
      
      \begin{itemize}
          \item \textit{b} is \textit{true}: \[ \mathit{(v', s') = (val, s)} \]
          \item \textit{b} is \textit{false}:
            \begin{align*}
                & \mathit{(v', s') = (val', (updFrame \hfill\ mem' \hfill\ frameId \hfill\ frame', frameId, nr\_frames')), where} \\
                & \mathit{(val', (mem', frameId', nr\_frames')) = eval \hfill\ e \hfill\ (mem, prevFrameId, nr\_frames)} \\
                & \mathit{frame'[funArgs] = ( funArgs[i] = LazyArg \hfill\ e \hfill\ true \hfill\ val' )} \\
            \end{align*}
      \end{itemize}
    \caption{Variable lookup for call-by-need\label{fig:lazy-varlookup}}
    \hrule
  \end{figure}


  We note that, at this point, where memory change happens, and probably evaluation of the expression provokes 
  the creation of new frames, we update the memory state as well as the frame counter. 

  \end{itemize}
  
\subsection{Function call}

In this section, we describe the interpreter for a function call. The call is of the form:
\[ 
  \mathit{Expr = Call \hfill\ callee \hfill\ actuals,} 
\]
where we have the information about \textit{callee}'s name and the actual parameters from the function call. 

\begin{figure}[htp]
  \[ \mathit{makeArgs :: [Actual] \times [Formal] \times State \rightarrow [FrameArg] \times State}, \]
\caption{Construction of frame arguments\label{fig:makeArgs}}
\end{figure} ~
\begin{figure}[htp]
  \begin{align*}
    \mathit{(v, state') = eval \hfill\ actual \hfill\ state} \\
    \mathit{frameArg = StrictArg \hfill\ v}
  \end{align*}
\caption{Construction of call-by-value frame argument\label{fig:makeCBVArg}}
\end{figure} ~
\begin{figure}[htp]
  \[ 
    \mathit{frameArg = ByNameArg \hfill\ actual} 
  \] 
\caption{Construction of call-by-name argument\label{fig:makeCBNArg}}
\end{figure} ~
\begin{figure}[htp]
  \[
    \mathit{frameArg = LazyArg \hfill\ actual \hfill\ false \hfill\ empty} 
  \]
\caption{Construction of lazy argument\label{lazyArgConstruction}}
\end{figure} ~
\begin{figure}[htp]
  \begin{align*}
    & \mathit{eval \hfill\ (Call \hfill\ callee \hfill\ actuals, s) = (val, s'''),} \\ \mathit{where} \\
    & \mathit{(formals, funBody) = lookup \hfill\ callee \hfill\ FunctionsMap} \\
    & \mathit{(frameArgs, (mem', \_, nr\_frames')) = makeArgs \hfill\ actuals \hfill\ formals  \hfill\ state} \\
    & \mathit{newFrame = Frame \hfill\ callee \hfill\ frameArgs \hfill\ [] \hfill\ frameId} \\
    & \mathit{mem'' = push \hfill\ mem' \hfill\ newFrame \hfill\ (nr\_frames + 1) \hfill\ frameId} \\
    & \mathit{s' = (mem'', lastFrameId \hfill\ mem'', nr\_frames + 1)} \\
    & \mathit{(val, s'') = eval \hfill\ funBody \hfill\ s'} \\
    & \mathit{(s'' = (mem''', _, nr\_frames''))} \\
    & \mathit{s''' = (mem''', frameId, nr\_frames'')}
  \end{align*}
\caption{Operational semantics for function call\label{fig:functionCall}}
\end{figure}

% \pagebreak

First, we are going to present a function about constructing the function's arguments, given the actual parameters of the call 
and the formal parameters from the function's signature, lying in the function definition in \textit{FunctionsMap}. So, let's 
pause for a while for the definition of this function, and then resume later for function call handling inside the 
interpreter.

The function, called \textit{makeArgs} has the form, that is shown in figure~\ref{fig:makeArgs},
where the actuals and the formals are explained above and the \textit{State} is the interpreter's 
current state.For every actual corresponding to every formal, we have the following, depending 
whether the parameter is in cbv, cbn or lazy evaluation order(abbr. e.o):
\begin{itemize}
  \item cbv e.o.: As shown in figure~\ref{fig:makeCBVArg} the function returns \textit{(frameArg, state')}, where 
  \textit{frameArg} is added to \textit{[FrameArg]} and \textit{state'} is the next input state for 
  \textit{makeArgs}. 
  \item cbn e.o.: As shown in figure~\ref{fig:makeCBNArg}, the state remains unchanged and thus 
  \textit{(frameArg, state)} is returned.
  \item lazy e.o.: As shown in figure~\ref{lazyArgConstruction} the state does not change, 
  and thus \textit{(frameArg, state)} is returned.  
\end{itemize}

As it seems above, only cbv arguments are executed at this point, and the memory change they provoke, 
is returned in the state of the \textit{eval} function.

Now, it' s time to resume the presentation about the function call in the interpreter.
The operational meaning of a function call is shown in figure~\ref{fig:functionCall}. 
Every time we have a function call a new frame is pushed to the memory. Then, the interpreter 
evaluates the body of the function, and finally we reset the environment for the next operation 
handled by the interpreter.



\subsection{Pattern matching}

As we have shown in section~\ref{sec:syntax}, we distinguish between pattern matching on integers and pattern matching on data. 
More specifically a branch for a pattern matching is:
\begin{minted}{haskell}
  type Branch  = (Pattern, Expr)
  data Pattern = CPat { tag :: CN, vars :: [VN] } -- pattern matching on constructors 
               | IPat { pattVal :: Int }          -- pattern matching on integers 
\end{minted}

\begin{figure}[htp]
  \begin{align*}
    \mathit{caseExpr = Case \hfill\ caseId \hfill\ e \hfill\ branches}
  \end{align*}
\caption{Case expression\label{fig:case}}
\end{figure} ~
\begin{figure}[htp]
  % \hrule
  \begin{align*}
    &  \mathit{eval \hfill\ (e, s) = (e', s'),}  \\
    \mathit{where} \\
    &  \mathit{s' = (mem', savedFrameId, n), \hfill\ and} \\
    &  \mathit{e' = VI \hfill\ i, \hfill\ integer \hfill\ pattern \hfill\ matching, or} \\
    &  \mathit{e' = VC \hfill\ c, \hfill\ constructor \hfill\ pattern \hfill\ matching} \\
    &  \mathit{c = Susp \hfill\ (cn, \_) \hfill\ \_}  
  \end{align*}
\caption{Evaluation of the scrutinee\label{fig:scrueval}}
\end{figure} ~
\begin{figure}[htp]
  \setlength{\jot}{-3pt}%
  \begin{align*}
    & \mathit{eval \hfill\ (caseExpr, s) = (eval \hfill\ e'' \hfill\ s', s'),} \\
    \mathit{where} \\
    & \mathit{e'' = lookup \hfill\ (IPat \hfill\ i) \hfill\ cases} \\
    % \mathit{, and} \\
    & \mathit{\textit{s'} \hfill\ is \hfill\ the \hfill\ state \hfill\ after \hfill\ scrutinee's 
    \hfill\ evaluation.}
  \end{align*}
\caption{Integer pattern matching operational semantics\label{fig:intPattMatch}}
\end{figure} ~
\begin{figure}[htp]
  \begin{align*}
    & \mathit{eval \hfill\ (caseExpr, s) = (eval \hfill\ e'' \hfill\ s'', s''), } \\ 
    \mathit{where} \\
    & \mathit{pattIndex = indexOfPattern \hfill\ cn \hfill\ patterns} \\
    & \mathit{(\_, e'') = branches \hfill\ [pattIndex]} \\
    & \mathit{susps' = (caseId, c) \hfill\ : \hfill\ susps} \\
    & \mathit{frame' = Frame \hfill\ caller \hfill\ funArgs \hfill\ susps' \hfill\ prevFrameId} \\
    & \mathit{s'' = (updFrame \hfill\ mem' \hfill\ frameId \hfill\ frame', \hfill\ frameId, \hfill\ n)}
  \end{align*}
\caption{Pattern matching on constructors operational semantics\label{fig:consPattMatch}}
% \hrule
\end{figure}



The case expression is shown in the figure~\ref{fig:case}. For its evaluation, the interpreter 
does the following:~
\begin{itemize}
  \item First, we evaluate the scrutinized expression, shown in figure~\ref{fig:scrueval}.
  \item Next, in figure~\ref{fig:intPattMatch} we show how the interpreter works for 
        integer pattern matching.
  \item Finally, the pattern matching on constructors is shown in figure~\ref{fig:consPattMatch}.
\end{itemize}


In the above definitions, \textit{indexOfPatterns} gives as output the index of the pattern 
in the \textit{patterns} list, and this list is retrieved by the \textit{branches} list 
by ignoring the second value.

Integer pattern matching cannot be exhaustive, because integer domain consists of infinite elements, and thus we 
assume that \textit{IPat i} is a pattern that exists in the patterns list. Otherwise, the interpreter will throw an exception.


We note that even though our interpreter works for lists, this is applied to every data constructor, 
when `case' works in the same way as Haskell's builtin `case'. The `constructor' representation 
would be the same for every constructor definition, as constructors are also functions themselves. 
The latter is obvious taking into consideration that we work on a functional language; 
a programming language with \textit{functions as first-class citizens}.

\subsection{Constructor application}

In the case of having a constructor application of a \textit{lazy data constructor},
this is equivalent to a memory allocation of a thunk. In our case, this is 
a suspended execution of lazy data constructor, the one explained in section~\ref{sec:suspended}.
More specifically, the \textit{eval} for a lazy constructor application 
is shown in figure~\ref{fig:consAppl}.

\begin{figure}[h]
  \begin{align*}
    & \mathit{eval \hfill\ (ConstrF \hfill\ tag \hfill\ exprs, s) = (VC \hfill\ (Susp \hfill\ (tag, exprs) \hfill\ frameId), s)} \\
    \mathit{, where} \\
    &  \mathit{\textit{frameId}: \hfill\ the \hfill\ id \hfill\ of \hfill\ the 
    \hfill\ current \hfill\ frame \hfill\ existing \hfill\ in \hfill\ the \hfill\ interpeter's 
    \hfill\ state,} \\
    &  \mathit{\textit{tag}: \hfill\ the \hfill\ name \hfill\ of \hfill\ the \hfill\ 
    constructor.}
  \end{align*}
\caption{Lazy list constructor application operational semantics\label{fig:consAppl}}
\end{figure} ~
% \begin{figure}[h]
%   \begin{align*}
%     & \mathit{eval~(SHConstrF~tag~(e~:~es), s) = (VC~(Susp~(tag, (e'~:~es))~frameId), s')} \\
%     & \mathit{(e',s') = eval~(e, s)}
%   \end{align*}
% \caption{Strict head list constructor application\label{fig:shconsAppl}}
% \end{figure} ~
% \begin{figure}[h]
%   \begin{align*}
%     & \mathit{eval~(STConstrF~tag~(e~:~es), s) = (VC~(Susp~(tag, (e~:~es'))~frameId), s')} \\
%     & \mathit{(es',s') = eval~(es, s)}
%   \end{align*}
% \caption{Strict tail list constructor application\label{fig:stconsAppl}}
% \end{figure} ~
% \begin{figure}[h]
%   \begin{align*}
%     & \mathit{eval~(MLConstrF~tag~(e~:~es), s) = (VC~(Susp~(tag, (e'~:~es'))~frameId), s'')} \\
%     & \mathit{(e',s') = eval~(e, s)} \\
%     & \mathit{(es', s'') = eval~(es, s')}
%   \end{align*}
% \caption{ML-list constructor application\label{fig:mlconsAppl}}
% \end{figure}

% \newpage

\subsection{Constructor projection}

In this case, the interpreter has come across a variable bound by 
pattern matching. As we mentioned earlier (section~\ref{sec:lazy-data-cons}), the evaluation
of a term is forced, when such variables are needed to be evaluated.
The \textit{eval} function of \textit{constructor projection} is shown in 
figure~\ref{fig:consproj}. ~
\begin{figure}[htp]
  \begin{align*}
    & \mathit{eval \hfill\ (CProj \hfill\ caseId \hfill\ cpos, s) = (val, s'),} \\
    \mathit{where } \\
    & \mathit{s' = mem' \hfill\ frameId \hfill\ nr\_frames'} \\
    & \mathit{susp = lookup \hfill\ cid \hfill\ susps} \\
    & \mathit{Susp \hfill\ (\_, el) \hfill\ savedFrameId = susp} \\
    & \mathit{e' = el[cpos]} \\
    & \mathit{(val, (mem', \_, nr\_frames')) = eval \hfill\ (e', s)}
  \end{align*}
\caption{Constructor projection operational semantics\label{fig:consproj}}
\end{figure} ~
First, we find the $\mathit{susp}$ inside the $\mathit{susps}$ in the current frame. Then, 
from the expression list $\mathit{el}$ we find the right constructor in the $\mathit{cpos}$ 
position. After evaluating this expression, we have the result-value and the next state 
for our interpreter.

\chapter{Analysis: Searching for optimisation opportunities}
\label{ch:analysis}

In this chapter, we present the analysis performed in order to reveal true tail-call positions.
First, we make some important high-level definitions for the reader to be able to follow up. 
The presentation of the algorithms for each one of the optimisations will follow; section~\ref{sec:classic-tco-analysis} contains 
the algorithm for classic tail-call optimisation and section~\ref{sec:modulo-cons-analysis} contains the algorithm for tail recursion modulo cons.

The input of the analysis is the core level language described in section~\ref{sec:syntax}, 
along with the operational semantics provided in the previous chapter. The output is appropriately 
\textit{annotated} function calls which the enriched evaluator of the next chapter is going to handle.
The analysis in this chapter reveals \textit{where} to apply the optimisations, while 
in the next chapter we present \textit{how} to actually perform the optimisations in the runtime system.



% Analysis chapter 

\section{Classic tail-call optimisation}
\label{sec:classic-tco-analysis}

At this point, we shall make clear that the terms tail-call or tail-call position are not the same 
as tail-call optimisable, providing the definitions shown below.

\subsection{Tail-call position (tail-call) vs. Tail-call optimisable (true tail-call)}

\paragraph{Definition 6.1}
A function call is in \textit{tail call position}, or \textit{tail call}, \textit{if and only if} its execution is the last action 
performed before the function returns.

\paragraph{Definition 6.2}
A function call is \textit{tail call optimisable}, or \textit{true tail call}, \textit{if and only if} it is in tail call position and it satisfies the rules shown in 
section~\ref{sec:data-driven-analysis}.\\

The same definitions also stand for tail recursion modulo cons, if we substitute \textit{tail-call} with 
\textit{tail recursion modulo cons}; an equivalent section is omitted for section~\ref{sec:modulo-cons-analysis}.

In the next sections, we present the path from \textit{function calls} in the core language to \textit{tail-call positons}, 
and from there to \textit{true tail-calls}; that is function calls that are actually optimisable. The latter is annotated as a new 
expression in the core language, called \textit{TailCall}. When the interpreter comes across this expression, it performs the 
optimisation, while the program is executing.

\subsection{Control-flow analysis: Spotting tail-call positions}
\label{sec:control-flow}

For a call-by-value language, this step reveals each and every true tail-call position. For a language with mixed evaluation order, and specifically 
with call-by-need semantics this is not enough, as it has been already sketched in section~\ref{sec:example2}, as lazy arguments are arbitrarily evaluated and thus 
they escape their context. 

This is a local analysis, performed locally in a function's body. The analysis is summarized in the following rules:
\begin{itemize}
  \item The body of a lambda (or a function) is a tail call.
  \item When an if/case expression is in tail call position, then the right hand side of the branches is in tail-call position. 
  In the case of an `if' expression, this means that then/else clause is in tail call position.
  \item Nothing else is in tail call position.
\end{itemize}

To illustrate the above, let's consider the following, very simple example:
\begin{minted}{haskell}
  foo n = 
    if n > 0  
      then n * foo (n-1) 
      else 1
\end{minted}

The body of `foo' function is in tail call position. This means that `if', which is the body, is in tail call position. 
Thus, then/else are tail calls. Now in the `then' clause, where the multiplication takes place, the call to `foo' is not in tail call position, 
according to the third rule.

But if we had the following example:
\begin{minted}{haskell}
  foo n res = 
    if n > 0 
      then foo (n - 1) (n * res)
      else res
\end{minted}
then the call is in tail-call position as the `then' clause is in tail-call position.

\subsection{Data-driven analysis: Revealing true tail-calls}
\label{sec:data-driven-analysis}

After revealing tail-call position, deriving from the control flow of the program shown in the previous section, now we apply some rules in order to 
reveal true tail call positions, depending by the evaluation order of caller and callee function. After all, tail-call optimisation 
is all about passing the control from the caller to the callee. This step is omitted in call-by-value languages as there is 
only one evaluation order and the semantics allow the optimisation quite naturally.

Although it seems that the rules are applied in a second analysis pass, this is done for clarity 
purposes; in the implementation we can do that in-place, in a single analysis pass just after a 
tail call (and thus potentially a true tail call) is revealed.

The rules for a potential tail call (revealed by control flow analysis from 
section~\ref{sec:control-flow}) to be a true tail call are:
\begin{itemize}
  \item Actual parameters in the function call are not dependent by the formal parameters of 
  the caller function. For example, these actual parameters can be constants. 
  \item Actual parameters in the function call are variables. If they are variables we can 
  statically predict when the runtime mutation is possible. The reader can also refer to 
  figure~\ref{fig:mutate} for possible cases. We perform the mutation for all the nine 
  combinations, except for a subcase in two cases. 
  \item Actual parameter is an expression, but it is in call-by-value position. In this case, we 
  have two subcases:
    \begin{itemize}
      \item The expression is a base type expression. This is easier as such expressions,
      when they are evaluated, they reduce to a base type value and thus they do not leave thunks. 
      In this subcase, we could also have data like ML-lists, which also reduce to a value.
      \item The expression is constructed data. In this case, we find all variables inside the 
      expression. If these variables are reduced to value (base type values or deeply evaluated 
      data), then the function call is tail-call optimisable.
    \end{itemize}
\end{itemize}

Function calls that are not subject to the rules above are not tail call optimisable.


\section{Tail recursion modulo cons}
\label{sec:modulo-cons-analysis}

% \subsection{Control-flow analysis: Spotting tail recursion modulo cons positions}

Tail recursion modulo cons can be applied to any constructor application, that is guarded by a lazy constructor.
In our language this happens to (:), which is lazy and is the constructor for lists. It could also be applied 
to arithmetic operations, for example in Haskell, but in our language all arithmetic operations are strict.

The control flow of the program also reveals the tail recursion modulo cons in the same way as in classic tail 
calls. The only difference is that constructor application must be a tail call. Thus the rules for tail recursion 
modulo cons have the following form:
\begin{itemize} 
  \item The body of a lambda (or a function) is a tail call and it is also a lazy constructor application
  (instead of a function application).
  \item When an if/case expression is in tail call position, then the right hand side of the branches is in tail-call position. 
  In the case of an `if' expression, this means that then/else clause is in tail call position. The right hand side 
  of a branch must also be a lazy constructor application.
  \item Nothing else is in tail recursion modulo cons position.
\end{itemize}

% \subsection{Data-driven analysis: Revealing true tail recursion modulo cons positions}

The additional rule for tail recursion modulo cons is that if you have a tail call of the form:
\begin{minted}{haskell}
  x : y
\end{minted}
then \textit{`x'} must not contain any recursive calls and \textit{`y'} must be a function call that is subject to the 
rules presented in section~\ref{sec:data-driven-analysis}; in this way frame mutation will become possible. If the last rule is applied, 
then we can have \textit{x `:' tail recursive call to the function}. Details on that will be presented later, in section~\ref{sec:tco-modulo-cons-eval}.


% \section {Intermediate list node removal}
% Sharing problem 
% Arithmetic operators blah blah blah
% Global analysis

\chapter {Runtime evaluator for optimisations}
\label{ch:evaluator}

In this chapter, we will present how the optimisations are implemented in the interpreter.
More specifically there will be presented:
\[ \mathit{eval \hfill\ (e, s) = (e', s')} \]
where:
\begin{itemize}
\item in section~\ref{sec:classic-tco-eval} we have the evaluation of tail-call optimisation, first expression 
      shown in figure~\ref{fig:annos},
\item and in section~\ref{sec:tco-modulo-cons-eval} we have the evaluation of tail recursion modulo cons shown
      also in figure~\ref{fig:annos}.
\begin{figure}[h]
  \begin{align*}
    & \mathit{e = TailCall \hfill\ callee \hfill\ actuals} \\
    & \mathit{e = TRMC \hfill\ tag \hfill\ exprs} 
  \end{align*}
\caption{Annotated expressions\label{fig:annos}}
\end{figure}

\end{itemize}
The first is the classic tail-call optimisation, while the latter is the tail-recursion 
modulo cons. There will be a comprehensive explanation of how we mutated the frames and how we counted them for 
our evaluation, that follows in the next chapter.

\section {Evaluator for classic tail-call optimisation}
\label{sec:classic-tco-eval}

Classic tail call evaluation contains one major \textit{operation}, which makes the optimisation 
feasible: this is \textit{frame mutation}. This operation includes the replacement of the current frame's arguments 
with the arguments necessary for the construction of the frame for the next function call. For this operation,
it is mandatory that the caller's arguments do not escape and for those that escape we correctly passed them 
to the new frame. 

The \textit{eval} for the \textit{TailCall} follows in figure~\ref{fig:tco}; we remind that this is actually optimisable as the analysis 
revealed, although we make few, inexpensive extra checks for some cases.
The functionality of \textit{checkMutate} will be explained later on in this section. The other variables 
, shown in figure~\ref{fig:tco} are:
\begin{itemize}
  \item \textit{formals} are the formal parameters of the function definition of the callee function,
  \item \textit{actuals} are the actual parameter of this tail-call optimisable function call,
  \item \textit{funArgs} are the arguments inside the current frame, 
  \item and \textit{s} is the current state of the interpreter.
\end{itemize}


\begin{figure}[h]
  \begin{align*}
    & \mathit{eval \hfill\ (TailCall \hfill\ callee \hfill\ actuals, s) = (e', s'),} \\
    \mathit{where} \\
    & \mathit{(formals, funBody) = lookup \hfill\ FunctionsMap \hfill\ callee} \\
    & \mathit{e' = eval \hfill\ (funBody, s')} \\
    & \mathit{s' = checkMutate \hfill\ formals \hfill\ actuals \hfill\ funArgs \hfill\ s} 
  \end{align*}
\caption{Tail-call optimisation operational semantics \label{fig:tco}}
\end{figure}


At this point, we are ready to provide the definition for \textit{checkMutate}, which 
is a function that given the current interpreter's state performs the runtime mutation 
of the frame and produces the next state of the interpreter. Its declaration is given in 
the figure~\ref{fig:checkdecl} and the operational meaning of the function in the 
figure~\ref{fig:checkMutate}.

\begin{figure}[h]
  \begin{align*}
    \mathit{checkMutate :: [Actual] \times [Formal] \times [FrameArg] \times State \rightarrow State} 
  \end{align*}
\caption{Declaration of $\mathit{checkMutate}$ operation\label{fig:checkdecl}}
\end{figure}

 

\begin{figure}[h]
  \begin{align*}
    & \mathit{checkMutate \hfill\ (actuals, formals, funArgs, s) = s', } \\
    \mathit{where } \\
    & \mathit{(mem, frameId, nr\_frames) = s} \\
    & \mathit{(callerFormals, \_) = lookup \hfill\ callee \hfill\ FunctionsMap} \\
    & \mathit{(funArgs', s'') = mutate \hfill\ callerFormals \hfill\ formals \hfill\ funArgs \hfill\ actuals \hfill\ s } \\
    & \mathit{(mem', frameId', nr\_frames') = s''} \\
    & \mathit{frame'' = Frame \hfill\ callee \hfill\ funArgs' \hfill\ [] \hfill\ prevFrameId} \\
    & \mathit{s' = (updFrame \hfill\ mem' \hfill\ frameId \hfill\ frame'', frameId, nr\_frames')}
  \end{align*}
\caption{Operational semantics for \textit{checkMutate}\label{fig:checkMutate}}
\end{figure}

Now, we are going to describe an auxiliary function used in order to constructor 
the function's arguments of the mutated frame; specifically in the definition of 
\textit{funArgs'} the function called \textit{mutate}.
The operational semantics for \textit{mutate} operation is shown in figure~\ref{fig:mutate}.
From the figure, we have that \textit{mutate} is a function that takes as input:
\begin{itemize}
  \item The formal parameters of the caller function,
  \item the formal parameters of the callee function,
  \item the frame arguments that exist in the current frame (the one we want to mutate),
  \item the actual parameter of the function call, which is tail-call optimisable,
  \item the current state of the interpreter, 
\end{itemize}
and produces:
\begin{itemize}
  \item The frame arguments for the new frame. We note here that we want to turn the actual parameters 
  of the function call into the appropriate frame arguments, using the function signatures of the caller and the callee.
  Specifically, we are interested in the format of the arguments, and thus we need to know the evaluation 
  order of the functions.
  \item The next state for the interpreter. Because evaluation \textit{may} take place, while this function is executing 
  (for example we need to turn a lazy frame argument into a strict and thus we perform the evaluation before 
  we jump into the callee function's body), we need to change the memory state and count the frames correctly
  for our evaluation that follows in the next chapter.
\end{itemize}

As the language is first-order, it does not support partial applications, and thus the number of arguments 
in the actual parameters list is equal to the number of formals of the callee function. The \textit{mutate} function 
terminates when these two lists are empty at the same iteration, or else it throws an exception. Its execution starts 
and continues until it terminates by processing each and every actual parameter of the function call. The result is 
a list that accumulates the result of every iteration. 


\begin{figure}[h]
  $\mathit{getIndex :: VN \times EvaluationOrder \times Type \times [Formal] \rightarrow Index}$ \\
  $\mathit{getIndex~(vn,~eo,~type)~fs=elemIndex~(vn,(eo,type))~fs}$ \\
  \\
  $\mathit{getEvaluationOrder :: Formal \rightarrow EvaluationOrder} $ \\
  $\mathit{getEvaluationOrder :: (\_, (eo, \_)) = eo}$ \\
  \\%
  $\mathit{signOfVar :: [Formal] \times VN \rightarrow EvalutionOrder \times Type } $ \\
  $\mathit{signOfVar~formals~vn = lookup~vn~formals}$ \\
  \\%
  $\mathit{transform :: CallerEO \times CalleeEO \times FrameArg \times 
            State \rightarrow FrameArg \times State}$ \\
  $\mathit{transform~(CBV, CBV, arg, s) = (arg, s)}$ \\
  $\mathit{transform~(CBN, CBN, arg, s) = (arg, s)}$ \\
  $\mathit{transform~(Lazy, Lazy, arg, s) = (arg, s)}$ \\
  $\mathit{transform~(CBV, CBN, ByNameArg~e, s) = (StrictArg~v, s'),}$ \\
  $\mathit{\hspace*{1em} where~(v, s') = eval~(e, s)}$ \\
  $\mathit{transform~(CBV, Lazy, LazyArg~e~b~v, s) = 
              if~b~then~(StrictArg~v, s)~else~(val, s'),}$ \\
  $\mathit{\hfill\ \hfill\ where~(val, s') = eval~(e, s)} $ \\
  $\mathit{transform~(CBN, CBV, StrictArg~(VI~v),s)=(ByNameArg~(EInt~v),s)}$ \\
  $\mathit{transform~(CBN, CBV, StrictArg~(VC~c),s)=error}$ \\
  $\mathit{transform~(CBN, Lazy, LazyArg~e~true~(VI~v), s) = (ByNameArg~(EInt~v), s)}$ \\
  $\mathit{transform~(CBN, Lazy, LazyArg~e~true~(VC~c), s) = error}$ \\
  $\mathit{transform~(CBN, Lazy, LazyArg~e~false~v, s) = (ByNameArg~e, s)}$ \\
  $\mathit{transform~(Lazy, CBV, StrictArg~v, s) = (LazyArg~e~true~v, s)}$ \\
  $\mathit{transform~(Lazy, CBN, ByNameArg~e, s) = (LazyArg~e~false~null, s)}$ \\
  \\%
  $\mathit{mutate :: [Formal] \times [Formal] \times [FrameArg]
            \times [Actual] \times Index \times State \rightarrow [FrameArg] \times State} $ \\
  $\mathit{mutate~(\_,~[],\_,[],\_,~acc,~s)=(acc,~s)}$ \\
  $\mathit{mutate~(callerfs,~calleefs,~args,~(EVar~v~:~as),~ix,~acc,~s)}$ \\
  $\mathit{\hfill\ =~mutate~(callerfs,~calleefs,~args,~as,~(ix+1),(arg'~:~acc), ~s')}$ \\
  $\mathit{\hfill\ \hfill\ where~calleeEO=getEvaluationOrder~calleefs[ix]}$ \\
  $\mathit{\hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ 
            sign@(callerEO, callerType) = signOfVar~(vn, callerfs)}$ \\
  $\mathit{\hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ 
            callerIx = getIndex~(vn, sign)~callerfs}$ \\
  $\mathit{\hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ 
            arg = args[callerIx]}$ \\
  $\mathit{\hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ 
            (arg', s') = transform~(calleeEO, callerEO, arg, s)}$ \\
  $\mathit{mutate~(callerfs,~calleefs,~args,~(a@(EInt~n)~:~as),~ix,~acc,~s)}$ \\
  $\mathit{\hfill\ =~mutate~(callerfs,~calleefs,~args,~as,~(ix+1),(arg~:~acc), ~s)}$ \\
  $\mathit{\hfill\ \hfill\ where~calleeEO=getEvaluationOrder~calleefs[ix]}$ \\
  $\mathit{\hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ 
      if~calleeEO=CBV~then~StrictArg~(VI~n)~else~if~calleeEO=CBN~then~ByNameArg~a~else~LazyArg~a~false~null}$ \\
  $\mathit{mutate~(callerfs,~calleefs,~args,~(a~:~as),~ix,~acc,~s)}$ \\ 
  $\mathit{\hfill\ =if~calleeEO=CBV~then~mutate~(callerfs,~calleefs,~args,~as,~(ix+1),(arg'~:~acc), ~s')}$ \\
  $\mathit{\hfill\ \hfill\ where~calleeEO=getEvaluationOrder~calleefs[ix]}$ \\  
  $\mathit{\hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ 
            (v, s') = eval~(a, s)}$ \\
  $\mathit{\hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ 
            arg'=StrictArg~v}$ \\
\caption{Operational semantics for $\mathit{mutate}$ operation\label{fig:mutate}}
\end{figure}

\section {Evaluator for tail recursion modulo cons}
\label{sec:tco-modulo-cons-eval}

mpla mpla mpla 

\chapter {Evaluation of the optimisations}
\label{ch:evaluation}

Write about the interpreter again for each case.

How it counts the frames. 

Give graph results from the microbenchmarks.

\chapter{Related work}
\label{ch:related}

Implementations of programming languages use a stack for function calls, 
where stack frames (or \emph{activation records}) are pushed for every function invocation: this permits recursion 
and has good performance. Stack allocation for function calls has been an old technique, 
dating back at least to ALGOL~\cite{Dijkstra60,Naur78} and LISP~\cite{McCarthy60,Stoyan79}.

Tail calls are function calls that happen last inside a function and
they can be implemented with a ``go to'' instruction. In the special
case that the caller's frame will not be needed again, \emph{tail-call
  optimization} can reuse it to construct the frame of the callee,
saving space, and making some programs run in constant
space. Tail calls can be further optimized by the
instruction-scheduling stage of a compiler~\cite[\S12.4.3]{Torczon12}.
Tail calls have been used to transform recursive functions to
iterative (tail-recursive)
ones~\cite[\S{9}]{McCarthy62}\cite{Barron68}.  Tail-call optimization
is an old idea~\cite[p.~7]{Gill65}\cite[p.~21]{Knuth74}, which is an
established part of modern compilers.

Some languages and implementations often offer features that are not
easy to compose with tail-call optimization. Frames may
not be resized in-place for languages that support
coroutines~\cite[p.~60]{Waite84}. Languages that support first-class
continuations~\cite{Sperber10}, higher-order return
values~\cite[p.~103]{Appel92}\cite{Steele78},
backtracking~\cite{Bobrow73}, or non-strict evaluation, and
implementations in continuation-passing style~\cite[p.~103]{Appel92},
may allocate frames on the heap. 

Tail-call optimization is also important for implementations of logic languages~\cite{Bigot99},
functional programming languages running on the Java virtual machine~\cite{Madsen:2018:TCE:3178372.3179499},
imperative languages such as C~\cite{baueran:mthesis:2003,Probst01}, or even low-level compiler-targeted languages such as
LLVM~\cite{Pandey:2015:LC:2842773}.

Find something Haskell-ish for classic tail-calls. GHC used Cmm and 
later LLVM to support tail calls~\cite{Terei:2010:LBG:1863523.1863538}.

Fusion vs. tail recursion modulo cons: functional programming \emph{short cut fusion}~\cite{Gill:1993:SCD:165180.165214,Pardo16} is based on work initially started with the listlessness optimization~\cite{Wadler84}. Listlessness is closely related to tail recursion modulo cons: ``programs for the listless machine are related to programs compiled using an optimization called tail recursion, particularly tail recursion modulo cons''~\cite{Wadler84}.


\chapter{Conclusion}
\label{ch:conclusion}

%% summary of what is done.

This thesis shows how to extend classic tail-call optimization to lazy
languages supporting alternative evaluation order choices (such as
call-by-value and call-by-name). Our prototype implementation is an
interpreter that uses information from a local static analysis, in
order to detect opportunities for tail-call optimization at tail-call
positions.

Our technique can also be implemented in a purely compile-time
setting, integrated with a defunctionalizing compiler for lazy
functional languages, such as GIC~\cite{Fourtounis14} or
GRIN~\cite{Boquist96,Podlovics19}.  This integration needs a small
code generator for stack frame mutation for tail calls, driven by the
decisions currently made by our interpreter. Such an extension should
be an obvious next step for our implementation.

%% can be used for Haskell? Simply sketch something.
%% benchmarks.

Integration with a more complex compiler should also help with
evaluating our technique with more realistic benchmarks, such as the
\emph{nofib} benchmark suite~\cite{nofib}.

Finally, Kerneis and Chroboczek proved that tail calls and lambda
lifting are compatible in a call-by-value
setting~\cite{Kerneis2011}. Since our technique can be optionally
combined with a lambda lifter (section~\ref{sec:syntax}), another
future step in the context of this thesis would be to formalize the
interaction between lambda lifting, tail calls, and our richer support
for evaluation order choices.

%% > gfour: the tco described in this thesis is a superset of standard
%% > tco for strict languages, so there is no future work here.
%% extension of the tail-call optimisation for strict
%% languages.

%% > gfour: we used lists as an example, our technique works for any
%% > data type, so there is no future work here.
%% what is missing (only used for lists, booleans).
%% generalization for constructors.

\selectlanguage{greek}

%%%  Bibliography

\bibliographystyle{softlab-thesis}
\bibliography{thesis}


%%%  Appendices

\backmatter

% \appendix

% \chapter{General}

\end{document}
