\documentclass[diploma]{softlab-thesis}

\usepackage{syntax}
\usepackage{graphicx}
\usepackage{minted}
\usepackage{amsmath}

%%%
%%%  The document
%%%

\begin{document}

%%%  Title page

\frontmatter


\title{Βελτιστοποίηση κλήσεων αναδρομής ουράς σε συναρτησιακές γλώσσες με πολλαπλά είδη αποτίμησης }
\author{Παναγιώτης Μπουγουλιάς}
\authoren{Panagiotis Bougoulias}
\date{Αύγουστος 2019}
\datedefense{28}{8}{2019}

\supervisor{Νικόλαος Σ. Παπασπύρου}
\supervisorpos{Καθηγητής Ε.Μ.Π.}

\committeeone{Νικόλαος Σ. Παπασπύρου}
\committeeonepos{Καθηγητής Ε.Μ.Π.}
\committeetwo{Αριστείδης Παγουρτζής}
\committeetwopos{Αν. Καθηγητής Ε.Μ.Π.}
\committeethree{Γεώργιος Γκούμας}
\committeethreepos{Επίκ. Καθηγητής Ε.Μ.Π.}

\TRnumber{CSD-SW-TR-5-19}  % number-year, ask nickie for the number
\department{Τομέας Τεχνολογίας Πληροφορικής και Υπολογιστών}

\maketitle


%%%  Abstract, in Greek

\begin{abstractgr}%

Οι συναρτησιακές γλώσσες προγραμματισμού είναι διάσημες για τη χρήση αναδρομής αντί για «βρόχους», 
κάτι που υπάρχει και χαρακτηρίζει τις προστακτικές γλώσσες προγραμματισμού. Ενώ η αναδρομή είναι καλύτερη από 
τους βρόχους σε ό,τι αφορά την καθαρότητα του κώδικα, καθώς είναι άμεσα συνδεδεμένη με το μαθηματικό ορισμό
των συναρτήσεων, έχουν ένα βασικό ελάττωμα το οποίο συνδέεται με τη χρήση της μνήμης για την εκτέλεση των 
προγραμμάτων. Το πρόβλημα αυτό είναι ότι ένας αλγόριθμος που χρησιμοποιεί σταθερό χώρο μνήμης για την εκτέλεση του
σε μια προστακτική γλώσσα προγραμματισμού, μπορεί να χρησιμοποιήσει γραμμικό χώρο σε συναρτησιακή, εξαιτίας 
της αναδρομής.
  

Η λύση αυτού του προβλήματος, που δόθηκε στη δεκαετία του '70 για τη γλώσσα Scheme, ήταν η χρήση της βελτιστοποίησης
κλήσεων ουράς, μια πολύ απλή αλλά, όπως αποδείχθηκε, πολύ αποτελεσματική για την εξάλειψη του παραπάνω προβλήματος.
Εκτός από τη Scheme, η βελτιστοποίηση αυτή περιλαμβάνεται στις υλοποιήσεις των περισσότερων συναρτησιακών 
γλωσσών με αυστηρή σημασιολογία, όπως η SML/NJ και η OCaml, καθώς και σε υλοποιήσεις προστακτικών 
γλωσσών, όπως ο "Clang" μεταγλωττιστής για τη C/C++, κάτι το οποίο φανερώνει την αξία της συγκεκριμένης 
βελτιστοποίησης για τη εξάλειψη του κόστους δέσμευσης μνήμης εξαιτίας της αναδρομής. 

Ο σκοπός αυτής της διπλωματικής διατριβής είναι να ενσωματώσει αυτή την ευρέως γνωστή βελτιστοποίηση 
μεταγλωττιστή (βελτιστοποίηση κλήσεων ουράς) για συναρτησιακές γλώσσες προγραμματισμού με αυστηρή αποτίμηση σε 
συναρτησιακή γλώσσα προγραμματισμού με πολλαπλά είδη αποτίμησης (κλήση κατά αξία, κλήση κατ' όνομα και 
κλήση κατ' ανάγκη). Συγκεκριμένα στην  περίπτωση της κλήσης κατ' ανάγκης, οι τιμές που υπακούουν σε αυτή τη
σημασιολογία "δραπετεύουν" από τη εμβέλεια του ονόματος τους πιο εύκολα απ' ότι στην 
κλήση κατ' αξία, με αποτέλεσμα να βρεθούν οι κλήσεις ουράς να είναι αρκετά πιο δύσκολο.


\begin{keywordsgr}
Βελτιστοποίηση κλήσης ουράς, οκνηρή αποτίμηση, στατική ανάλυση, διερμηνέας.
\end{keywordsgr}
\end{abstractgr}



%%%  Abstract, in English


\begin{abstracten}%
  Functional programming languages favour recursion over loops
  while the latter are a key feature of imperative programming languages. Although recursion may 
  be better than loops in terms of code purity, as it is directly linked to the mathematical definition
  of functions, it has a major flaw associated with the memory overhead to execute
  programs. This problem is that an algorithm uses a fixed memory space to run it
  in a imperative programming language, it can use linear space in a functional language because
  of recursion.
  
  
  The solution to this problem, given in the 1970s for the programming language Scheme, was tail-call 
  optimisation, a very simple but, as it turned out, very effective in order to eliminate the above 
  problem.
  In addition to Scheme, this optimisation is included in most implementations of functional programming 
  languages with strict semantics, such as SML / NJ and OCaml, as well as in imperative programming 
  languages, such as the "Clang" compiler for C/C++, which demonstrates the value of this particular
  optimisation to eliminate memory overhead due to recursion.
  
  The purpose of this thesis is to integrate this well-known compiler optimisation
  (tail call optimisation) for strict functional programming languages in
  functional programming languages with multiple evaluation order choices (call-by-value, call-by-name and
  call-by-need). Specifically in the presence of call-by-need semantics, the program values under this 
  semantics "escape" their context more easily than in call-by-value, making tail-calls much more 
  difficult to reveal.
  

\begin{keywordsen}
Tail-call optimisation, lazy evaluation, static analysis, interpreter. 
\end{keywordsen}
\end{abstracten}


%%%  Acknowledgements

\begin{acknowledgementsgr}
Ευχαριστώ θερμά τον επιβλέποντα καθηγητή αυτής της διατριβής,
κ.~Νίκο Παπασπύρου, για τη συνεχή καθοδήγηση και εμπιστοσύνη
του. Θέλω να ευχαριστήσω ακόμα
το Γιώργο Φουρτούνη, ο οποίος με βοήθησε σε
διάφορα στάδια αυτής της εργασίας.  Θα ήθελα τέλος να ευχαριστήσω
την οικογένειά μου και κυρίως τους γονείς μου, οι οποίοι με
υποστήριξαν και έκαναν δυνατή την απερίσπαστη ενασχόλησή μου τόσο
με την εκπόνηση της διπλωματικής μου, όσο και συνολικά με τις
σπουδές μου.
\end{acknowledgementsgr}


%%%  Various tables

\tableofcontents
\listoftables
\listoffigures
%\listofalgorithms


%%%  Main part of the book

\mainmatter

\chapter{Εισαγωγή}
Μπλα μπλα...

\englishtext

\chapter{Introduction}
\label{ch:introduction}

\section {Purpose of the thesis}

The purpose of the thesis is to integrate tail-call optimisation to functional programming languages 
in the presence of multiple evaluation order choices (call-by-value, call-by-name, call-by-need). Our optimisation can be combined with the 
defunctionalization transformation~\cite{Reynolds72definitionalinterpreters}, so that the resulting performance optimisation also supports
higher-order functional languages. 

\section {Motivation}

Tail-call optimisation for strict functional languages is a well-studied topic, but it fails in the 
presence of laziness: the computation of a lazy argument can happen arbitrarily during the execution 
of the program and thus lazy arguments escape their context more easily than strict ones.
On the one hand, laziness gives programmers great options: to use infinite data structures~\cite{Abel13}, 
to define control flow (structures) as abstaractions instead of primitives, to increase performance
by avoiding needless calculations, and to avoid error conditions when evaluating compound expressions.
But this flexibility comes at a cost: too lazy programs can lead to poor performance and even memory leaks.
On the other hand, strictness enables programmers to count performance more easily, but programs can 
fall into undesired behavior, such as divergence.

In this thesis, we get the best of both worlds: our programs need not be too lazy nor too strict,
with evaluation order annotations supporting tail-call optimisation in lazy evaluated 
functional programming languages, thus eliminating memory overhead associated with recursion in the 
same way as in strict functional languages.

\section {Overview of the thesis}

In this thesis, we integrate tail-call optimisation in a functional 
language in the presence of multiple evaluation order choices (strict, lazy, call-by-name semantics). 
Our optimisation supports user-defined data types with pattern matching and thus can be combined with the
defunctionalization transformation, so that higher-order functional languages are also supported. The source language, similar to Haskell, 
is transformed (via defunctionalization) to a low-level, minimal, first-order functional language 
with non-strict semantics, lazy evaluation and lazy structured data as well as strictness 
annotations. To find opportunities for optimisation, we perform a static analysis on the 
low-level functional language, to spot tail-call positions. The difficult part, 
compared with languages with strict semantics, is that lazy semantics makes program values escape 
their context and thus finding tail-call positions is not trivial. This optimisation was evaluated
on an interpreter of the language that explicitly allocates and measures frames, so that on 
tail-call positions found by the analysis, we can properly replace the unnecessary current 
frame's arguments with the arguments needed by the frame that represents the next function call. 
Our optimisation either improves program run-time, or does not change it. Also, in the case of 
strict programs, our optimisation is equivalent to classic tail-call optimisation. In conclusion,
in a non-strict, lazy-evaluated functional language with lazy data constructors and strictness 
annotations, for all benchmarks we use, there is always memory optimisation, and for the majority 
of them there is a significant memory optimisation with performance boost.

\section{Contributions}

Our major contributions, presented in this thesis, are:
\begin{itemize}
  \item We show how tail-call optimisation and tail recursion modulo cons can be applied to a functional programming 
  language with mixed evaluation order. Our key contribution is how it can be applied in 
  the presence of \textit{lazy} evaluation, and thus turning the optimisation to an extension of tail-call optimisation 
  for call-by-value languages.
  \item A prototype implementation of an interpreter with explicit frame allocation, as well as frame counting mechanism,
  for a functional language with call-by-value, call-by-name and call-by-need semantics, lazy data constructors 
  and pattern matching.
  \item A static analysis algorithm to find \textit{true} tail call positions and the implementation of the runtime system 
  for these optimisations embedded in the interpreter.
  \item The evaluation of this optimisation on micro benchmarks shows that it either improves the runtime 
  or does not change it. The evaluation seems to approach in many cases the number of frame allocations in call-by-value languages, 
  which is the best result we can have.
\end{itemize}

An overview of the contents of each chapter follows:
\begin{itemize}
  \item In \textit{Chapter~\ref{ch:background}}, we provide the necessary background for the reader in 
        order to follow the next chapters. There is a comprehensive explanation of classic 
        tail-call optimisation (section~\ref{sec:tco}), an overview of the evaluation order choices we study 
        in this thesis (section~\ref{sec:evaluation-order}), an overview of static analysis (section~\ref{sec:static-analysis}). Finally, 
        in section~\ref{sec:abstract-machines} there is an overview of abstact machines and interpreters, focusing on 
        lazy functional languages.

  \item In \textit{Chapter~\ref{ch:overview}}, there is an overview of the thesis; we provide the intuition 
        for our key ideas presented in the rest of the thesis.

  \item In \textit{Chapter~\ref{ch:language}}, we present the language we studied. Briefly, we describe 
        how from a higher-order functional language and applying the appropriate 
        transformations (sections~\ref{sec:defunctionalization}-\ref{sec:other-transformations}) we can reach the first-order functional 
        language we used for our analysis and evaluation of the optimisation.

  \item In \textit{Chapter~\ref{ch:execution-model}}, we describe the execution model of our language. We present operational 
        properties as well as implementation details.

  \item In \textit{Chapter~\ref{ch:analysis}}, we give the static analysis algorithm that we use in order to spot 
        and thus properly annotate true tail-call positions. These annotated function calls 
        are later handled by the interpreter.

  \item In \textit{Chapter~\ref{ch:evaluator}}, how we operationally treat inside the interpreter the 
        tail call optimisable function calls and tail recursion modulo cons.

  \item In \textit{Chapter~\ref{ch:evaluation}}, there is an evaluation of our optimisations on microbenchmarks.

  \item \textit{Chapter~\ref{ch:related}} and \textit{Chapter`\ref{ch:future}} are related work and future wok respectively.

\end{itemize}




\chapter{Background}
\label{ch:background}

In this chapter, we provide the reader the necessary background for this thesis. The optimisations presented in this thesis 
are explained. Anyone familiar with these ideas, can skip this section and continue to the next chapter, where we give the intuition behind the
main idea of this thesis.

\section{Tail-call optimisation}
\label{sec:tco}

The main optimisation this thesis discusses is the tail-call optimisation. This optimisation, first found in Scheme~\cite{Sussman:1975:IEL:889230,Steele:1976:LUI:889232} and
generally usually found in strict functional languages, 
allows functional programming languages to have constant space 
similar to `for' loops from imperative programming languages~\cite{Clinger:1998:PTR:277650.277719}. 
Without this, recursion would require \textit{linear} memory space; 
i.e. one frame allocation for each function call. More recent works perform tail-call optimisation 
for non-functional languages, such as C/C++~\cite{Probst01} 
and Java~\cite{Madsen:2018:TCE:3178372.3179499}.

What exactly is \textit{tail call optimisation}? Tail calls are function calls in specific locations;
specifically they are function calls performed as the final action of a function. Tail-call optimisation is actually passing 
the control from the caller to the callee; the runtime does not allocate a new frame for the 
callee function. Instead, it reuses the current frame from the caller function. This leads to 
a constant memory usage for the whole procedure. 

In the example below, we have a `factorial' in OCaml:
\begin{minted}{OCaml}
  let rec fact n = 
    if n > 0 
      then n * fact (n-1)
      else 1
\end{minted}

Inside the function's body, there is a function call to `fact'. This is not a tail-call, because this call isn't 
the last call performed in the function's body. In this example, `*' is the last operation performed, just before the function returns.
Let's assume that we have a call to the function:
\begin{minted}{OCaml}
 let main = fact 3
\end{minted}

The calling stack in this execution is:
\begin{minted}{OCaml}
fact 3 = 3 * fact 2
fact 2 = 2 * fact 1
fact 1 = 1 * fact 0 
fact 0 = 1
\end{minted}

From the calling stack above, it seems that `fact 3' requires the result of `fact 2', which requires the result of `fact 1', which 
requires the result of `fact 0', in order to produce the final result. A stack frame is allocated for each function call and it is finally 
free, when the result is returned to the caller. The last operation that happens in every call is the multiplication.

Let's take a look at a second example, again for the `factorial'.
\begin{minted}{OCaml}
  let rec fact' n acc = 
    if n > 0 
      then fact' (n-1) (n * acc)
      else acc 
\end{minted}

These two examples have absolutely the same result. The \textit{path} they follow in order to produce it though, is totally different.
At this point, let's imagine a call to the function of the second example:
\begin{minted}{OCaml}
  let main = fact' 3 1
\end{minted}

Here is calling stack for ` fact' ':
\begin{minted}{OCaml}
  fact' 3 1 = fact' 2 3
  fact' 2 3 = fact' 1 6
  fact' 1 6 = fact' 0 6
  fact' 0 6 = 6
\end{minted}

As we observe, the call to fact' is the last call the function does before it returns. Also, the return result `acc' of the function is 
evaluated at every function call. This is the reason why fact' can run using only one stack frame, and thus we have \textit{constant} stack 
space for the execution. Constant space is also what happens if we wrote `factorial' with a `for' loop, imperative 
programming style. 

Tail-call optimisation is great for both having functional programming, and thus recursion and more clear code, and also not the 
memory overhead recursion \textit{usually} requires.

\section{Evaluation order choices}
\label{sec:evaluation-order}

In this section, we will describe the evaluation order choices we used in this thesis. In the setting of our first-order language, evaluation order is closely tied to how parameters passed and evaluated at a function call. Evaluation order controls \textit{how} the caller and the callee function will interact, 
when the former calls the latter. 

The evaluation order choices we studied are: 
\begin{itemize}
  \item call-by-value or \textit{strict} arguments (e.g. OCaml, Scheme), 
  \item call-by-name arguments and,
  \item call-by-need or \textit{lazy} arguments (e.g. Haskell).
\end{itemize}

Call-by-name and call-by-need semantics is similar to each other; they always produce the same result.
Their key difference is that call-by-need computes a value when it needs it, memoizes the result after the computation 
and does not evaluate it again, while call-by-name re-evaluates the value, in case it's needed again for a computation.
This makes call-by-name less practical. Call-by-need can also be considered as a \textit{practical} implementation 
of call-by-name, first appeared as a real-world implementation in the \textit{Miranda} programming 
language, later in \textit{Clean} and have become more popular
with Haskell's programming language implementation: the Glasgow Haskell Compiler (GHC).

\subsection {Call-by-value (CBV) or \textit{strict} evaluation}
\label{sec:cbv}

Call by value is the most commonly used technique for parameter passing. It' s used in the most functional 
programming languages (e.g. Scheme, OCaml etc) and also in imperative and object oriented programming 
languages (C/C++, Java etc).

\par Call by value principles briefly are:
\begin{itemize}
  \item Evaluate \textit{fully} the actual parameters at the call inside the caller function's body.
  \item \textit{Bind} the \textit{fully evaluated} values with callee's formal parameters \textit{locally} inside the callee.
\end{itemize}

Let's become more clear using a simple first example:
\begin{minted}{haskell}
  length :: [Int] -> Int -> Int
  length l@[]     acc = acc 
  length l@(x:xs) acc = length xs (acc + 1)

  -- Make the call to length
  main = length [1,2,3] 0
\end{minted}

Let's suppose strictness in the example above, i.e.:
\begin{itemize}
  \item `l' is a strict list, exactly the same as a regular list in SML.
  \item  `acc' is also a strict parameter. 
\end{itemize}

During the execution we have the following memory snapshots:
\begin{minted}{haskell}
  length [1,2,3] 0 = length [2,3] 1 -- At this point, `acc' is 
                                    -- evaluated to 0+1 = 1.
  length [2,3]   1 = length [3]   2
  length [3]     2 = length []    3
  length []      3 = 3
\end{minted}

This is the tail-recursive form of the function, known from the previous section, that counts the number 
of elements inside a list. As it seems above, the accumulator parameter `acc' is evaluated in every 
function call, before the control of the call passes to the callee.
\newline
\par Now, let's take a look at a second example, where the accumulator is a list. The purpose for this 
example is to highlight the difference between strict data constructors a la ML and lazy data constructors.
It will become obvious in later section, when we will talk about laziness (section~\ref{sec:lazy}).

\begin{minted}{haskell}
  makelist n acc = 
    if n > 0 
      then makelist (n-1) (n : acc)
      else acc
  main = makelist 3 []
\end{minted}

The calling stack of this program is:
\begin{minted}{haskell}
  makelist 3 []      = makelist 2 [3] 
  -- Again, `acc' is evaluated before 
  -- the call on the right-hand side is triggered.
  makelist 2 [3]     = makelist 1 [2,3]
  makelist 1 [2,3]   = makelist 0 [1,2,3]
  makelist 0 [1,2,3] = [1,2,3]
\end{minted}

Until this point, we examined CBV semantics, the most common 
semantics that a programmer uses. From this point on, we will dive into 
the two remaining kinds of semantics we used and we will show to the reader 
the relation between them and their key differences, especially for datatypes.
It is important the reader to understand the key differences from now, even though 
we will have a comprehensive explanation throughout the thesis.

\subsection {Call-by-name (CBN) evaluation}
\label{sec:cbn}

Call by name is an evaluation strategy where the arguments to a function are not evaluated before the function is called. 
They are substituted directly into the function body (using capture-avoiding substitution) and then left to be evaluated 
whenever they appear in the function. If an argument is not used in the function body, the argument is never evaluated; 
if it is used several times, it is re-evaluated each time it appears.

Call-by-name evaluation is occasionally preferable to call-by-value evaluation. If a function's 
argument is not used in the function, call by name will save time by not evaluating the argument, 
whereas call by value will evaluate it regardless. If the argument is a non-terminating computation, 
the advantage is enormous. However, when the function argument is used, call by name is often slower, 
requiring a mechanism such as a thunk, first appeared in ALGOL60~\cite{Naur78}. More recent works 
works prove a relation between call-by-name and call-by-value~\cite{Wadler03}, supporting our interest 
to investigate call-by-name as an evaluation order present in our core language.

A first example in order to showcase how a programmer can put CBN semantics to good use, is:

\begin{minted}{haskell}
  loop x = loop x

  head []     = error "Empty list"
  head (x:xs) = x

  main = head [42, loop 42]
\end{minted}

While in CBV, this program would cause a memory overflow, because it would try to evaluate [42, loop 42],
while `loop' is an ifinite loop and it would diverge, and thus the above would be an incorrect program, 
in CBN it will return 42, which is actually the first element of the list.

In a second example though, the drawback of CBN becomes obvious; it re-evaluates already evaluated values and thus 
turns the algorithm complexity from linear to more than quadratic. The example follows:

\begin{minted}{haskell}
  fact n acc = 
    if n > 0 
      then fact (n-1) (n*acc)
      else acc

  main = fact 3
\end{minted}

In this example, the successive order of calls would be:
\begin{minted}{haskell}
  -- 1 
  fact 3 1 = 
    if n > 0                  -- Here becomes n = 3
      then fact (n-1) (n*acc) -- where n = 3  and acc = 1*3
  -- 2
  if n > 0                    -- Evaluates n-1=3-1=2 and n = 2 
    then fact (n-1) (n*acc)   -- again n-1=2-1=1 and n*acc=1*1
  -- This will follow until the end of execution, 
  -- and this leads to call-by-name with memoization (call-by-need).
\end{minted}


\subsection {Call-by-need or \textit{lazy} evaluation }
\label{sec:lazy}

Call by need is a memoized variant of call by name where, if the function argument is evaluated, 
that value is stored for subsequent uses. If the argument is side-effect free, this produces the same results as call by name, 
saving the cost of recomputing the argument. 

Haskell is a well known language that uses lazy evaluation. Because evaluation of expressions may happen arbitrarily 
far into a computation, Haskell only supports side-effects (such as mutation) via the use of monads. This eliminates any 
unexpected behavior from variables whose values change prior to their delayed evaluation.
\newline
\par Lazy evaluation is roughly guarded by two major priciples:
\begin{itemize}
  \item \textit{Call-by-name} semantics, and
  \item \textit{single-evaluation} property, which makes the memoization compulsory.
\end{itemize}

At this point, let's take a closer look at this program, also presented in the previous section about CBN,
but now in the presence of laziness:

\subsection{Lazy data constructors}
\label{sec:lazy-data-cons}

\begin{minted}{haskell}
  loop x = loop x -- function that diverges

  head l = 
    case l of 
      []     -> error "Empty list"
      (x:xs) -> x

  main = head [42, loop 42]
\end{minted}

When we call `head' with [42, loop 42] the following happens:
\begin {itemize}
  \item Allocates a frame with an unevaluated \textit{thunk}, which is [42, loop 42], for the function call to head.
  This means that `l' formal parameter contains a pointer to the memory cell, which contains the aforementioned actual parameter. 
  \item Then, `head' is evaluated. Imagine `case' as an operation that "opens" the data, i.e. it forces evaluation \textit{one} 
  more step. The first expression to be evaluated is the list `l', which is \textit{needed} in order to pick a branch. More 
  specifically `eval l' produces `x1:x2', where `x1' contains a pointer to `42' and `x2' contains a pointer to `loop 42'.
  It also binds `x', `xs' to `x1', `x2' successively.
  \item At this point, `case' knows which branch to pick from the previous step. As `l' is not an empty list, it picks the 
  second branch. 
  \item On the right-hand side of the second branch, there is the variable `x'. Now, the value of `x' is needed, and thus 
  it evaluates `x1', that is evaluates the content of the pointer and finally it returns 42.
  \item An important notice is that because pattern matching variable `xs' doesn't exist on the right hand side 
  of the branch, it doesn't evaluate `xs' and thus the program doesn't diverge.
\end{itemize}

\subsection{BangPatterns: Haskell with strictness}
\label{sec:bangpatterns}

In Haskell's de-facto compiler, Glasgow Haskell Compiler (GHC), there is a language extension, the bang patterns, 
available both in the interactive environment (ghci) with:
\begin{minted}{haskell}
  ghci -XBangPatterns
\end{minted}
and also in the compiler as a flag, or as a language extension annotation inside a Haskell's source file as:
\begin{minted}{haskell}
  {-# LANGUAGE BangPatterns #-}
\end{minted}
which allow the explicit use of strictness in Haskell. We should also mention the existence of `seq', a function found
in Haskell's Prelude:
\begin{minted}{haskell}
  seq :: a -> b -> b
\end{minted}
which forces the evaluation of the first argument and returns the second argument as a result.

The example below showcases the use:
\begin{minted}{haskell}
  {-# LANGUAGE BangPatterns #-}

  loop x = loop x -- function that diverges

  -- !l: l is a strict parameter
  head !l = 
    case l of 
      []     -> error "Empty list"
      (x:xs) -> x

  main = head [42, loop 42]
\end{minted}

The same annotation in our language's source files is used; it will be explained in detail in later section of 
Chapter~\ref{ch:language}. For now, we provide some explanation about how the above program will run, in order to highlight 
the difference with `head' with the lazy parameter, Haskell's builtin, which was given earlier. 

The program above has the following behaviour when executed:
\begin{itemize}
  \item Again, `head' is called. But now the frame for `head' has an evaluated \textit{thunk}, because `!' moves the 
  evaluation one more step. So, in contrast to the earlier example, `l' has a pointer to (x1:x2), where x1 contains a pointer to 
  `42' and x2 contains a pointer to `loop 42'. The \textit{thunk} is also marked as \textit{evaluated}.
  \item Then, `head' is evaluated. At this point, when `case' needs to evaluate `l', which is marked as evaluated, `case' knows 
  which branch to follow, which is the same as earlier, and doesn't do anything else.
  \item After the branch is picked, again the right hand side of the branch is evaluated and `42' is returned as a result.
  \item An important notice here is that `!' doesn't force \textit{deep} evaluation of the data structure. It just moves the 
  value from weak-head normal form to head normal form. For data, this means that the outermost value is evaluated.
\end{itemize}

The idea about extending Haskell with strictness was used in StrictCore, an intermediate language 
which aims to improve GHC's Core language by having
thunk/value distinction at the type level and multi-arity functions and multiple value returns, 
inspired by~\cite{Bol09}.


\subsection{Deepseq: ML-lists in Haskell}
\label{sec:deepseq}

The above functionality of `BangPatterns' shows that even with these strictness annotations, data constructors (lists in our
example) are not the same as ML lists. But Haskell also has the `deepseq' module, which cause deep evaluation of the data, 
and in this way we can \textit{head normal data}. 

It follows an explanation of `deepseq' functionality. 
BangPatterns are used in data constructors definitions.

\begin{minted}{haskell}
  data List a = Empty | Cons !a !(List a)
\end{minted}

In the above data definition, `Cons' contains:
\begin{itemize}
  \item A strict head, annotated with a `!'.
  \item A strict tail, annotated also with a `!'.
\end{itemize}

In case that this list was used for `head', we finally have ML lists and the program 
will diverge as it happens in a strict functional language like OCaml. `Deepseq' automatically can turn a data structure
defined in Haskell into a ML-like data structure, by automatic instance derivation.
\newline \newline
\par In case the programmer needs more customization, he can use BangPatterns in every possible combination. 
The definitions below are also used in this thesis' language.
\begin{minted}{haskell}
  -- 1. Haskell builtin lists.
  data List a = Empty | Cons a (List a) 
  -- 2. Lists with strict head.
  data List a = Empty | Cons !a (List a)
  -- 3. Lists with strict tail.
  data List a = Empty | Cons a !(List a)
  -- 4. Deeply evaluated lists. 
  data List a = Empty | Cons !a !(List a)
\end{minted}

\section {Static analysis}
\label{sec:static-analysis}

\subsection{General background}

Static program analysis is the analysis of computer software that is performed without actually executing programs.
The analysis is performed in compile-time, before the program actually starts executing. 

\subsection{Abstract interpretation}

Use case for strictness analysis, an instance of 
abstract interpretation. Explanation and citations
for that.

\section{Abstract machines and Interpreters}
\label{sec:abstract-machines}

\subsection {Stack Environment Control Dump machine (SECD)}
\label{sec:secd}

The SECD machine is a highly influential 
virtual machine and abstract 
machine intended as a target for functional programming 
language compilers. The letters stand for Stack, Environment, 
Control, Dump, the internal registers of the machine. 
The registers Stack, Control, and Dump point to (some 
realisations of) stacks, and Environment points to (some 
realisation of) an associative array.

The machine was the first to be specifically designed to 
evaluate lambda calculus expressions. It was originally 
described by Peter J. Landin in "The Mechanical Evaluation 
of Expressions"[1] in 1964. The description published by 
Landin was fairly abstract, and left many implementation 
choices open (like an operational semantics). Hence the SECD 
machine is often presented in a more detailed form, such as 
Peter Henderson's Lispkit Lisp compiler, which has been 
distributed since 1980. Since then it has been used as the 
target for several other experimental compilers.

In 1989 researchers at the University of Calgary worked 
on a hardware implementation of the machine.

Original citation:~\cite{La64}. Recent work on how the thing works:~\cite{Danvy:2004:RDL:2154439.2154443}.

\subsection{Three-instruction machine (TIM)}
\label{sec:tim}

TIM~\cite{Argo89}.

provide background for abstract machines and Interpreters
secd, tim, stg etc etc

\subsection{G-Machine}
\label{sec:g-machine}
Write about G-Machine, STG's predecessor. Compare it with G-Machine.

\subsection{Spineless Tagless G-Machine (STG)}
\label{sec:stg}
Overview of STG~\cite{Jo92} and its latest version~\cite{Ma06}.

\subsection{Push/enter vs. eval/apply}
\label{sec:push-enter}
Push-enter vs. eval-apply~\cite{Ma06}, marlow and jones. Our model is push-enter, since it is first-order.

% \section {Boxed vs. Unboxed values}
% μπλα μπαλα.





\chapter {Overview}
\label{ch:overview}

In this chapter, we present to the reader some examples providing the intuition of the main idea described 
in the following chapters. The description is informal and the reader has to know only the details of laziness 
described in the background in order to follow. We do not refer to details of the analysis and the execution model 
that may confuse the reader, while leaving that part for later explanation, in the appropriate sections.

More specifically, in section~\ref{sec:classic-tco-examples} we provide examples for integers (values always in WHNF) and 
for almost all the cases of handling lists (`lazy' data constructors): 
consuming (`sum'), constructing (`makelist'), consuming and constructing (`map'). 
In section~\ref{sec:modulo-cons-example}, an example for tail recursion modulo cons is presented. It is an extension of classic 
tail-call optimisation, first appeared in Prolog implementations.


\section {Classic tail-call optimisation}
\label{sec:classic-tco-examples}

% \subsection {Example 1: Integers}
% In this example, the only values are integers. As mentioned 
% in the previous chapter, integer values are always in weak-head normal 
% form (WHNF). This means that their \textit{full} evaluation requires \textit{one} more evaluation
% step, provided that the program does \textit{not} diverge. 


% In the first example presented below the argument is in CBV evaluation order, 
% while in the second it is in lazy evaluation order. \textbf{[1 or 2 examples (if 1 isn't enough) which makes clear the copy of values from 
% one frame to the next and also the importance of strictness.]}


\subsection {Example 1: Consuming lists}
\label{sec:example1}

The first example with constructed data is a 
function that \textit{consumes} the input data in 
order to produce a result.  The function traverses 
the input once and then computes the result. As we 
already mentioned, all arguments here are \textit{lazy}.

\begin{minted}{haskell}
sum :: [Int] -> Int -> Int
sum []     acc = acc
sum (x:xs) acc = sum xs (x + acc)
\end{minted}

In \textit{strict} languages like SML/NJ or Scheme,
this is subject to tail-call optimisation. As we know from section~\ref{sec:cbv},
`acc' is \textit{fully} evaluated in every execution step, while in the
presence of laziness `acc' is evaluated \textit{once}, when the input 
list is empty and the function \textit{needs} it as a result.

The intuition here is that lazy argument `acc' has to be strict, as in the example below,
because it is a variable that has always a value (in the case the value of the variable `x') added to it,
and finally it is returned as a result. This is known in the world from strictness analysis [1], as we 
will describe later in section~\ref{sec:strictness-analysis}.

\begin{minted}{haskell}
  sum :: [Int] -> Int -> Int
  sum l !acc = 
    case l of 
      []     -> acc 
      x : xs -> sum xs (x + acc) 
\end{minted}

At the latter example, `acc' (an integer or WHNF) is strict. This means that `acc' is 
fully evaluated in each execution step, and thus it can be tail-call optimised. This, of course,
isn't possible if `acc' was, for example, a list, as we will illustrate with the following examples.


\subsection {Example 2: Constructing lists}
\label{sec:example2}

In this example, we have a function that constructs a list with successive 
integers up to the input number `n' (`0' excluded, `n' included). The function contains 
a tail-recursive call in its body to itself (`makelist (n-1) (n : acc)'). 

\begin{minted}{haskell}
makelist :: Int -> [Int] -> [Int]
makelist !n !acc = 
  if n > 0 
    then makelist (n-1) (n : acc)
    else acc
\end{minted}

Although the example above seems a perfect candidate for tail-call optimisation, it isn't, 
at least in the traditional point of view of tail-call optimisation. Here, lists are 
lazy data constructors and aren't fully evaluated in every execution step. The bang (`!') doesn't 
force deep evaluation of the data, but it forces the evaluation one more step. That means that the strict 
`acc' constructs its \textit{backbone} (a memory thunk) in memory, along with a \textit{recipe} 
(`n-1' and `n:acc' cells) for further evaluation. 

With a more case-aware analysis and additional work in the evaluator, 
we were actually able to tail-call optimise the example
above. The details will follow in sections~\ref{sec:classic-tco-analysis} and \ref{sec:classic-tco-eval} for the analysis 
and the evaluator respectively.

\subsection {Example 3: Constructing and consuming lists}
\label{sec:example3}

An example of constructing and consuming, or better \textit{processing}, lists is `map' or `foldl'/`foldr'.
In the example below, we present a defunctionalized version of `map', similar to Prelude's `map', instantiated for
the integer domain.

\begin{minted}{haskell}
data Func = Add Int
apply f x =
 case f of
   Add a0 -> add a0 x

map :: Func -> [a] -> [b] -> [b]
map f l acc =
 case l of
   []     -> acc
   x : xs -> map f xs (apply f x : acc)

inc a = a + 1

result = map (Add 1) [1, 2, 3] []
\end{minted}
In the example presented above, 
the tail-recursive call to `map' can be subject to tail-call optimisation, 
following the same principles as in the examples like `sum' and `makelist'. The classic non tail-recursive 
version of `map' (`apply f x : map f xs') is actually subject to tail recursion modulo cons, which is presented 
in the following section.

\section{Tail recursion modulo cons}
\label{sec:modulo-cons-example}

Tail recursion modulo cons is a generalization of classic tail-call optimisation. First found in an 
implementation of Prolog, it can also be applied in
functional programming languages, especially those with lazy evaluation~\cite{Wadler84}.

Tail recursion modulo cons can also be found in bibliography, as \textit{guarded} recursion, 
a recursive call guarded by a constructor. This can become more clear, if we consider lazy data constructors, 
described in section~\ref{sec:lazy}, which use a mechanism called \textit{thunk} for their evaluation.

Let's illustrate this idea with a simple example presented in the next section.

\subsection {Motivating example}
In Example 3 (section~\ref{sec:example3}), `makelist' was in the tail-recursive 
form. In this section, we have a different version of the function. 
Programmers who constantly use strict functional programming languages like OCaml 
will argue that the program below is bad. 

In Haskell, this is not the case. Actually, in Haskell's Prelude all functions are written 
in the form below, where these programs are subject to many optimisations triggered 
by Haskell's \textit{rewriting machine}, and performed in the runtime 
(especially this program is subject to \textit{fusion}~\cite{Coutts07}). 
\newline
\par At this point, we showcase the use of tail recursion \textit{modulo cons}, instead of other optimisations
used in GHC.

\begin{minted}{haskell}
makelist x = 
  if x > 0 
    then x : makelist (x-1)
    else []
\end{minted}

In the example above, the \textbf{\textit{then}} clause contains a constructor 
application: 
\begin{center}
  @ (@ (:) x) (@ makelist (x-1))
\end{center}

This recursive call is guarded by the constructor (:).
From section~\ref{sec:lazy-data-cons}, where we described lazy data constructors,
we know that this constructor application will be suspended when 
the program is running. This means that it will create a memory 
thunk with two cells, which will contain `x' and `makelist (x-1)'.
The function call to makelist is actually a call that can be transformed 
to a tail-recursive call to `makelist', if the `cons' thunk is \textit{updated} 
with the value of the variable `x'. 

\chapter {The language}
\label{ch:language}

In this chapter, we will describe the language that we studied in this thesis.
The semantics of the language will become clear to the reader, as well as 
the special treatment of the evaluation order in the final core 
language, which was used for the static analysis and for the optimisations. Briefly, a 
comprehensive description of the path from a higher-order functional language 
to a first-order functional language with the evaluation-order annotations will follow.

\section {Overview of the language }
\label{sec:language-overview}

The language we studied is a functional language 
with multiple evaluation orders (call-by-need or 
\textit{lazy}, call-by-name and call-by-value or \textit{strict}).
We consider laziness as something that happens naturally in the language, while 
the other two evaluation orders are used as language extensions,
using proper annotations.

The annotations can appear syntactically (i.e. the programmer can annotate 
the formal parameters in the function definition) or 
after applying the transformations, described in sections 3.2 to 3.4, 
to the source language. The latter
is only the case for strict arguments revealed by strictness analysis.

\section {Defunctionalization transformation}
\label{sec:defunctionalization}

Defunctionalization is a compile time tranformation technique which eliminates higher order 
functions, replacing them by a single first-order \textit{apply} function, introduced by John Reynolds~\cite{Reynolds72definitionalinterpreters}.
Reynolds' observation was that a given program contains only finitely many function abstractions, so that each can 
be assigned (and replaced by) a unique identifier. Every function application within the program is then replaced 
by a call to the apply function with the function identifier as the first argument. The apply function's only job is 
to dispatch on this first argument, and then perform the instructions denoted by the function identifier on the 
remaining arguments.

One complication to this basic idea is that function abstractions may reference free variables. In such situations, 
defunctionalization must be preceded by closure conversion (lambda lifting), so that any free variables of a function 
abstraction are passed as extra arguments to apply. In addition, if closures are supported as first-class values, 
it becomes necessary to represent these captured bindings by creating data structures.

The defunctionalization transformation was used in MLton, an optimising compiler for ML. The first-order
core language created oportunities for whole-program analysis and led to great performance~\cite{mlton}.

As an example of defunctionalization, Prelude's `map' follows. The transformation leads to 
the non tail-recursive version of `map', shown in section ??.

Prelude's `map':

\begin{minted}{haskell}
  map :: (a -> b) -> [a] -> [b]
  map f []     = []
  map f (x:xs) = f x : map f xs

  inc :: Int -> Int 
  inc a = a + 1
  
  result = map inc [1,2,3]
\end{minted}

After performing defunctionalization `map' is (instantiated for integers):
\begin{minted}{haskell}
  data Func = Inc 

  apply :: Func -> b -> b
  apply f x =
    case f of
      Inc -> inc x

  map :: Func -> [a] -> [b]
  map f l =
  case l of
    []     -> acc
    x : xs -> apply f x : map f xs

  inc :: Int -> Int 
  inc a = a + 1

  result :: [Int]
  result = map Inc [1, 2, 3] []
\end{minted}

The differences between the two versions are:
\begin{itemize}
  \item Higher-order function, the first argument of `map' (f :: a -> b) is 
  transformed to a \textit{unique} identifier, which is the data constructor `Inc'.
  \item For the application inside the body of `result' function, we have the first order \textit{apply}
  function, which patterns matches on the unique identifiers that are applied to `map'.
\end{itemize}

Further details and formalization of defunctionalization transformation are not given here. 
The reader can refer to Reynolds' paper for more information about this transformation.

\section {Strictness analysis}
\label{sec:strictness-analysis}

Lazy evaluation only evaluates terms to values when needed; this provides the 
opportunity for infinite data structures and programs that do not diverge, as those in 
strict programming languages. But everything comes at a cost: evaluation can happen 
arbitrarily and thus lazy arguments can escape their context.

But Mycroft
noticed that some lazy terms are actually strict under the right circumstances~\cite{Mycroft:1980:TPT:647324.721526}. For instance, the `case' 
construct forces the evaluation of the scrutinee, causing the scrutinee to actually become strict, 
similar to strictness presented in section~\ref{sec:bangpatterns} about BangPatterns. 

And it's more than that. Let's look again the sum program of section~\ref{sec:example1}:
\begin{minted}{haskell}
  sum :: [Int] -> Int -> Int
  sum []     acc = acc
  sum (x:xs) acc = sum xs (x + acc)
\end{minted}

Here, lazy argument `acc', which is a thunk in each function call is evaluated once, when the program's 
execution flow reaches the base case. This \textit{arbitrary} evaluation of lazy arguments seems not to 
be so arbitrary after all. We do know when `acc' is going to be evaluated.
\newline
\par Well, the question is what makes `acc' so predictable? 

From the example above, we have the following information for `acc':
\begin{itemize}
  \item `acc' is an integer, always added to another integer.
  \item `acc' is the result of the function.
\end{itemize}

From these observations we can deduct that `acc' is going to be evaluated (second observation) and 
all intermediate values are needed for its evaluation, as `acc' is an integer (first observation).
\newline
\par Although in this thesis we used integers and lists, strictness analysis can be applied except for 
integer domain to any other domain, using abstract interpretation.
\newline
\par Strictness analysis is performed in the defunctionalized higher-order language in order to 
properly annotate strict arguments.

\section {Other transformations}
\label{sec:other-transformations}

After defunctionalization transformation and strictness analysis are performed, we also 
perform some more transformations to the source language in order the intermediate 
language to reach the final form, which is the input of the analysis, presented in later section.


\begin{itemize}
  \item \textbf{Alpha-renaming:}  This transformation renames all variables bound by pattern matching.
  Every `case' expression opens a new scope and variable names in this scope are bound to the closest 
  `case' pattern. This transformation also handles name shadowing. 
  \item \textbf{If-to-case transform:}  When the language supports pattern matching on data 
  (constructors), `if' expression is useless. It can be transformed to pattern matching on 
  the nullary boolean constructor. Haskell does not have `if' expression as builtin; it only allows
  syntactic use (as syntactic sugar for boolean patterns).
  \item \textbf{Constructor projections:}  Every variable bound by a `case' pattern has to be 
  transformed to a special syntactic node in the core language, which contains the case unique identifier
  and the position inside the expression list in the constructor pattern~\cite{Fourtounis:2013:GIT:2769663.2769674}. The `case' id is 
  unique inside a function definition (locally).
\end{itemize}

\section{Syntax}
\label{sec:syntax}

In this section, the syntax of our core language is given.
This is the output of the strictness analysis and 
defunctionalization transformation as well as the other transformations of the previous 
section. We run the analysis algorithm to spot tail-call positions with input 
the language from this section. The interpreter is also built for that language; the evaluator for 
the optimisations are also implemented inside the interpreter for this language.
\newline
\par In figure~\ref{fig:grammar}, there is the abstract syntax of 
the first order intermediate language.
We need to highlight the following points, before we dive deeper into the language:
\begin{itemize}
  \item In the source language there is an `if' expression syntactically. In the syntax figure there isn't.
  This is because `case' is much more powerful than `if' and an `if' can be transformed to a `case'. 
  Actually, we have (boolean are constructed data as well):
  \begin{minted}{haskell}
    if cond then e1 else e2 => case cond of { True -> e1; False -> e2 }
  \end{minted}
  \item There aren't any partial applications, neither in function nor in constructor applications.
  This means that the arguments in a function call are the same in number as in the function definition.
  \item There is not `let' expression in the core language. Instead we assume that our language 
  fully depends upon the lambda lifter ; Johnson style \textit{full laziness} lambda lifter~\cite{Johnsson:1985:LLT:5280.5292}
  will get the work done.
  \item Case patterns are simple and do not allow wildcard patterns. Turning a complex case pattern into
  a simple case pattern is a well studied topic~\cite{Au85,Wadler87}.
  \item The scrutinee of a case construct is not a case expression. We assume that case-of-case 
  transform~\cite{Jone98} is performed.
\end{itemize}

% Better have it as figure. 
\begin{figure}[t]
\hrule
\begin{grammar}
    <p> ::= <fdef>\textsuperscript{+} \hfill\ Program

    <fdef> ::= \textit{f v\textsubscript{1} ... v\textsubscript{n}} = <expression> \hfill\ Function Definition

    <expr> ::= \textit{v} \hfill\ Variable
    \alt <integer> \hfill\ Integer
    \alt \textit{f e\textsubscript{1} ... e\textsubscript{n}} \hfill\ Function application
    \alt \textit{c e\textsubscript{1} ... e\textsubscript{n}} \hfill\ Constructor application
    \alt \texttt{case} \textit{e\textsubscript{0}} \texttt{of} \textit{patt\textsubscript{1} $\rightarrow$ e\textsubscript{1} | ... | patt\textsubscript{n} $\rightarrow$ e\textsubscript{n}} \hfill\ Case expression
     
    <patt> ::= \textit{c v\textsubscript{1} ... v\textsubscript{n}} \hfill\ Constructor pattern
    \alt <integer> \hfill\ Integer pattern

    <integer> ::= 1, 2, ... \hfill\ Integer domain

\end{grammar}
\hrule
\caption{My grammar\label{fig:grammar}}
\end{figure}

The syntax in the figure is a syntax of a first order functional language. Our syntax has two main 
differences from the one shown in the figure:
\begin{itemize}
  \item The concrete syntax of the core language has evaluation order annotations in order to 
  distinguish between the semantics during the parameter passing. We have already mentioned the 
  strictness annotations added by the strictness analysis. 
  More specifically, the programmer can concretely annotate the formals in the function definition with:
    \begin{itemize}
      \item {`!' for a strict formal parameter,}
      \item { `\#' for a call-by-name formal parameter, while}
      \item {lazy arguments aren't annotated, because we consider laziness as something that naturally happens 
      in the language.}
    \end{itemize}
  
  As far as the abstract syntax is concerned, the formal parameters of a function definition are:
  \begin{minted}{haskell}
    type Formal = (VN, (EvalOrder, Type))
    type VN = String 
    type EvalOrder = CBV | CBN | Lazy 
    data Type = TInt | TCons Type -- an value of type integer (TInt) or 
                                  -- a list of values with type Type
  \end{minted}
  where the type constructor of a formal parameter has the information about the parameter's name and 
  the static info of its evaluation order and its type. We assume the base types as integers and later in 
  the analysis part, we will explain why this is enough.

  \item There is one more node in the syntax tree: \textit{constructor projections}. The transformation for this 
  particular syntax node has been explained earlier (section~\ref{sec:other-transformations}). 
  \begin{minted}{haskell}
    data Expr = ... | CProj CaseID CPos 
  \end{minted}
  In a constructor projection, the first argument `CaseID' shows the position of case where the argument belongs
  and the second argument the position of the variable in the left hand side of a constructor pattern in a `case' branch.
  
  The purpose of constructor projections is to bind the variables on the right hand side of the branch with the variables 
  on the left hand side of the branch. In this way, these variables are distinguished from the top level variables, i.e.
  the formal parameters in the function definition and they offer the possibility to know the position in the frame, 
  a reason that will become more clear in the next chapter, where we are going to give the details of the 
  execution model.
\end{itemize}



\chapter {Execution model}
\label{ch:execution-model}

In this chapter, we will present technical details the operational semantics for the 
language we studied in this thesis as well as the technical details about the implementation of
the interpreter, on which we evaluate our technique for the tail-call optimisation and
tail recursion modulo cons.
\newline 
\par In section~\ref{sec:execution-model-overview} there is a high-level description of the machine; section ?? follows 
with the call-by-name and call-by-need semantics and finally in section ?? the runtime data structures and the 
design decisions will become clear to the reader.

\section {Overview of the execution model}
\label{sec:execution-model-overview}

In this section, we present a high-level description for the execution model; this will be helpful for the reader
to follow the technical details from the next sections. Also, it will be easier to compare to other existing 
abstract machines and interpreters that exist for a lazy functional language.

Our model, based on GIC~\cite{Fourtounis14}, 
includes the following high-level properties:
\begin{itemize}
  \item We implement a first-order lazy abstract machine. First-order as we do not support
  function arguments can't be functions and partial evaluation. Laziness is the default semantics
  for our model.
  \item We have a frame-based execution model for our language, but the frames are 
  \textit{heap-allocated frames}, instead of stack. The reason for this is that lazy evaluation 
  breaks the sequential order of execution, because of frame updates, and thus we are not able 
  to allocate and deallocate frames with push/pop operations.
  \item Our interpreter supports explicit frame allocation, needed for frame mutation and evaluation 
  of our technique, as well as a frame counting mechanism of frames.
  \item Our language supports multiple evaluation orders and thus our interpreter 
  also handles them (call-by-value, call-by-name, call-by-need).
  \item Our data are lazy data constructors, but we can also support ML-lists (data with deep evaluation
  presented in section~\ref{sec:deepseq}).
  \item At function calls we follow the push/enter function call policy. Before jumping into 
  the function's body, we allocate the frame and evaluate all the actual parameters, with the respect
  to the semantics. 
  \item Our model supports pattern matching (constructors and base type values) similar to Haskell. 
  This is the most complicated feature in a lazy functional language, if we consider that initial 
  abstract machine didn't provide support for that (section~\ref{sec:g-machine}).
\end{itemize}

\section {Runtime system}
\label{sec:runtime-system}

In this section, there is a detailed explanation of the prototype implementation of the interpreter we 
used for the language. First, we are going to present the data structures used in the runtime; then, 
we present the operational features of our interpreter. 

\section{Runtime data structures}

Here, there are the definitions of the runtime structures, as they are used in the implementation. The 
implementation is in Haskell, but the code will be simple, so that every reader with a basic background of a functional 
language can understand.
\newline
\par There is an authoring convention for next sections that will describe the runtime structures. At first, a definition 
will appear; probably accompanied with one or more definitions. If it contains more complex data in its body, it will be 
described later in the section or there will be a pointer to another section.

\subsection{Memory: The global frame container}

In this section, we provide the definition of \textit{memory}: 
a \textit{mutable} memory space, where frames (explained in section~\ref{sec:frames}) are stored.

We have the following definition for \textit{memory}:
\begin{minted}{haskell}
  type FrameId = Int
  data Mem = Mem {
    memFrames :: Map FrameId Frame, lastFrameId :: FrameId
  }
\end{minted}

The data definition has the following fields:
\begin{itemize}
  \item A \textit{map} data structure in which a unique \textit{frame} identifier actually corresponds to 
  a frame in the memory (\textit{memFrames}). 
  \item The frame identifier for the last frame that was allocated (\textit{lastFrameId}).
\end{itemize}

The reader can think of memory as the memory in a computer: every memory cell has an address (\textit{FrameId}) and 
the address has a content (\textit{frame}). A similar representation to Launchbury's mutable heap for 
lazy evaluation~\cite{La93}.
Here, not all frames have the same capacity; the details will be given in later section for a frame.
\newline
\par This aforementioned data structure is accompanied with three operations in order to handle it:
\begin{itemize}
  \item Add a frame to the memory with \textit{push} operation (figure~\ref{fig:push}).
  \item Get a frame from the memory given its unique identifier (\textit{getFrame})
  (figure~\ref{fig:getFrame}).
  \item Update the content of a memory's frame, given its unique identifier (\textit{updFrame})
  (figure~\ref{fig:updFrame}).
\end{itemize}

\begin{figure}[h]
  $ \mathit{push} :: \mathit{Mem \times Frame \rightarrow Mem} $ \\
  $ \mathit{push~(mem, frame) = mem'} $ \\
  $ \mathit{mem' = Mem~\{~memFrames = frames', lastFrameId = lastId~\} } $ \\
  $ \mathit{frames' = frame : (memFrames~mem)} $ \\
  $ \mathit{lastId = lastFrameId~mem + 1} $
\caption{Push frame operation\label{fig:push}}
\end{figure}

\begin{figure}[h]
  $ \mathit{getFrame} :: \mathit{Mem \times FrameId \rightarrow Frame} $ \\
  $ \mathit{getFrame~(mem, id) = frame} $ \\
  $ \mathit{frame = lookup~id~(memFrames~mem)} $
\caption{Get frame operation\label{fig:getFrame}}
\end{figure}

\begin{figure}[h]
  $ \mathit{updFrame} :: \mathit{Mem \times FrameId \times Frame \rightarrow Mem} $ \\
  $ \mathit{upFrame~(mem, frameId, frame) = 
      mem~\{memFrames = insert~frameId~frame~(memFrames~mem)~\} } $ 
\caption{Update frame operation\label{fig:updFrame}}
\end{figure}


Later on, we will use the terms \textit{push}, \textit{getFrame} and \textit{updFrame} in order to refer to 
operations performed in memory.

\subsection{Suspended execution of constructed data}
\label{sec:suspended}

The data definition of suspensions (for short or suspended execution of constructed data) is:
\begin{minted}{haskell}
  data Susp = Susp (CN, [Expr]) FrameId
\end{minted}

A \textit{Susp} data construction contains:
\begin{itemize}
  \item The constructor's name \textit{CN} along with the arguments applied to it in an expression list, 
  as the constructors in our language are \textit{lazy}.
  \item A pointer to the frame' s identifier (\textit{FrameId}) , which is the environment for this suspension.
  This is the environment, until this suspension has been created. When the execution of the program forces the 
  constructor' s execution again, it will use this environment for its evaluation.
\end{itemize}

\subsection{Values}
\label{sec:values}

A value can either an integer value or a suspension.

\begin{minted}{haskell}
  data Value = 
    VI Integer 
  | VC Susp 
\end{minted}

From the above definition, we have that a value can be either an integer (or generally a base type 
value) or a suspension of constructed data (see section~\ref{sec:suspended}). While the former is obvious, especially 
for most programmers who use strict languages, the latter is something that happens in lazy evaluated 
programming languages. Computations may not be deeply evaluated and thus they can create thunks or 
leave unevaluated thunks that can be evaluated later.

\subsection{Frames}
\label{sec:frames}

The basic \textit{unit} of the execution machine is a \textit{frame}. A frame contains all necessary information 
for a function call. It is allocated every time a new function call takes place; then, it can be mutated in case it contains
a lazy parameter.
\newline
\par Here is the definition of a \textit{frame}:
\begin{minted}{haskell}
  type FN      = String 
  type CaseID  = Int 
  type FrameId = Int 

  data Frame   = Frame {
    fName  :: FN,                  -- Function Name
    fArgs  :: [FrameArg],          -- Bindings of formals with actuals
    fSusps :: [(CaseID, Susp)],    -- Data deconstruction forced by `case'
    fPrev  :: FrameId              -- pointer to previous stack frame 
  }
\end{minted}

A frame has the following information during its lifetime:
\begin{itemize}
  \item The function's name (\textit{FN}). This information is important to lookup the function 
  definition in \textit{functions map}, a structure that will be explained later, and the execution to 
  proceed.
  \item The actual parameters that are binded with the formal parameters of the function 
  definition of \textit{`FN'}.
  \item Information about suspended execution, thunk creation and evaluation forced by `case'. Each \textit{`CaseID'}, 
  unique in the body of the function contains pointers to its own thunks.
  \item A pointer to the previous frame's unique identifier (\textit{fPrev}). This is the \textit{environment} in the 
  interpreter's implementation, implied and not explicitely existing in the \textit{state} of the interpreter.
\end{itemize} 
An argument that lives in `fArg :: [FrameArg]' has the following definition:

\begin{minted}{haskell}
  data FrameArg = 
    StrictArg { val :: Value }
  | ByNameArg { expr :: Expr }
  | LazyArg   { expr :: Expr, isEvaluated :: Bool, cachedVal :: Maybe Value }  
\end{minted}

An argument can be either:
\begin{itemize}
  \item Strict and thus containing a \textit{value} (more about values in section~\ref{sec:values}).
  \item Call-by-name and thus containing only an expression, an unevaluated thunk with no option for 
  memoization.
  \item Lazy and thus containing an expression, in the same way as call-by-name arguments, 
  but also a \textit{flag} whether it is evaluated or not (preserving in this way the \textit{single evaluation property} if 
  it is already evaluated) and also space for the \textit{cached value}.
\end{itemize}

\section{Interpreter}

The interpreter is a function that takes a program's \textit{expression}, a \textit{static} memory space which contains 
information about top-level function definitions and a \textit{state}, 
reaches a \textit{final state} and \textit{returns a value}, where an expression is one of the expressions of the syntax 
tree presented in section~\ref{sec:syntax}. The definition of the \textit{state} follows later in the section.

From now on, the function $\mathit{eval}$ corresponds to the interpreter function.The declaration of the \textit{eval} 
function is shown in figure~\ref{fig:eval}:

\begin{figure}[h]
  \[
    \mathit{eval} :: \mathit{Expr} \times \mathit{FunctionsMap} \times \mathit{State} \rightarrow 
    \mathit{State} \times \mathit{Value}
  \]
\caption{Declaration of \textit{eval}\label{fig:eval}}
\end{figure}

\begin{figure}[t]

\[
  \mathit{State :: (Mem, FrameId, NRFrames)}
\]

\caption{State of the interpreter\label{fig:state}}
\end{figure} 

The \textit{State} of the \textit{eval} is shown in figure~\ref{fig:state}:
where the definitions for \textit{Mem}, \textit{FrameId} are given earlier in this chapter. The field \textit{NRFrames}
gives the number of frames allocated so far. Remember at this point that the interpreter includes \textit{explicit frame 
allocation} and this number is the \textit{goal number} for the tail-call optimisation, that will be presented in a 
later section.

The structure \textit{FunctionsMap} is a stucture that is created at compile time and it remains alive in the runtime 
as well. It doesn't change during the execution of the program and is a \textit{map} of key-value pair, where:
\begin{itemize} 
  \item Keys are the names of top-level functions.
  \item Values are a pair of formal parameters with their static information (evaluation order, type) 
  of the function and the body of the function.
\end{itemize}

The data definition of the aforementioned structure is shown in figure~\ref{fig:functionsmap}:
\begin{figure}[h]
\begin{minted}{haskell}
  type FN = String 
  data FunctionsMap = Map FN ([Formal], Expr)
\end{minted}
\caption{FunctionsMap\label{fig:functionsmap}}
\end{figure}
The result of the interpreter is the result of the execution of the body of the top-level function \textit{main}. 
This function is a special case of a function and is assumed not to have any arguments. So, the initial expression 
\textit{expr0} is: 
\begin{minted}{haskell}
  (_, expr0) = Map.lookup "main" functionsMap
\end{minted}
% \newline

The \textit{initial state} for the interpreter's execution to start with, is:
\begin{figure}[h]
\[ 
  \mathit{State0 = (mem0, frameId0, nr\_frames0) }
\]
\caption{Initial state of the interpreter\label{fig:state0}}
\end{figure}
, where:
\begin{itemize}
  \item The initial state of memory, called \textit{mem0}, is:
    \begin{minted}{haskell}
      -- cTOPFRAMED: last frame id available when execution starts
      mem0   = push (Mem Map.empty 0) frame0 
      frame0 = Frame "main" [] [] cTOPFRAMEID 
    \end{minted}
  \item The initial id of the last frame id that lives in the memory is given by:
    \begin{minted}{haskell}
      frameId0 = lastFrameId mem0
    \end{minted}
  \item The initial number of frames allocated, before eval starts execution are:
    \begin{minted}{haskell}
      nr_frames = 1
    \end{minted}
  , as we have \textit{one} frame allocation for "main" function.
\end{itemize}

At this point, we have everything set up. We declared the interpreter's function \textit{eval} and we have an initial 
state to start our eval with. Now, let's dive into the execution of each expression of the syntax tree of our language 
presented in section~\ref{sec:syntax}. Minor implementation details are omitted for clarity; at first we assume laziness everywhere, 
while later there will be an overview of how the interpreter runs in the presence of ML-lists.
\newline
\par We finally begin our pattern matching on the expressions. The \textit{FunctionsMap} structure is also omitted as 
eval's argument; we assume that we lookup this for formals and we want to jump to a function's body, e.g. in the function  
call expression.

In every execution step our \textit{eval} is looking up the current state. As we have already mentioned the state is 
a record of:
\begin{minted}{haskell}
  State = (Mem, FrameId, NRFrames) 
  -- FrameId: id of the current frame
\end{minted}
, and thus by looking up the current's state frame, we can obtain the environment, as following:
\begin{minted}{haskell}
  thisFrame = getFrame mem frameId 
  Frame caller funArgs susps prevFrameId = thisFrame 
\end{minted}

In this way, we have information about:
\begin{itemize}
  \item \textit{caller}: the name of the caller function we are currently in,
  \item \textit{funArgs}: the current function' s actual arguments that are built for the frame (see later how we build these 
  arguments when a function call is invoked), 
  \item \textit{susps}: suspended executions for constructors forced by pattern matching, 
  \item \textit{prevFrameId}: The id of the previous frame, just like having a pointer to the previous frame.
\end{itemize}

After the necessary information from the current state is obtained, the intepreter handles each one of the expressions
in the following way, presented in the following sections.

\subsection{Variable lookup}

We reminde at this point that a variable bound at case pattern matching isn't evaluated here because of the constructor 
projection transformation we described earlier in section~\ref{sec:other-transformations}, and thus in this section we are concerned about evaluation 
of top-level variables. 

A top-level variable exists in the formal parameters of a function definition. In \textit{frame's terms}, 
we are looking for the proper \textit{FrameArg} in the \textit{funArgs} field, mentioned earlier when we explained 
the interpreter's \textit{current state}.

The procedure is the following (this is equivalent to lookup the variable inside the environment):
\begin{itemize}
  \item First, we find the position of the variable in the current frame.
  \begin{itemize}
    \item Lookup the \textit{caller} function in the \textit{FunctionsMap} structure to find the function's 
    \textit{signature}.
    \item Once the signature is found, then we find the position in formal parameters of the function definition, 
    i.e. the \textit{index (i)} of the argument.
  \end{itemize} 
  \item Given the index that we found earlier, we find the proper frame argument in the current frame. 
\end{itemize}

Once we have found the proper frame argument, we have \textit{three} cases, depending whether the variable is in cbv, cbn or lazy 
evaluation order (we use the abbrevation e.o. which stands for evaluation order). 

Later, we give the v' and s' for:
  $ \mathit{eval (v, s) = (v', s')} $

  \begin{itemize}
    \item cbv e.o.: Variable lookup operation for call-by-value 
          variables is shown in figure~\ref{fig:cbv-varLookup}.
      \begin{figure}[t]
      \hrule
        \begin{align*}
           & \mathit{(v', s') = (val, s),} \\
           \mathit{where} \\ 
           & \mathit{v = StrictArg \hfill\ val}
        \end{align*}
      \caption{Variable lookup for call-by-value\label{fig:cbv-varLookup}}
      \end{figure}
    \item cbn e.o.: Variable lookup operation for call-by-value 
    variables is shown in figure~\ref{fig:cbn-varLookup}.

    We note that whatever is the new interpreter's state \textit{s''}, we do not memoize it, as call-by-name semantics 
    doesn't include any change of the memory's state.

    \begin{figure}[t]
      \begin{align*}
        & \mathit{ (v', s') = (val, s), \hfill\ where } \\
        & \mathit{ v = ByNameArg \hfill\ expr, } \\
        & \mathit{(val, s'') = eval \hfill\ expr \hfill\ (mem, prevFrameId, nr\_frames)} \\
      \end{align*}
    \caption{Variable lookup for call-by-name\label{fig:cbn-varLookup}}
    \end{figure}      

    \item lazy e.o.: In this case (figure~\ref{fig:lazy-varlookup}) we have \textit{two} subcases.
    The subcases are whether \textit{b} is \textit{true} or \textit{false}, i.e. the lazy argument is evaluated and cached or
    not evaluated. In the latter case, the interpreter needs to evaluate the variable and update the frame, as shown below,
    in the appropriate case:

    \begin{figure}[t]
      \[\mathit{v = LazyArg \hfill\ e \hfill\ b \hfill\ val}\]
      
      \begin{itemize}
          \item \textit{b} is \textit{true}: \[ \mathit{(v', s') = (val, s)} \]
          \item \textit{b} is \textit{false}:
            \begin{align*}
                & \mathit{(v', s') = (val', (updFrame \hfill\ mem' \hfill\ frameId \hfill\ frame', frameId, nr\_frames')), where} \\
                & \mathit{(val', (mem', frameId', nr\_frames')) = eval \hfill\ e \hfill\ (mem, prevFrameId, nr\_frames)} \\
                & \mathit{frame'[funArgs] = ( funArgs[i] = LazyArg \hfill\ e \hfill\ true \hfill\ val' )} \\
            \end{align*}
      \end{itemize}
    \caption{Variable lookup for call-by-need\label{fig:lazy-varlookup}}
    \hrule
  \end{figure}


  We note that, at this point, where there is memory change, and probably evaluation of the expression provokes 
  the creation of new frames, we update the memory state as well as the frame counter. 

  \end{itemize}
  
\subsection{Function call}

In this section, we describe the interpreter for a function call. The call is of the form:
\[ 
  \mathit{Expr = Call \hfill\ callee \hfill\ actuals,} 
\]
where we have the information about \textit{callee}'s name and the actual parameters from the function call. 

\begin{figure}[htp]
  \[ \mathit{makeArgs :: [Actual] \times [Formal] \times State \rightarrow [FrameArg] \times State}, \]
\caption{Construction of frame arguments\label{fig:makeArgs}}
\end{figure} ~
\begin{figure}[htp]
  \begin{align*}
    \mathit{(v, state') = eval \hfill\ actual \hfill\ state} \\
    \mathit{frameArg = StrictArg \hfill\ v}
  \end{align*}
\caption{Construction of call-by-value frame argument\label{fig:makeCBVArg}}
\end{figure} ~
\begin{figure}[htp]
  \[ 
    \mathit{frameArg = ByNameArg \hfill\ actual} 
  \] 
\caption{Construction of call-by-name argument\label{fig:makeCBNArg}}
\end{figure} ~
\begin{figure}[htp]
  \[
    \mathit{frameArg = LazyArg \hfill\ actual \hfill\ false \hfill\ empty} 
  \]
\caption{Construction of lazy argument\label{lazyArgConstruction}}
\end{figure} ~
\begin{figure}[htp]
  \begin{align*}
    & \mathit{eval \hfill\ (Call \hfill\ callee \hfill\ actuals, s) = (val, s'''),} \\ \mathit{where} \\
    & \mathit{(formals, funBody) = lookup \hfill\ callee \hfill\ FunctionsMap} \\
    & \mathit{(frameArgs, (mem', \_, nr\_frames')) = makeArgs \hfill\ actuals \hfill\ formals  \hfill\ state} \\
    & \mathit{newFrame = Frame \hfill\ callee \hfill\ frameArgs \hfill\ [] \hfill\ frameId} \\
    & \mathit{mem'' = push \hfill\ mem' \hfill\ newFrame \hfill\ (nr\_frames + 1) \hfill\ frameId} \\
    & \mathit{s' = (mem'', lastFrameId \hfill\ mem'', nr\_frames + 1)} \\
    & \mathit{(val, s'') = eval \hfill\ funBody \hfill\ s'} \\
    & \mathit{(s'' = (mem''', _, nr\_frames''))} \\
    & \mathit{s''' = (mem''', frameId, nr\_frames'')}
  \end{align*}
\caption{Operational semantics for function call\label{fig:functionCall}}
\end{figure}

% \pagebreak

First, we are going to present a function about constructing the function's arguments, given the actual parameters of the call 
and the formal parameters from the function's signature, lying in the function definition in \textit{FunctionsMap}. So, let's 
pause for a while for the definition of this function, and then resume later for function call handling inside the 
interpreter.

The function, called \textit{makeArgs} has the form, that is shown in figure~\ref{fig:makeArgs},
where the actuals and the formals are explained above and the \textit{State} is the interpreter's 
current state.For every actual corresponding to every formal, we have the following, depending 
whether the parameter is in cbv, cbn or lazy evaluation order(abbr. e.o):
\begin{itemize}
  \item cbv e.o.: As shown in figure~\ref{fig:makeCBVArg} the function returns \textit{(frameArg, state')}, where 
  \textit{frameArg} is added to \textit{[FrameArg]} and \textit{state'} is the next input state for 
  \textit{makeArgs}. 
  \item cbn e.o.: As shown in figure~\ref{fig:makeCBNArg}, the state remains unchanged and thus 
  \textit{(frameArg, state)} is returned.
  \item lazy e.o.: As shown in figure~\ref{lazyArgConstruction} the state does not change, 
  and thus \textit{(frameArg, state)} is returned.  
\end{itemize}

As it seems above, only cbv arguments are executed at this point, and the memory change they provoke, 
is returned in the state of the \textit{eval} function.

Now, it' s time to resume the presentation about the function call in the interpreter.
The operational meaning of a function call is shown in figure~\ref{fig:functionCall}. 
Every time we have a function call a new frame is pushed to the memory. Then, the interpreter 
evaluates the body of the function, and finally we reset the environment for the next operation 
handled by the interpreter.



\subsection{Pattern matching}

As we have shown in section~\ref{sec:syntax}, we distinguish between pattern matching on integers and pattern matching on data. 
More specifically a branch for a pattern matching is:
\begin{minted}{haskell}
  type Branch  = (Pattern, Expr)
  data Pattern = CPat { tag :: CN, vars :: [VN] } -- pattern matching on constructors 
               | IPat { pattVal :: Int }          -- pattern matching on integers 
\end{minted}

\begin{figure}[htp]
  \begin{align*}
    \mathit{caseExpr = Case \hfill\ caseId \hfill\ e \hfill\ branches}
  \end{align*}
\caption{Case expression\label{fig:case}}
\end{figure} ~
\begin{figure}[htp]
  % \hrule
  \begin{align*}
    &  \mathit{eval \hfill\ (e, s) = (e', s'),}  \\
    \mathit{where} \\
    &  \mathit{s' = (mem', savedFrameId, n), \hfill\ and} \\
    &  \mathit{e' = VI \hfill\ i, \hfill\ integer \hfill\ pattern \hfill\ matching, or} \\
    &  \mathit{e' = VC \hfill\ c, \hfill\ constructor \hfill\ pattern \hfill\ matching} \\
    &  \mathit{c = Susp \hfill\ (cn, \_) \hfill\ \_}  
  \end{align*}
\caption{Evaluation of the scrutinee\label{fig:scrueval}}
\end{figure} ~
\begin{figure}[htp]
  \begin{align*}
    & \mathit{eval \hfill\ (caseExpr, s) = (eval \hfill\ e'' \hfill\ s', s'),} \\
    \mathit{where} \\
    & \mathit{e'' = lookup \hfill\ (IPat \hfill\ i) \hfill\ cases} \\
    % \mathit{, and} \\
    & \mathit{\textit{s'} \hfill\ is \hfill\ the \hfill\ state \hfill\ after \hfill\ scrutinee's 
    \hfill\ evaluation.}
  \end{align*}
\caption{Integer pattern matching operational semantics\label{fig:intPattMatch}}
\end{figure} ~
\begin{figure}[htp]
  \begin{align*}
    & \mathit{eval \hfill\ (caseExpr, s) = (eval \hfill\ e'' \hfill\ s'', s''), } \\ 
    \mathit{where} \\
    & \mathit{pattIndex = indexOfPattern \hfill\ cn \hfill\ patterns} \\
    & \mathit{(\_, e'') = branches \hfill\ [pattIndex]} \\
    & \mathit{susps' = (caseId, c) \hfill\ : \hfill\ susps} \\
    & \mathit{frame' = Frame \hfill\ caller \hfill\ funArgs \hfill\ susps' \hfill\ prevFrameId} \\
    & \mathit{s'' = (updFrame \hfill\ mem' \hfill\ frameId \hfill\ frame', \hfill\ frameId, \hfill\ n)}
  \end{align*}
\caption{Pattern matching on constructors operational semantics\label{fig:consPattMatch}}
% \hrule
\end{figure}



The case expression is shown in the figure~\ref{fig:case}. For its evaluation, the interpreter 
does the following:~
\begin{itemize}
  \item First, we evaluate the scrutinized expression, shown in figure~\ref{fig:scrueval}.
  \item Next, in figure~\ref{fig:intPattMatch} we show how the interpreter works for 
        integer pattern matching.
  \item Finally, the pattern matching on constructors is shown in figure~\ref{fig:consPattMatch}.
\end{itemize}


In the above definitions, \textit{indexOfPatterns} gives as output the index of the pattern 
in the \textit{patterns} list, and this list is retrieved by the \textit{branches} list 
by ignoring the second value.

Integer pattern matching can't be exhaustive, because integer domain consists of infinite elements, and thus we 
assume that \textit{IPat i} is a pattern that exists in the patterns list. Otherwise, the interpreter will throw an exception.


We note that even though our interpreter works for lists, this is applied to every data constructor, 
when `case' works in the same way as Haskell's builtin `case'. The `constructor' representation 
would be the same for every constructor definition, as constructors are also functions themselves. 
The latter is obvious taking into consideration that we work on a functional language; 
a programming language with \textit{functions as first-class citizens}.

\subsection{Constructor application}

In the case of having a constructor application of a \textit{lazy data constructor},
this is equivalent to a memory allocation of a thunk. In our case, this is 
a suspended execution of lazy data constructor, the one explained in section~\ref{sec:suspended}.
More specifically, the \textit{eval} for a lazy constructor application 
is shown in figure~\ref{fig:consAppl}.

\begin{figure}[h]
  \begin{align*}
    & \mathit{eval \hfill\ (ConstrF \hfill\ tag \hfill\ exprs, s) = (VC \hfill\ (Susp \hfill\ (tag, exprs) \hfill\ frameId), s)} \\
    \mathit{, where} \\
    &  \mathit{\textit{frameId}: \hfill\ the \hfill\ id \hfill\ of \hfill\ the 
    \hfill\ current \hfill\ frame \hfill\ existing \hfill\ in \hfill\ the \hfill\ interpeter's 
    \hfill\ state,} \\
    &  \mathit{\textit{tag}: \hfill\ the \hfill\ name \hfill\ of \hfill\ the \hfill\ 
    constructor.}
  \end{align*}
\caption{Lazy list constructor application operational semantics\label{fig:consAppl}}
\end{figure} ~
% \begin{figure}[h]
%   \begin{align*}
%     & \mathit{eval~(SHConstrF~tag~(e~:~es), s) = (VC~(Susp~(tag, (e'~:~es))~frameId), s')} \\
%     & \mathit{(e',s') = eval~(e, s)}
%   \end{align*}
% \caption{Strict head list constructor application\label{fig:shconsAppl}}
% \end{figure} ~
% \begin{figure}[h]
%   \begin{align*}
%     & \mathit{eval~(STConstrF~tag~(e~:~es), s) = (VC~(Susp~(tag, (e~:~es'))~frameId), s')} \\
%     & \mathit{(es',s') = eval~(es, s)}
%   \end{align*}
% \caption{Strict tail list constructor application\label{fig:stconsAppl}}
% \end{figure} ~
% \begin{figure}[h]
%   \begin{align*}
%     & \mathit{eval~(MLConstrF~tag~(e~:~es), s) = (VC~(Susp~(tag, (e'~:~es'))~frameId), s'')} \\
%     & \mathit{(e',s') = eval~(e, s)} \\
%     & \mathit{(es', s'') = eval~(es, s')}
%   \end{align*}
% \caption{ML-list constructor application\label{fig:mlconsAppl}}
% \end{figure}

% \newpage

\subsection{Constructor projection}

In this case, the interpreter has come across a variable bound by 
pattern matching. As we mentioned earlier (section~\ref{sec:lazy-data-cons}), the evaluation
of a term is forced, when such variables are needed to be evaluated.
The \textit{eval} function of \textit{constructor projection} is shown in 
figure~\ref{fig:consproj}. ~
\begin{figure}[htp]
  \begin{align*}
    & \mathit{eval \hfill\ (CProj \hfill\ caseId \hfill\ cpos, s) = (val, s'),} \\
    \mathit{where } \\
    & \mathit{s' = mem' \hfill\ frameId \hfill\ nr\_frames'} \\
    & \mathit{susp = lookup \hfill\ cid \hfill\ susps} \\
    & \mathit{Susp \hfill\ (\_, el) \hfill\ savedFrameId = susp} \\
    & \mathit{e' = el[cpos]} \\
    & \mathit{(val, (mem', \_, nr\_frames')) = eval \hfill\ (e', s)}
  \end{align*}
\caption{Constructor projection operational semantics\label{fig:consproj}}
\end{figure} ~
First, we find the $\mathit{susp}$ inside the $\mathit{susps}$ in the current frame. Then, 
from the expression list $\mathit{el}$ we find the right constructor in the $\mathit{cpos}$ 
position. After evaluating this expression, we have the result-value and the next state 
for our interpreter.

\chapter{Analysis: Searching for optimisation opportunities}
\label{ch:analysis}

In this chapter, we present the analysis performed in order to reveal true tail-call positions.
First, we make some important high-level definitions for the reader to be able to follow up. 
The presentation of the algorithms for each one of the optimisations will follow; section~\ref{sec:classic-tco-analysis} contains 
the algorithm for classic tail-call optimisation and section~\ref{sec:modulo-cons-analysis} contains the algorithm for tail recursion modulo cons.
\newline
\par The input of the analysis is the core level language described in section~\ref{sec:syntax}, 
along with the operational semantics provided in the previous chapter. The output is appropriately 
\textit{annotated} function calls which the enriched evaluator of the next chapter is going to handle.
The analysis in this chapter reveals \textit{where} to apply the optimisations, while 
in the next chapter we present \textit{how} to actually perform the optimisations in the runtime system.



% Analysis chapter 

\section{Classic tail-call optimisation}
\label{sec:classic-tco-analysis}

At this point, we shall make clear that the terms tail-call or tail-call position are not the same 
as tail-call optimisable, providing the definitions shown below.

\subsection{Tail-call position (tail-call) vs. Tail-call optimisable (true tail-call)}

\paragraph{Definition 6.1}
A function call is in \textit{tail call position}, or \textit{tail call}, \textit{if and only if} its execution is the last action 
performed before the function returns.

\paragraph{Definition 6.2}
A function call is \textit{tail call optimisable}, or \textit{true tail call}, \textit{if and only if} it is in tail call position and it satisfies the rules shown in 
section~\ref{sec:data-driven-analysis}.\\

The same definitions also stand for tail recursion modulo cons, if we substitute \textit{tail-call} with 
\textit{tail recursion modulo cons}; an equivalent section is omitted for section~\ref{sec:modulo-cons-analysis}.

In the next sections, we present the path from \textit{function calls} in the core language to \textit{tail-call positons}, 
and from there to \textit{true tail-calls}; that is function calls that are actually optimisable. The latter is annotated as a new 
expression in the core language, called \textit{TailCall}. When the interpreter comes across this expression, it performs the 
optimisation, while the program is executing.

\subsection{Control-flow analysis: Spotting tail-call positions}

For a call-by-value language, this step reveals each and every true tail-call position. For a language with mixed evaluation order, and specifically 
with call-by-need semantics this isn't enough, as it has been already sketched in section~\ref{sec:example2}, as lazy arguments are arbitrarily evaluated and thus 
they escape their context. 

This is a local analysis, performed locally in a function's body. The analysis is summarized in the following rules:
\begin{itemize}
  \item The body of a lambda (or a function) is a tail call.
  \item When an if/case expression is in tail call position, then the right hand side of the branches is in tail-call position. 
  In the case of an `if' expression, this means that then/else clause is in tail call position.
  \item Nothing else is in tail call position.
\end{itemize}

To illustrate the above, let's consider the following, very simple example:
\begin{minted}{haskell}
  foo n = 
    if n > 0  
      then n * foo (n-1) 
      else 1
\end{minted}

The body of `foo' function is in tail call position. This means that `if', which is the body, is in tail call position. 
Thus, then/else are tail calls. Now in the `then' clause, where the multiplication takes place, the call to `foo' isn't in tail call position, 
according to the third rule.

But if we had the following example:
\begin{minted}{haskell}
  foo n res = 
    if n > 0 
      then foo (n - 1) (n * res)
      else res
\end{minted}
then the call is in tail-call position as the `then' clause is in tail-call position.

\subsection{Data-driven analysis: Revealing true tail-calls}
\label{sec:data-driven-analysis}

After revealing tail-call position, deriving from the control flow of the program shown in the previous section, now we apply some rules in order to 
reveal true tail call positions, depending by the evaluation order of caller and callee function. After all, tail-call optimisation 
is all about passing the control from the caller to the callee. This step is omitted in call-by-value languages as there is 
only one evaluation order and the semantics allow the optimisation quite naturally.

Although it seems that the rules are applied in a second analysis pass, this is done for clarity purposes; in the implementation we can 
only do that in-place, in a single analysis pass just after a tail call (and thus potentially a true tail call) is revealed.

\textbf{[TODO: Write the rules here!]}

\section{Tail recursion modulo cons}
\label{sec:modulo-cons-analysis}

% \subsection{Control-flow analysis: Spotting tail recursion modulo cons positions}

Tail recursion modulo cons can be applied to any constructor application, that is guarded by a lazy constructor.
In our language this happens to (:), which is lazy and is the constructor for lists. It could also be applied 
to arithmetic operations, for example in Haskell, but in our language all arithmetic operations are strict.

The control flow of the program also reveals the tail recursion modulo cons in the same way as in classic tail 
calls. The only difference is that constructor application must be a tail call. Thus the rules for tail recursion 
modulo cons have the following form:
\begin{itemize} 
  \item The body of a lambda (or a function) is a tail call and it is also a lazy constructor application
  (instead of a function application).
  \item When an if/case expression is in tail call position, then the right hand side of the branches is in tail-call position. 
  In the case of an `if' expression, this means that then/else clause is in tail call position. The right hand side 
  of a branch must also be a lazy constructor application.
  \item Nothing else is in tail recursion modulo cons position.
\end{itemize}

% \subsection{Data-driven analysis: Revealing true tail recursion modulo cons positions}

The additional rule for tail recursion modulo cons is that if you have a tail call of the form:
\begin{minted}{haskell}
  x : y
\end{minted}
then \textit{`x'} must not contain any recursive calls and \textit{`y'} must be a function call that is subject to the 
rules presented in section~\ref{sec:data-driven-analysis}; in this way frame mutation will become possible. If the last rule is applied, 
then we can have \textit{x `:' tail recursive call to the function}. Details on that will be presented later, in section~\ref{sec:tco-modulo-cons-eval}.


% \section {Intermediate list node removal}
% Sharing problem 
% Arithmetic operators blah blah blah
% Global analysis

\chapter {Runtime evaluator for optimisations}
\label{ch:evaluator}

In this chapter, we will present how the optimisations are implemented in the interpreter.
More specifically there will be presented:
\[ \mathit{eval \hfill\ (e, s) = (e', s')} \]
where:
\begin{itemize}
\item in section~\ref{sec:classic-tco-eval} we have the evaluation of tail-call optimisation, first expression 
      shown in figure~\ref{fig:annos},
\item and in section~\ref{sec:tco-modulo-cons-eval} we have the evaluation of tail recursion modulo cons shown
      also in figure~\ref{fig:annos}.
\begin{figure}[h]
  \begin{align*}
    & \mathit{e = TailCall \hfill\ callee \hfill\ actuals} \\
    & \mathit{e = TRMC \hfill\ tag \hfill\ exprs} 
  \end{align*}
\caption{Annotated expressions\label{fig:annos}}
\end{figure}

\end{itemize}
The first is the classic tail-call optimisation, while the latter is the tail-recursion 
modulo cons. There will be a comprehensive explanation of how we mutated the frames and how we counted them for 
our evaluation, that follows in the next chapter.

\section {Evaluator for classic tail-call optimisation}
\label{sec:classic-tco-eval}

Classic tail call evaluation contains one major \textit{operation}, which makes the optimisation 
feasible: this is \textit{frame mutation}. This operation includes the replacement of the current frame's arguments 
with the arguments necessary for the construction of the frame for the next function call. For this operation,
it is mandatory that the caller's arguments do not escape and for those that escape we correctly passed them 
to the new frame. 

The \textit{eval} for the \textit{TailCall} follows in figure~\ref{fig:tco}; we remind that this is actually optimisable as the analysis 
revealed, although we make few, inexpensive extra checks for some cases.
The functionality of \textit{checkMutate} will be explained later on in this section. The other variables 
, shown in figure~\ref{fig:tco} are:
\begin{itemize}
  \item \textit{formals} are the formal parameters of the function definition of the callee function,
  \item \textit{actuals} are the actual parameter of this tail-call optimisable function call,
  \item \textit{funArgs} are the arguments inside the current frame, 
  \item and \textit{s} is the current state of the interpreter.
\end{itemize}


\begin{figure}[h]
  \begin{align*}
    & \mathit{eval \hfill\ (TailCall \hfill\ callee \hfill\ actuals, s) = (e', s'),} \\
    \mathit{where} \\
    & \mathit{(formals, funBody) = lookup \hfill\ FunctionsMap \hfill\ callee} \\
    & \mathit{e' = eval \hfill\ (funBody, s')} \\
    & \mathit{s' = checkMutate \hfill\ formals \hfill\ actuals \hfill\ funArgs \hfill\ s} 
  \end{align*}
\caption{Tail-call optimisation operational semantics \label{fig:tco}}
\end{figure}


At this point, we are ready to provide the definition for \textit{checkMutate}, which 
is a function that given the current interpreter's state performs the runtime mutation 
of the frame and produces the next state of the interpreter. Its declaration is given in 
the figure~\ref{fig:checkdecl} and the operational meaning of the function in the 
figure~\ref{fig:checkMutate}.

\begin{figure}[h]
  \begin{align*}
    \mathit{checkMutate :: [Actual] \times [Formal] \times [FrameArg] \times State \rightarrow State} 
  \end{align*}
\caption{Declaration of $\mathit{checkMutate}$ operation\label{fig:checkdecl}}
\end{figure}

 

\begin{figure}[h]
  \begin{align*}
    & \mathit{checkMutate \hfill\ (actuals, formals, funArgs, s) = s', } \\
    \mathit{where } \\
    & \mathit{(mem, frameId, nr\_frames) = s} \\
    & \mathit{(callerFormals, \_) = lookup \hfill\ callee \hfill\ FunctionsMap} \\
    & \mathit{(funArgs', s'') = mutate \hfill\ callerFormals \hfill\ formals \hfill\ funArgs \hfill\ actuals \hfill\ s } \\
    & \mathit{(mem', frameId', nr\_frames') = s''} \\
    & \mathit{frame'' = Frame \hfill\ callee \hfill\ funArgs' \hfill\ [] \hfill\ prevFrameId} \\
    & \mathit{s' = (updFrame \hfill\ mem' \hfill\ frameId \hfill\ frame'', frameId, nr\_frames')}
  \end{align*}
\caption{Operational semantics for \textit{checkMutate}\label{fig:checkMutate}}
\end{figure}

Now, we are going to describe an auxiliary function used in order to constructor 
the function's arguments of the mutated frame; specifically in the definition of 
\textit{funArgs'} the function called \textit{mutate}.
The operational semantics for \textit{mutate} operation is shown in figure~\ref{fig:mutate}.
From the figure, we have that \textit{mutate} is a function that takes as input:
\begin{itemize}
  \item The formal parameters of the caller function,
  \item the formal parameters of the callee function,
  \item the frame arguments that exist in the current frame (the one we want to mutate),
  \item the actual parameter of the function call, which is tail-call optimisable,
  \item the current state of the interpreter, 
\end{itemize}
and produces:
\begin{itemize}
  \item The frame arguments for the new frame. We note here that we want to turn the actual parameters 
  of the function call into the appropriate frame arguments, using the function signatures of the caller and the callee.
  Specifically, we are interested in the format of the arguments, and thus we need to know the evaluation 
  order of the functions.
  \item The next state for the interpreter. Because evaluation \textit{may} take place, while this function is executing 
  (for example we need to turn a lazy frame argument into a strict and thus we perform the evaluation before 
  we jump into the callee function's body), we need to change the memory state and count the frames correctly
  for our evaluation that follows in the next chapter.
\end{itemize}

As the language is first-order, it doesn't support partial applications, and thus the number of arguments 
in the actual parameters list is equal to the number of formals of the callee function. The \textit{mutate} function 
terminates when these two lists are empty at the same iteration, or else it throws an exception. Its execution starts 
and continues until it terminates by processing each and every actual parameter of the function call. The result is 
a list that accumulates the result of every iteration. 


\begin{figure}[h]
  $\mathit{getIndex :: VN \times EvaluationOrder \times Type \times [Formal] \rightarrow Index}$ \\
  $\mathit{getIndex~(vn,~eo,~type)~fs=elemIndex~(vn,(eo,type))~fs}$ \\
  \\
  $\mathit{getEvaluationOrder :: Formal \rightarrow EvaluationOrder} $ \\
  $\mathit{getEvaluationOrder :: (\_, (eo, \_)) = eo}$ \\
  \\%
  $\mathit{signOfVar :: [Formal] \times VN \rightarrow EvalutionOrder \times Type } $ \\
  $\mathit{signOfVar~formals~vn = lookup~vn~formals}$ \\
  \\%
  $\mathit{transform :: CallerEO \times CalleeEO \times FrameArg \times 
            State \rightarrow FrameArg \times State}$ \\
  $\mathit{transform~(CBV, CBV, arg, s) = (arg, s)}$ \\
  $\mathit{transform~(CBN, CBN, arg, s) = (arg, s)}$ \\
  $\mathit{transform~(Lazy, Lazy, arg, s) = (arg, s)}$ \\
  $\mathit{transform~(CBV, CBN, ByNameArg~e, s) = (StrictArg~v, s'),}$ \\
  $\mathit{\hfill\ \hfill\ where~(v, s') = eval~(e, s)}$ \\
  $\mathit{transform~(CBV, Lazy, LazyArg~e~b~v, s) = 
              if~b~then~(StrictArg~v, s)~else~(val, s'),}$ \\
  $\mathit{\hfill\ \hfill\ where~(val, s') = eval~(e, s)} $ \\
  $\mathit{transform~(CBN, CBV, StrictArg~(VI~v),s)=(ByNameArg~(EInt~v),s)}$ \\
  $\mathit{transform~(CBN, CBV, StrictArg~(VC~c),s)=error}$ \\
  $\mathit{transform~(CBN, Lazy, LazyArg~e~true~(VI~v), s) = (ByNameArg~(EInt~v), s)}$ \\
  $\mathit{transform~(CBN, Lazy, LazyArg~e~true~(VC~c), s) = error}$ \\
  $\mathit{transform~(CBN, Lazy, LazyArg~e~false~v, s) = (ByNameArg~e, s)}$ \\
  $\mathit{transform~(Lazy, CBV, StrictArg~v, s) = (LazyArg~e~true~v, s)}$ \\
  $\mathit{transform~(Lazy, CBN, ByNameArg~e, s) = (LazyArg~e~false~null, s)}$ \\
  \\%
  $\mathit{mutate :: [Formal] \times [Formal] \times [FrameArg]
            \times [Actual] \times Index \times State \rightarrow [FrameArg] \times State} $ \\
  $\mathit{mutate~(callerfs,~calleefs,~args,~(EVar~v~:~as),~ix,~acc,~s)}$ \\
  $\mathit{\hfill\ =~mutate~(callerfs,~calleefs,~args,~as,~(ix+1),(arg'~:~acc), ~s')}$ \\
  $\mathit{\hfill\ \hfill\ where~calleeEO=getEvaluationOrder~calleefs[ix]}$ \\
  $\mathit{\hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ 
            sign@(callerEO, callerType) = signOfVar~(vn, callerfs)}$ \\
  $\mathit{\hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ 
            callerIx = getIndex~(vn, sign)~callerfs}$ \\
  $\mathit{\hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ 
            arg = args[callerIx]}$ \\
  $\mathit{\hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ 
            (arg', s') = mutate~(calleeEO, callerEO, arg, s)}$ \\
  $\mathit{mutate~(callerfs,~calleefs,~args,~(a@(EInt~n)~:~as),~ix,~acc,~s)}$ \\
  $\mathit{\hfill\ =~mutate~(callerfs,~calleefs,~args,~as,~(ix+1),(arg~:~acc), ~s)}$ \\
  $\mathit{\hfill\ \hfill\ where~calleeEO=getEvaluationOrder~calleefs[ix]}$ \\
  $\mathit{\hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ 
      if~calleeEO=CBV~then~StrictArg~(VI~n)~else~if~calleeEO=CBN~then~ByNameArg~a~else~LazyArg~a~false~null}$ \\
  $\mathit{mutate~(callerfs,~calleefs,~args,~(a~:~as),~ix,~acc,~s)}$ \\ 
  $\mathit{\hfill\ =if~calleeEO=CBV~then~mutate~(callerfs,~calleefs,~args,~as,~(ix+1),(arg'~:~acc), ~s')}$ \\
  $\mathit{\hfill\ \hfill\ where~calleeEO=getEvaluationOrder~calleefs[ix]}$ \\  
  $\mathit{\hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ 
            (v, s') = eval~(a, s)}$ \\
  $\mathit{\hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ \hfill\ 
            arg'=StrictArg~v}$ \\
\caption{Operational semantics for $\mathit{mutate}$ operation\label{fig:mutate}}
\end{figure}

\section {Evaluator for tail recursion modulo cons}
\label{sec:tco-modulo-cons-eval}

mpla mpla mpla 

\chapter {Evaluation of the optimisations}
\label{ch:evaluation}

Write about the interpreter again for each case.

How it counts the frames. 

Give graph results from the microbenchmarks.

\chapter{Related work}
\label{ch:related}

Implementations of programming languages use a stack for function calls, 
where activation records are pushed for every function invocation: this permits recursion 
and has good performance. Stack allocation for function calls has been an old technique, 
dating back at least to ALGOL~\cite{Dijkstra60,Naur78} and LISP~\cite{McCarthy60,Stoyan79}.

Tail-calls are function calls that happen last inside a function and
they can be implemented with a ``go to'' instruction. In the special
case that the caller's activation record will not be needed again,
\emph{tail-call optimization} can reuse it to construct the activation
record of the callee, saving space, and making some programs run in
constant space. Tail-calls can be further optimized by the
instruction-scheduling stage of a compiler~\cite[\S12.4.3]{Torczon12}.
Tail-calls have been used to transform recursive functions to
iterative (tail-recursive)
ones~\cite[\S{9}]{McCarthy62}\cite{Barron68}.  Tail-call optimization
is an old idea~\cite[p.~7]{Gill65}\cite[p.~21]{Knuth74}, which is an
established part of modern compilers.

Some languages and implementations often offer features that are not
easy to compose with tail-call optimization. Activation records may
not be resized in-place for languages that support
coroutines~\cite[p.~60]{Waite84}. Languages that support first-class
continuations~\cite{Sperber10}, higher-order return
values~\cite[p.~103]{Appel92}\cite{Steele78},
backtracking~\cite{Bobrow73}, or non-strict evaluation, and
implementations in continuation-passing style~\cite[p.~103]{Appel92},
may allocate activation records on the heap. 

Tail-call optimization is also important for implementations of logic languages~\cite{Bigot99},
functional programming languages running on the Java virtual machine~\cite{Madsen:2018:TCE:3178372.3179499},
imperative languages such as C~\cite{baueran:mthesis:2003,Probst01}, or even low-level compiler-targeted languages such as
LLVM~\cite{Pandey:2015:LC:2842773}.

Find something Haskell-ish for classic tail-calls. GHC used Cmm and 
later LLVM to support tail calls~\cite{Terei:2010:LBG:1863523.1863538}.

fusion vs. tail recursion modulo cons.


\chapter{Future work}
\label{ch:future}

summary of what is done.
extension of the tail-call optimisation for strict
languages.
what is missing (only used for lists, booleans).
generalization for constructors.
can be used for Haskell? Simply sketch something.
benchmarks.

Future work: integration with compiler (statically compile the decisions of interpreter).

\selectlanguage{greek}

%%%  Bibliography

\bibliographystyle{softlab-thesis}
\bibliography{thesis}


%%%  Appendices

\backmatter

% \appendix

% \chapter{General}

\end{document}
